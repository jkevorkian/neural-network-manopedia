{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:28:10.198246Z",
     "start_time": "2024-10-18T03:28:10.034333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          DATA SHAPE DEFINITION           ##\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define the parameters for the data shape\n",
    "videos_per_handsign = 2  # Adjust if necessary\n",
    "frames_per_video = 10\n",
    "num_landmarks = 51\n",
    "num_coordinates = 3\n",
    "\n",
    "num_additional_samples = 2      #how many different samples of frames_per_video frames will be taken from each video (carefull to not add too many if vids are short)\n",
    "\n",
    "data_augmentation = True        #Add noise and transformation to generate, from each video extracted, a num_augmented_versions number of new ones (also keep between 1-4)\n",
    "num_augmented_versions = 2\n",
    "\n",
    "# Define the root directory containing handsign folders\n",
    "root_path = \"ACOTADONomenclatedDataset\"\n",
    "\n",
    "def get_handsign_folders(root_path):\n",
    "    handsign_names = {}\n",
    "    handsign_video_counts = {}  # To store the video count for each handsign\n",
    "    handsign_count = 0\n",
    "    \n",
    "    # Walk through the root directory\n",
    "    for folder in os.listdir(root_path):\n",
    "        folder_path = os.path.join(root_path, folder)\n",
    "        \n",
    "        # Ignore non-directories\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # If the folder starts with \"#\", check its subdirectories\n",
    "        if folder.startswith(\"#\"):\n",
    "            for subfolder in os.listdir(folder_path):\n",
    "                subfolder_path = os.path.join(folder_path, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    handsign_names[handsign_count] = subfolder\n",
    "                    # Count videos in the subfolder\n",
    "                    videos = [f for f in os.listdir(subfolder_path) if f.endswith(('.mp4', '.avi', '.MOV'))]\n",
    "                    handsign_video_counts[subfolder] = len(videos)\n",
    "                    handsign_count += 1\n",
    "        else:\n",
    "            # Directly add the folder as a handsign\n",
    "            handsign_names[handsign_count] = folder\n",
    "            # Count videos in the folder\n",
    "            videos = [f for f in os.listdir(folder_path) if f.endswith(('.mp4', '.avi', '.MOV'))]\n",
    "            handsign_video_counts[folder] = len(videos)\n",
    "            handsign_count += 1\n",
    "    \n",
    "    return handsign_names, handsign_video_counts\n",
    "\n",
    "# Get the handsign names and video counts\n",
    "handsign_names, handsign_video_counts = get_handsign_folders(root_path)\n",
    "num_handsigns = len(handsign_names)\n",
    "\n",
    "# Sort handsigns by the number of available videos in descending order\n",
    "sorted_handsign_video_counts = dict(sorted(handsign_video_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Output the handsign names, number of handsigns, and sorted video counts\n",
    "print(f\"Number of handsigns: {num_handsigns}\")\n",
    "print(\"Handsign names:\")\n",
    "print(json.dumps(handsign_names, indent=4))\n",
    "\n",
    "print(\"\\nVideo counts per handsign (sorted by number of videos):\")\n",
    "print(json.dumps(sorted_handsign_video_counts, indent=4))\n"
   ],
   "id": "823e51359a2141fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of handsigns: 3\n",
      "Handsign names:\n",
      "{\n",
      "    \"0\": \"apellido\",\n",
      "    \"1\": \"argentina\",\n",
      "    \"2\": \"sordo\"\n",
      "}\n",
      "\n",
      "Video counts per handsign (sorted by number of videos):\n",
      "{\n",
      "    \"apellido\": 50,\n",
      "    \"argentina\": 50,\n",
      "    \"sordo\": 50\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:28:15.124292Z",
     "start_time": "2024-10-18T03:28:15.074558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "#redefine videos per handsign to accomodate for additional samples to be taken before generating the dummy array (this is done so there's no shaping/dimensions size incompatibility issue)\n",
    "videos_per_handsign = videos_per_handsign * (1+num_additional_samples)\n",
    "\n",
    "# Generate dummy data\n",
    "data = [np.random.rand(videos_per_handsign, frames_per_video, num_landmarks, num_coordinates) for _ in range(num_handsigns)]\n",
    "\n",
    "# Convert the list to a numpy array with shape (num_handsigns, videos_per_handsign, frames_per_video, num_landmarks, num_coordinates)\n",
    "data_array = np.array(data)\n",
    "\n",
    "# Save the data array to a .npy file\n",
    "np.save('handsigns_data.npy', data_array)"
   ],
   "id": "fa59d6b8b575718a",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:28:16.824953Z",
     "start_time": "2024-10-18T03:28:16.759277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          PROCESS VIDEO DATASET FUNC DEFINITIONS         ##\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_landmarks(hands_results, pose_results, last_handedness):\n",
    "    landmarks = []\n",
    "\n",
    "    try:\n",
    "        nose_landmark = pose_results.pose_landmarks.landmark[0]\n",
    "    except:\n",
    "        class nose_landmark:\n",
    "            x = 0\n",
    "            y = 0\n",
    "            z = 0\n",
    "        nose_landmark = nose_landmark()\n",
    "\n",
    "    left_hand_landmarks = [(0, 0, 0)] * 21\n",
    "    right_hand_landmarks = [(0, 0, 0)] * 21\n",
    "\n",
    "    if hands_results.multi_hand_landmarks and hands_results.multi_handedness:\n",
    "        for i, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):\n",
    "            label = hands_results.multi_handedness[i].classification[0].label\n",
    "            if label == 'Left':\n",
    "                left_hand_landmarks = [(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) for lm in hand_landmarks.landmark]\n",
    "                last_handedness['Left'] = True\n",
    "            elif label == 'Right':\n",
    "                right_hand_landmarks = [(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) for lm in hand_landmarks.landmark]\n",
    "                last_handedness['Right'] = True\n",
    "\n",
    "    if not hands_results.multi_hand_landmarks or len(hands_results.multi_hand_landmarks) < 2:\n",
    "        if not last_handedness.get('Left'):\n",
    "            left_hand_landmarks = [(0, 0, 0)] * 21\n",
    "        if not last_handedness.get('Right'):\n",
    "            right_hand_landmarks = [(0, 0, 0)] * 21\n",
    "\n",
    "    landmarks.extend(left_hand_landmarks)\n",
    "    landmarks.extend(right_hand_landmarks)\n",
    "\n",
    "    selected_body_landmarks = [0, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "    if pose_results.pose_landmarks:\n",
    "        for idx in selected_body_landmarks:\n",
    "            lm = pose_results.pose_landmarks.landmark[idx]\n",
    "            landmarks.append((lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z))\n",
    "    else:\n",
    "        landmarks.extend([(0, 0, 0)] * 9)\n",
    "\n",
    "    return np.array(landmarks), last_handedness\n",
    "\n",
    "\n",
    "def process_frame(frame, hands, pose, last_handedness):\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    hands_results = hands.process(image)\n",
    "    pose_results = pose.process(image)\n",
    "\n",
    "    landmarks, last_handedness = extract_landmarks(hands_results, pose_results, last_handedness)\n",
    "\n",
    "    return landmarks, last_handedness\n",
    "\n",
    "\n",
    "def process_video_with_samples(video_path, frames_per_video, num_landmarks, num_coordinates, num_additional_samples=0):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Check if the video was opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Unable to open video {video_path}.\")\n",
    "        return np.zeros((1 + num_additional_samples, frames_per_video, num_landmarks, num_coordinates))\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Handle case where the video contains zero frames\n",
    "    if total_frames == 0:\n",
    "        print(f\"Warning: Video {video_path} contains zero frames. Filling this video's samples with zeros.\")\n",
    "        return np.zeros((1 + num_additional_samples, frames_per_video, num_landmarks, num_coordinates))\n",
    "    \n",
    "    # Select evenly spaced frames\n",
    "    indices = np.linspace(0, total_frames - 1, frames_per_video, dtype=int)\n",
    "    if total_frames < frames_per_video:\n",
    "        print(f\"Warning: Video {video_path} has fewer frames ({total_frames}) than required ({frames_per_video}). Duplicating frames to match.\")\n",
    "\n",
    "    # Initialize frame sets and track used frames\n",
    "    frame_sets = [indices]\n",
    "    used_frames = set(indices)\n",
    "    \n",
    "    # Create additional samples\n",
    "    for i in range(1, num_additional_samples + 1):\n",
    "        available_frames = list(set(range(total_frames)) - used_frames)\n",
    "\n",
    "        if len(available_frames) >= frames_per_video:\n",
    "            # Select from available frames without duplication\n",
    "            additional_indices = np.linspace(0, len(available_frames) - 1, frames_per_video, dtype=int)\n",
    "            additional_indices = [available_frames[idx] for idx in additional_indices]\n",
    "        else:\n",
    "            print(f\"Warning: Not enough unique frames left for additional sample {i}. Duplicating frames.\")\n",
    "            additional_indices = np.linspace(0, total_frames - 1, frames_per_video, dtype=int)\n",
    "        \n",
    "        used_frames.update(additional_indices)\n",
    "        frame_sets.append(additional_indices)\n",
    "\n",
    "    frames_data = []\n",
    "    last_handedness = {'Left': False, 'Right': False}\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    # Initialize the MediaPipe solutions\n",
    "    with mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5) as hands, \\\n",
    "         mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "        frame_count = 0\n",
    "        frame_buffer = {}\n",
    "\n",
    "        # Read and store all frames once\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_buffer[frame_count] = frame  # Buffer the frame for later processing\n",
    "            frame_count += 1\n",
    "\n",
    "        # Process the buffered frames for each sample set\n",
    "        for frame_set in frame_sets:\n",
    "            for frame_idx in frame_set:\n",
    "                if frame_idx in frame_buffer:\n",
    "                    landmarks, last_handedness = process_frame(frame_buffer[frame_idx], hands, pose, last_handedness)\n",
    "                    frames_data.append(landmarks)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Ensure the correct number of frames is collected, padding if necessary\n",
    "    required_frames = frames_per_video * (1 + num_additional_samples)\n",
    "    if len(frames_data) < required_frames:\n",
    "        if len(frames_data) > 0:\n",
    "            # Duplicate the last valid frame to fill the gap\n",
    "            frames_data.extend([frames_data[-1]] * (required_frames - len(frames_data)))\n",
    "        else:\n",
    "            # Fill with zeros if no frames were processed\n",
    "            frames_data.extend([np.zeros((num_landmarks, num_coordinates))] * required_frames)\n",
    "\n",
    "    # Reshape the data into the expected format\n",
    "    reshaped_data = np.array(frames_data).reshape((1 + num_additional_samples, frames_per_video, num_landmarks, num_coordinates))\n",
    "    \n",
    "    return reshaped_data\n",
    "\n",
    "\n",
    "def process_dataset_with_samples(root_path, handsign_names, frames_per_video, num_landmarks, num_coordinates, videos_per_handsign, num_additional_samples=0):\n",
    "    data = []\n",
    "\n",
    "    for handsign_index in tqdm(range(len(handsign_names)), desc=\"Processing handsigns\"):\n",
    "        handsign_folder = handsign_names[handsign_index]\n",
    "        handsign_path = os.path.join(root_path, handsign_folder)\n",
    "        \n",
    "        if not os.path.exists(handsign_path):\n",
    "            print(f\"Warning: Directory {handsign_path} does not exist. Skipping.\")\n",
    "            data.append(np.zeros((videos_per_handsign, frames_per_video, num_landmarks, num_coordinates)))\n",
    "            continue\n",
    "\n",
    "        videos = [f for f in os.listdir(handsign_path) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        handsign_data = []\n",
    "\n",
    "        # Calculate how many videos to process based on videos_per_handsign and num_additional_samples\n",
    "        max_videos_to_process = videos_per_handsign // (1 + num_additional_samples)\n",
    "        \n",
    "        # Process the required number of videos\n",
    "        for video in tqdm(videos[:max_videos_to_process], desc=f\"Processing videos for handsign {handsign_index}\", leave=False):\n",
    "            video_path = os.path.join(handsign_path, video)\n",
    "            \n",
    "            # Call the updated process_video_with_samples function\n",
    "            video_data = process_video_with_samples(video_path, frames_per_video, num_landmarks, num_coordinates, num_additional_samples)\n",
    "            \n",
    "            # Append all generated samples (original + additional) from the video\n",
    "            for sample in video_data:\n",
    "                handsign_data.append(sample)\n",
    "\n",
    "        handsign_data = np.array(handsign_data)\n",
    "        total_video_samples = handsign_data.shape[0]  # Total samples generated from the videos processed\n",
    "\n",
    "        # Ensure total number of video samples matches the predefined videos_per_handsign\n",
    "        if total_video_samples < videos_per_handsign:\n",
    "            padding_needed = videos_per_handsign - total_video_samples\n",
    "            print(f\"Warning: Handsign {handsign_index} ('{handsign_folder}') has only {total_video_samples} samples. \"\n",
    "                  f\"Padding with {padding_needed} empty samples.\")\n",
    "            handsign_data = np.pad(handsign_data, ((0, padding_needed), (0, 0), (0, 0), (0, 0)), mode='constant')\n",
    "        elif total_video_samples > videos_per_handsign:\n",
    "            handsign_data = handsign_data[:videos_per_handsign]\n",
    "            print(f\"Warning: More samples generated ({total_video_samples}) than expected ({videos_per_handsign}). Trimming excess samples.\")\n",
    "\n",
    "        data.append(handsign_data)\n",
    "\n",
    "    final_data = np.array(data)\n",
    "    print(f\"Final dataset shape: {final_data.shape}\")\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n"
   ],
   "id": "c6b1d3592b943838",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T03:28:46.679643Z",
     "start_time": "2024-10-18T03:28:24.372468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          PROCESS VIDEOS DATASET FUNC CALLING         ##\n",
    "data_array = process_dataset_with_samples(root_path, handsign_names, frames_per_video, num_landmarks, num_coordinates, videos_per_handsign, num_additional_samples)\n",
    "\n",
    "# Save the data array to a .npy file\n",
    "np.save('handsigns_data.npy', data_array)\n",
    "print(\"Data saved to handsigns_data.npy\")\n",
    "    "
   ],
   "id": "38b563f5e5342b66",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing handsigns:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Processing videos for handsign 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 0:  50%|█████     | 1/2 [00:04<00:04,  4.74s/it]\u001B[A\n",
      "Processing videos for handsign 0: 100%|██████████| 2/2 [00:08<00:00,  4.05s/it]\u001B[A\n",
      "Processing handsigns:  33%|███▎      | 1/3 [00:08<00:16,  8.34s/it]            \u001B[A\n",
      "Processing videos for handsign 1:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 1:  50%|█████     | 1/2 [00:03<00:03,  3.55s/it]\u001B[A\n",
      "Processing videos for handsign 1: 100%|██████████| 2/2 [00:07<00:00,  3.50s/it]\u001B[A\n",
      "Processing handsigns:  67%|██████▋   | 2/3 [00:15<00:07,  7.57s/it]            \u001B[A\n",
      "Processing videos for handsign 2:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 2:  50%|█████     | 1/2 [00:03<00:03,  3.41s/it]\u001B[A\n",
      "Processing videos for handsign 2: 100%|██████████| 2/2 [00:06<00:00,  3.42s/it]\u001B[A\n",
      "Processing handsigns: 100%|██████████| 3/3 [00:22<00:00,  7.41s/it]            \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (3, 6, 10, 51, 3)\n",
      "Data saved to handsigns_data.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:18:02.009460Z",
     "start_time": "2024-10-17T13:18:01.215784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##        DATA AUGMENTATION (OPTIONAL)        ##\n",
    "\n",
    "#Augmentation parameters\n",
    "noise_level=0.005 #for the add_noise() function\n",
    "translation_vector=np.random.uniform(-0.05, 0.05, 3) #for the apply_translation() function\n",
    "scale_factor=np.random.uniform(0.6, 1.6) #for the apply_scaling() function\n",
    "angle_degrees=np.random.uniform(-25, 25) #for the apply_rotation()\n",
    "\n",
    "\n",
    "def apply_rotation(landmarks, angle_degrees):\n",
    "    \"\"\"Rotate the landmarks in 3D space by a given angle.\"\"\"\n",
    "    angle_radians = np.radians(angle_degrees)\n",
    "    cos_angle = np.cos(angle_radians)\n",
    "    sin_angle = np.sin(angle_radians)\n",
    "\n",
    "    # Rotation around the Z-axis (you can adjust for other axes if necessary)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_angle, -sin_angle, 0],\n",
    "        [sin_angle, cos_angle, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    return np.dot(landmarks, rotation_matrix)\n",
    "\n",
    "def apply_scaling(landmarks, scale_factor):\n",
    "    \"\"\"Scale the landmarks by a given factor.\"\"\"\n",
    "    return landmarks * scale_factor\n",
    "\n",
    "def apply_translation(landmarks, translation_vector):\n",
    "    \"\"\"Translate the landmarks by a given vector (x, y, z).\"\"\"\n",
    "    return landmarks + translation_vector\n",
    "\n",
    "def add_noise(landmarks, noise_level=0.001):\n",
    "    \"\"\"Add random noise to the landmarks.\"\"\"\n",
    "    noise = np.random.normal(0, noise_level, landmarks.shape)\n",
    "    return landmarks + noise\n",
    "\n",
    "def augment_data(data_array, num_augmented_versions=5):\n",
    "    \"\"\"\n",
    "    Augment the data array by applying transformations.\n",
    "    Creates `num_augmented_versions` augmented copies of each handsign video.\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    for handsign_data in data_array:\n",
    "        augmented_handsign_data = []\n",
    "        for video_data in handsign_data:\n",
    "            augmented_videos = [video_data]  # Start with the original video data\n",
    "\n",
    "            for _ in range(num_augmented_versions):\n",
    "                augmented_video = []\n",
    "                for frame in video_data:\n",
    "                    # Apply a combination of augmentations\n",
    "                    rotated_frame = apply_rotation(frame, angle_degrees)\n",
    "                    scaled_frame = apply_scaling(rotated_frame, scale_factor)\n",
    "                    translated_frame = apply_translation(scaled_frame, translation_vector)\n",
    "                    noisy_frame = add_noise(translated_frame, noise_level)\n",
    "\n",
    "                    augmented_video.append(noisy_frame)\n",
    "                \n",
    "                augmented_videos.append(np.array(augmented_video))\n",
    "\n",
    "            # Flatten the augmented videos for each original video\n",
    "            augmented_handsign_data.extend(augmented_videos)\n",
    "\n",
    "        augmented_data.append(np.array(augmented_handsign_data))\n",
    "    \n",
    "    return np.array(augmented_data)\n",
    "\n",
    "# Load original handsigns data\n",
    "handsigns_data = np.load('handsigns_data.npy')\n",
    "\n",
    "# Apply augmentation\n",
    "if data_augmentation:\n",
    "    \n",
    "    augmented_data = augment_data(handsigns_data, num_augmented_versions)\n",
    "    \n",
    "    # Save the augmented data to a new .npy file\n",
    "    np.save('handsigns_data_augmented.npy', augmented_data)\n",
    "    \n",
    "    # Update the videos per handsign value to match the videos generated by the augmentation\n",
    "    data_array = np.load('handsigns_data_augmented.npy')\n",
    "    videos_per_handsign = data_array.shape[1]\n",
    "    \n",
    "    print(\"Augmented data saved to handsigns_data_augmented.npy, videos_per_handsign augmented by \"+str(num_augmented_versions)+\" per existing video for a total of \"+str(videos_per_handsign)+\" videos per handsign\")\n",
    "else:\n",
    "    print(\"no data augmentation was performed\")"
   ],
   "id": "d0c17cfc27c8ccac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data saved to handsigns_data_augmented.npy, videos_per_handsign augmented by 2 per existing video for a total of 657 videos per handsign\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:18:12.039231Z",
     "start_time": "2024-10-17T13:18:11.529794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          MODEL DEFINITION            ##\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Reshape, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Reshape input to (frames_per_video, num_landmarks * num_coordinates)\n",
    "new_input_shape = (frames_per_video, num_landmarks * num_coordinates)\n",
    "\n",
    "model = Sequential([\n",
    "    # Reshape layer\n",
    "    Reshape((frames_per_video, num_landmarks * num_coordinates), input_shape=(frames_per_video, num_landmarks, num_coordinates)),\n",
    "    \n",
    "    # LSTM layers with Dropout and Batch Normalization to reduce overfitting\n",
    "    LSTM(64, return_sequences=True, kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    LSTM(128, return_sequences=False, kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    # Fully connected layer\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    # Output layer for multi-class classification\n",
    "    Dense(num_handsigns, activation='softmax')  # Softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Specify a learning rate\n",
    "learning_rate = 0.0005\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model.summary() # Uncomment if you want to see the model summary\n"
   ],
   "id": "c1f9d72562ce0728",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-17T13:18:19.028360Z",
     "start_time": "2024-10-17T13:18:17.145895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##        DATA PREPROCESSING FOR TRAINING            ##\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# Load the data from the .npy file, making a copy to use for training as to not modify the original extracted data\n",
    "if data_augmentation:\n",
    "    shutil.copy('handsigns_data_augmented.npy', 'handsigns_data_training_copy.npy')\n",
    "    data_array = np.load('handsigns_data_training_copy.npy')\n",
    "    \n",
    "    # Update videos_per_handsign based on augmentation\n",
    "    #videos_per_handsign = data_array.shape[1]  # Dynamically update based on the new augmented shape\n",
    "    print(\"using handsigns_data_augmented.npy. After augmentation videos per handsign updated to: \" + str(data_array.shape[1]))\n",
    "else:\n",
    "    shutil.copy('handsigns_data.npy', 'handsigns_data_training_copy.npy')\n",
    "    data_array = np.load('handsigns_data_training_copy.npy')\n",
    "\n",
    "print('Array used shape: ',data_array.shape)\n",
    "# X remains unchanged\n",
    "X = data_array \n",
    "\n",
    "# Create labels for each handsign (0 to num_handsigns-1)\n",
    "# This creates a label for each hand sign, repeated for each video\n",
    "y = np.repeat(np.arange(num_handsigns), videos_per_handsign)\n",
    "y = y.reshape(num_handsigns, videos_per_handsign)\n",
    "\n",
    "# Initialize lists to hold training and validation data\n",
    "X_train_list = []\n",
    "X_val_list = []\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "\n",
    "# Split videos and labels for each handsign\n",
    "for handsign_index in range(num_handsigns):\n",
    "    # Split the videos within each handsign\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        np.arange(videos_per_handsign), \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Select training and validation data for this handsign\n",
    "    X_train_list.append(data_array[handsign_index, train_indices])\n",
    "    X_val_list.append(data_array[handsign_index, val_indices])\n",
    "    \n",
    "    # Select corresponding labels\n",
    "    y_train_list.append(y[handsign_index, train_indices])\n",
    "    y_val_list.append(y[handsign_index, val_indices])\n",
    "\n",
    "# Concatenate lists to form the final training and validation sets\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "X_val = np.concatenate(X_val_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "y_val = np.concatenate(y_val_list, axis=0)\n",
    "\n",
    "# Reshape X_train and X_val to fit the model's expected input shape\n",
    "X_train = X_train.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "X_val = X_val.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "\n",
    "# Flatten y_train and y_val\n",
    "y_train = y_train.flatten()\n",
    "y_val = y_val.flatten()"
   ],
   "id": "664f881d08e116f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using handsigns_data_augmented.npy. After augmentation videos per handsign updated to: 657\n",
      "Array used shape:  (10, 657, 10, 51, 3)\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:21:28.088387Z",
     "start_time": "2024-10-17T13:18:30.287457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          MODEL TRAINING          ##\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Callback helpers for model training #\n",
    "# Early stopping to stop training when validation loss stops improving\n",
    "# Model checkpointing to save the best model during training\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)  \n",
    "checkpoint = ModelCheckpoint('best_handsigns_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)  \n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[early_stopping, checkpoint, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "model.save('handsigns_model.h5')\n",
    "\n",
    "# Optionally, save the training history\n",
    "import pickle\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "    \n",
    "\n",
    "    \n",
    "##          TRAINING HISTORY ANALYSIS           ##\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# If you want to save the plot instead of displaying it:\n",
    "# plt.savefig('training_history.png')"
   ],
   "id": "febb1178fa7e41a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.1427 - loss: 20.6074\n",
      "Epoch 1: val_loss improved from inf to 13.05329, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 10ms/step - accuracy: 0.1436 - loss: 20.5310 - val_accuracy: 0.2742 - val_loss: 13.0533 - learning_rate: 5.0000e-04\n",
      "Epoch 2/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.2344 - loss: 12.8604\n",
      "Epoch 2: val_loss improved from 13.05329 to 9.19279, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.2357 - loss: 12.8095 - val_accuracy: 0.4970 - val_loss: 9.1928 - learning_rate: 5.0000e-04\n",
      "Epoch 3/500\n",
      "\u001B[1m157/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.3199 - loss: 9.2173\n",
      "Epoch 3: val_loss improved from 9.19279 to 6.75784, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.3204 - loss: 9.1832 - val_accuracy: 0.5447 - val_loss: 6.7578 - learning_rate: 5.0000e-04\n",
      "Epoch 4/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.3828 - loss: 6.8865\n",
      "Epoch 4: val_loss improved from 6.75784 to 5.16415, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.3830 - loss: 6.8673 - val_accuracy: 0.5879 - val_loss: 5.1641 - learning_rate: 5.0000e-04\n",
      "Epoch 5/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4238 - loss: 5.3417\n",
      "Epoch 5: val_loss improved from 5.16415 to 4.06165, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 8ms/step - accuracy: 0.4239 - loss: 5.3382 - val_accuracy: 0.6348 - val_loss: 4.0616 - learning_rate: 5.0000e-04\n",
      "Epoch 6/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.4565 - loss: 4.3348\n",
      "Epoch 6: val_loss improved from 4.06165 to 3.32175, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.4571 - loss: 4.3283 - val_accuracy: 0.6674 - val_loss: 3.3217 - learning_rate: 5.0000e-04\n",
      "Epoch 7/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.4977 - loss: 3.6141\n",
      "Epoch 7: val_loss improved from 3.32175 to 2.79382, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.4982 - loss: 3.6098 - val_accuracy: 0.6871 - val_loss: 2.7938 - learning_rate: 5.0000e-04\n",
      "Epoch 8/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5688 - loss: 2.9792\n",
      "Epoch 8: val_loss improved from 2.79382 to 2.31019, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.5688 - loss: 2.9774 - val_accuracy: 0.7333 - val_loss: 2.3102 - learning_rate: 5.0000e-04\n",
      "Epoch 9/500\n",
      "\u001B[1m156/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5880 - loss: 2.5936\n",
      "Epoch 9: val_loss improved from 2.31019 to 2.22879, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5886 - loss: 2.5884 - val_accuracy: 0.6409 - val_loss: 2.2288 - learning_rate: 5.0000e-04\n",
      "Epoch 10/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5417 - loss: 2.5112\n",
      "Epoch 10: val_loss improved from 2.22879 to 1.89761, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5424 - loss: 2.5085 - val_accuracy: 0.7311 - val_loss: 1.8976 - learning_rate: 5.0000e-04\n",
      "Epoch 11/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5528 - loss: 2.3756\n",
      "Epoch 11: val_loss improved from 1.89761 to 1.74193, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.5545 - loss: 2.3690 - val_accuracy: 0.7326 - val_loss: 1.7419 - learning_rate: 5.0000e-04\n",
      "Epoch 12/500\n",
      "\u001B[1m157/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6434 - loss: 1.9895\n",
      "Epoch 12: val_loss improved from 1.74193 to 1.57000, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.6434 - loss: 1.9871 - val_accuracy: 0.7508 - val_loss: 1.5700 - learning_rate: 5.0000e-04\n",
      "Epoch 13/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6302 - loss: 1.9310\n",
      "Epoch 13: val_loss improved from 1.57000 to 1.43311, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.6306 - loss: 1.9290 - val_accuracy: 0.7576 - val_loss: 1.4331 - learning_rate: 5.0000e-04\n",
      "Epoch 14/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6676 - loss: 1.7148\n",
      "Epoch 14: val_loss improved from 1.43311 to 1.36857, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.6677 - loss: 1.7142 - val_accuracy: 0.7591 - val_loss: 1.3686 - learning_rate: 5.0000e-04\n",
      "Epoch 15/500\n",
      "\u001B[1m160/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.6779 - loss: 1.6078\n",
      "Epoch 15: val_loss improved from 1.36857 to 1.24731, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.6783 - loss: 1.6061 - val_accuracy: 0.7614 - val_loss: 1.2473 - learning_rate: 5.0000e-04\n",
      "Epoch 16/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6971 - loss: 1.4890\n",
      "Epoch 16: val_loss did not improve from 1.24731\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.6969 - loss: 1.4887 - val_accuracy: 0.7417 - val_loss: 1.2738 - learning_rate: 5.0000e-04\n",
      "Epoch 17/500\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6768 - loss: 1.4653\n",
      "Epoch 17: val_loss did not improve from 1.24731\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.6768 - loss: 1.4652 - val_accuracy: 0.6061 - val_loss: 1.8490 - learning_rate: 5.0000e-04\n",
      "Epoch 18/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6336 - loss: 1.6794\n",
      "Epoch 18: val_loss did not improve from 1.24731\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.6349 - loss: 1.6739 - val_accuracy: 0.7265 - val_loss: 1.2787 - learning_rate: 5.0000e-04\n",
      "Epoch 19/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6894 - loss: 1.4640\n",
      "Epoch 19: val_loss improved from 1.24731 to 1.08838, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.6894 - loss: 1.4629 - val_accuracy: 0.7811 - val_loss: 1.0884 - learning_rate: 5.0000e-04\n",
      "Epoch 20/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7160 - loss: 1.3213\n",
      "Epoch 20: val_loss did not improve from 1.08838\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.7163 - loss: 1.3200 - val_accuracy: 0.7492 - val_loss: 1.1597 - learning_rate: 5.0000e-04\n",
      "Epoch 21/500\n",
      "\u001B[1m157/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7096 - loss: 1.2765\n",
      "Epoch 21: val_loss improved from 1.08838 to 0.96888, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.7104 - loss: 1.2741 - val_accuracy: 0.7962 - val_loss: 0.9689 - learning_rate: 5.0000e-04\n",
      "Epoch 22/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7072 - loss: 1.2622\n",
      "Epoch 22: val_loss did not improve from 0.96888\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.7074 - loss: 1.2616 - val_accuracy: 0.7758 - val_loss: 1.0259 - learning_rate: 5.0000e-04\n",
      "Epoch 23/500\n",
      "\u001B[1m156/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7167 - loss: 1.2212\n",
      "Epoch 23: val_loss did not improve from 0.96888\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.7171 - loss: 1.2201 - val_accuracy: 0.7818 - val_loss: 1.0221 - learning_rate: 5.0000e-04\n",
      "Epoch 24/500\n",
      "\u001B[1m155/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6628 - loss: 1.4719\n",
      "Epoch 24: val_loss did not improve from 0.96888\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.6646 - loss: 1.4648 - val_accuracy: 0.7583 - val_loss: 1.0546 - learning_rate: 5.0000e-04\n",
      "Epoch 25/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6899 - loss: 1.3558\n",
      "Epoch 25: val_loss did not improve from 0.96888\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6907 - loss: 1.3532 - val_accuracy: 0.7189 - val_loss: 1.1645 - learning_rate: 5.0000e-04\n",
      "Epoch 26/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7388 - loss: 1.1703\n",
      "Epoch 26: val_loss improved from 0.96888 to 0.93301, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.7385 - loss: 1.1702 - val_accuracy: 0.7970 - val_loss: 0.9330 - learning_rate: 5.0000e-04\n",
      "Epoch 27/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7555 - loss: 1.1072\n",
      "Epoch 27: val_loss did not improve from 0.93301\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.7551 - loss: 1.1079 - val_accuracy: 0.7614 - val_loss: 1.0030 - learning_rate: 5.0000e-04\n",
      "Epoch 28/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6704 - loss: 1.4387\n",
      "Epoch 28: val_loss improved from 0.93301 to 0.91501, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.6717 - loss: 1.4328 - val_accuracy: 0.8023 - val_loss: 0.9150 - learning_rate: 5.0000e-04\n",
      "Epoch 29/500\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7510 - loss: 1.0986\n",
      "Epoch 29: val_loss improved from 0.91501 to 0.91439, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.7509 - loss: 1.0987 - val_accuracy: 0.7985 - val_loss: 0.9144 - learning_rate: 5.0000e-04\n",
      "Epoch 30/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7445 - loss: 1.1098\n",
      "Epoch 30: val_loss did not improve from 0.91439\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.7445 - loss: 1.1094 - val_accuracy: 0.7894 - val_loss: 0.9715 - learning_rate: 5.0000e-04\n",
      "Epoch 31/500\n",
      "\u001B[1m156/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7289 - loss: 1.1929\n",
      "Epoch 31: val_loss improved from 0.91439 to 0.86948, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.7294 - loss: 1.1897 - val_accuracy: 0.8205 - val_loss: 0.8695 - learning_rate: 5.0000e-04\n",
      "Epoch 32/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7754 - loss: 1.0149\n",
      "Epoch 32: val_loss did not improve from 0.86948\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.7749 - loss: 1.0152 - val_accuracy: 0.7902 - val_loss: 0.8800 - learning_rate: 5.0000e-04\n",
      "Epoch 33/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7563 - loss: 1.0231\n",
      "Epoch 33: val_loss improved from 0.86948 to 0.84309, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.7568 - loss: 1.0221 - val_accuracy: 0.8098 - val_loss: 0.8431 - learning_rate: 5.0000e-04\n",
      "Epoch 34/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.7594 - loss: 1.0844\n",
      "Epoch 34: val_loss improved from 0.84309 to 0.84218, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.7594 - loss: 1.0840 - val_accuracy: 0.8053 - val_loss: 0.8422 - learning_rate: 5.0000e-04\n",
      "Epoch 35/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.7631 - loss: 1.0167\n",
      "Epoch 35: val_loss did not improve from 0.84218\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.7629 - loss: 1.0177 - val_accuracy: 0.8159 - val_loss: 0.8445 - learning_rate: 5.0000e-04\n",
      "Epoch 36/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7824 - loss: 0.9952\n",
      "Epoch 36: val_loss did not improve from 0.84218\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.7816 - loss: 0.9968 - val_accuracy: 0.7962 - val_loss: 0.9009 - learning_rate: 5.0000e-04\n",
      "Epoch 37/500\n",
      "\u001B[1m153/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7541 - loss: 1.0293\n",
      "Epoch 37: val_loss improved from 0.84218 to 0.80762, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.7558 - loss: 1.0257 - val_accuracy: 0.8159 - val_loss: 0.8076 - learning_rate: 5.0000e-04\n",
      "Epoch 38/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7726 - loss: 1.0105\n",
      "Epoch 38: val_loss did not improve from 0.80762\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7726 - loss: 1.0100 - val_accuracy: 0.6644 - val_loss: 1.3761 - learning_rate: 5.0000e-04\n",
      "Epoch 39/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.6831 - loss: 1.2569\n",
      "Epoch 39: val_loss did not improve from 0.80762\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.6846 - loss: 1.2535 - val_accuracy: 0.6894 - val_loss: 1.1943 - learning_rate: 5.0000e-04\n",
      "Epoch 40/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7358 - loss: 1.2118\n",
      "Epoch 40: val_loss did not improve from 0.80762\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.7363 - loss: 1.2093 - val_accuracy: 0.7136 - val_loss: 1.1716 - learning_rate: 5.0000e-04\n",
      "Epoch 41/500\n",
      "\u001B[1m156/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7279 - loss: 1.2503\n",
      "Epoch 41: val_loss did not improve from 0.80762\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.7296 - loss: 1.2434 - val_accuracy: 0.8402 - val_loss: 0.8109 - learning_rate: 5.0000e-04\n",
      "Epoch 42/500\n",
      "\u001B[1m160/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7650 - loss: 1.0576\n",
      "Epoch 42: val_loss improved from 0.80762 to 0.79881, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.7653 - loss: 1.0561 - val_accuracy: 0.8197 - val_loss: 0.7988 - learning_rate: 5.0000e-04\n",
      "Epoch 43/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7999 - loss: 0.9283\n",
      "Epoch 43: val_loss improved from 0.79881 to 0.77360, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.7994 - loss: 0.9296 - val_accuracy: 0.8348 - val_loss: 0.7736 - learning_rate: 5.0000e-04\n",
      "Epoch 44/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7778 - loss: 1.0047\n",
      "Epoch 44: val_loss did not improve from 0.77360\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7777 - loss: 1.0044 - val_accuracy: 0.8197 - val_loss: 0.8084 - learning_rate: 5.0000e-04\n",
      "Epoch 45/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8040 - loss: 0.8876\n",
      "Epoch 45: val_loss did not improve from 0.77360\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8038 - loss: 0.8881 - val_accuracy: 0.7735 - val_loss: 0.9216 - learning_rate: 5.0000e-04\n",
      "Epoch 46/500\n",
      "\u001B[1m160/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7936 - loss: 0.9236\n",
      "Epoch 46: val_loss did not improve from 0.77360\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7931 - loss: 0.9248 - val_accuracy: 0.7894 - val_loss: 0.8504 - learning_rate: 5.0000e-04\n",
      "Epoch 47/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7947 - loss: 0.9164\n",
      "Epoch 47: val_loss did not improve from 0.77360\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.7946 - loss: 0.9170 - val_accuracy: 0.5742 - val_loss: 2.0853 - learning_rate: 5.0000e-04\n",
      "Epoch 48/500\n",
      "\u001B[1m160/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.5722 - loss: 1.8932\n",
      "Epoch 48: val_loss did not improve from 0.77360\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.5746 - loss: 1.8828 - val_accuracy: 0.7712 - val_loss: 1.0310 - learning_rate: 5.0000e-04\n",
      "Epoch 49/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7366 - loss: 1.2305\n",
      "Epoch 49: val_loss did not improve from 0.77360\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7369 - loss: 1.2287 - val_accuracy: 0.8098 - val_loss: 0.8856 - learning_rate: 2.5000e-04\n",
      "Epoch 50/500\n",
      "\u001B[1m160/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7835 - loss: 1.0270\n",
      "Epoch 50: val_loss did not improve from 0.77360\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7836 - loss: 1.0264 - val_accuracy: 0.8212 - val_loss: 0.8092 - learning_rate: 2.5000e-04\n",
      "Epoch 51/500\n",
      "\u001B[1m153/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7760 - loss: 0.9946\n",
      "Epoch 51: val_loss did not improve from 0.77360\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7774 - loss: 0.9920 - val_accuracy: 0.8023 - val_loss: 0.8351 - learning_rate: 2.5000e-04\n",
      "Epoch 52/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8132 - loss: 0.9057\n",
      "Epoch 52: val_loss improved from 0.77360 to 0.75314, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8131 - loss: 0.9056 - val_accuracy: 0.8386 - val_loss: 0.7531 - learning_rate: 2.5000e-04\n",
      "Epoch 53/500\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7770 - loss: 0.9851\n",
      "Epoch 53: val_loss improved from 0.75314 to 0.67915, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7771 - loss: 0.9848 - val_accuracy: 0.8591 - val_loss: 0.6792 - learning_rate: 2.5000e-04\n",
      "Epoch 54/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8033 - loss: 0.8979\n",
      "Epoch 54: val_loss did not improve from 0.67915\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8035 - loss: 0.8973 - val_accuracy: 0.8386 - val_loss: 0.7318 - learning_rate: 2.5000e-04\n",
      "Epoch 55/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7784 - loss: 0.9669\n",
      "Epoch 55: val_loss did not improve from 0.67915\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.7788 - loss: 0.9655 - val_accuracy: 0.8500 - val_loss: 0.7001 - learning_rate: 2.5000e-04\n",
      "Epoch 56/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8088 - loss: 0.8716\n",
      "Epoch 56: val_loss did not improve from 0.67915\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8088 - loss: 0.8714 - val_accuracy: 0.8364 - val_loss: 0.7118 - learning_rate: 2.5000e-04\n",
      "Epoch 57/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8104 - loss: 0.8368\n",
      "Epoch 57: val_loss did not improve from 0.67915\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8109 - loss: 0.8354 - val_accuracy: 0.8167 - val_loss: 0.7372 - learning_rate: 2.5000e-04\n",
      "Epoch 58/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8159 - loss: 0.8200\n",
      "Epoch 58: val_loss did not improve from 0.67915\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8158 - loss: 0.8197 - val_accuracy: 0.8439 - val_loss: 0.7008 - learning_rate: 2.5000e-04\n",
      "Epoch 59/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8138 - loss: 0.8163\n",
      "Epoch 59: val_loss improved from 0.67915 to 0.57636, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8141 - loss: 0.8157 - val_accuracy: 0.8765 - val_loss: 0.5764 - learning_rate: 1.2500e-04\n",
      "Epoch 60/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8417 - loss: 0.7384\n",
      "Epoch 60: val_loss did not improve from 0.57636\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8416 - loss: 0.7388 - val_accuracy: 0.8720 - val_loss: 0.6021 - learning_rate: 1.2500e-04\n",
      "Epoch 61/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7820 - loss: 0.9203\n",
      "Epoch 61: val_loss did not improve from 0.57636\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.7831 - loss: 0.9168 - val_accuracy: 0.8674 - val_loss: 0.5866 - learning_rate: 1.2500e-04\n",
      "Epoch 62/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8363 - loss: 0.7534\n",
      "Epoch 62: val_loss improved from 0.57636 to 0.57628, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8362 - loss: 0.7534 - val_accuracy: 0.8742 - val_loss: 0.5763 - learning_rate: 1.2500e-04\n",
      "Epoch 63/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8442 - loss: 0.7104\n",
      "Epoch 63: val_loss improved from 0.57628 to 0.55463, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8440 - loss: 0.7109 - val_accuracy: 0.8803 - val_loss: 0.5546 - learning_rate: 1.2500e-04\n",
      "Epoch 64/500\n",
      "\u001B[1m153/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8463 - loss: 0.7142\n",
      "Epoch 64: val_loss did not improve from 0.55463\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8459 - loss: 0.7143 - val_accuracy: 0.8591 - val_loss: 0.5828 - learning_rate: 1.2500e-04\n",
      "Epoch 65/500\n",
      "\u001B[1m160/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8400 - loss: 0.7053\n",
      "Epoch 65: val_loss did not improve from 0.55463\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8401 - loss: 0.7049 - val_accuracy: 0.8674 - val_loss: 0.5830 - learning_rate: 1.2500e-04\n",
      "Epoch 66/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8477 - loss: 0.7012\n",
      "Epoch 66: val_loss did not improve from 0.55463\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8478 - loss: 0.7010 - val_accuracy: 0.8386 - val_loss: 0.6516 - learning_rate: 1.2500e-04\n",
      "Epoch 67/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8469 - loss: 0.6803\n",
      "Epoch 67: val_loss improved from 0.55463 to 0.53062, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8472 - loss: 0.6800 - val_accuracy: 0.8932 - val_loss: 0.5306 - learning_rate: 1.2500e-04\n",
      "Epoch 68/500\n",
      "\u001B[1m160/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8525 - loss: 0.7036\n",
      "Epoch 68: val_loss did not improve from 0.53062\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8527 - loss: 0.7023 - val_accuracy: 0.8455 - val_loss: 0.6341 - learning_rate: 1.2500e-04\n",
      "Epoch 69/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8492 - loss: 0.6729\n",
      "Epoch 69: val_loss did not improve from 0.53062\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8491 - loss: 0.6729 - val_accuracy: 0.8485 - val_loss: 0.6579 - learning_rate: 1.2500e-04\n",
      "Epoch 70/500\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8408 - loss: 0.7129\n",
      "Epoch 70: val_loss improved from 0.53062 to 0.51941, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.8408 - loss: 0.7127 - val_accuracy: 0.8894 - val_loss: 0.5194 - learning_rate: 1.2500e-04\n",
      "Epoch 71/500\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8443 - loss: 0.6817\n",
      "Epoch 71: val_loss did not improve from 0.51941\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8443 - loss: 0.6817 - val_accuracy: 0.8879 - val_loss: 0.5301 - learning_rate: 1.2500e-04\n",
      "Epoch 72/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8439 - loss: 0.6637\n",
      "Epoch 72: val_loss improved from 0.51941 to 0.50550, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.8440 - loss: 0.6635 - val_accuracy: 0.8856 - val_loss: 0.5055 - learning_rate: 1.2500e-04\n",
      "Epoch 73/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8457 - loss: 0.7001\n",
      "Epoch 73: val_loss did not improve from 0.50550\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8457 - loss: 0.6998 - val_accuracy: 0.8788 - val_loss: 0.5320 - learning_rate: 1.2500e-04\n",
      "Epoch 74/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8548 - loss: 0.6349\n",
      "Epoch 74: val_loss improved from 0.50550 to 0.49784, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8549 - loss: 0.6349 - val_accuracy: 0.8917 - val_loss: 0.4978 - learning_rate: 1.2500e-04\n",
      "Epoch 75/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8532 - loss: 0.6429\n",
      "Epoch 75: val_loss did not improve from 0.49784\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8531 - loss: 0.6428 - val_accuracy: 0.8742 - val_loss: 0.5387 - learning_rate: 1.2500e-04\n",
      "Epoch 76/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8467 - loss: 0.6640\n",
      "Epoch 76: val_loss did not improve from 0.49784\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8468 - loss: 0.6637 - val_accuracy: 0.8833 - val_loss: 0.5218 - learning_rate: 1.2500e-04\n",
      "Epoch 77/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8490 - loss: 0.6507\n",
      "Epoch 77: val_loss did not improve from 0.49784\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8490 - loss: 0.6510 - val_accuracy: 0.8742 - val_loss: 0.5254 - learning_rate: 1.2500e-04\n",
      "Epoch 78/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8400 - loss: 0.6661\n",
      "Epoch 78: val_loss did not improve from 0.49784\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8402 - loss: 0.6659 - val_accuracy: 0.8803 - val_loss: 0.5010 - learning_rate: 1.2500e-04\n",
      "Epoch 79/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8571 - loss: 0.6285\n",
      "Epoch 79: val_loss improved from 0.49784 to 0.47185, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8571 - loss: 0.6284 - val_accuracy: 0.9015 - val_loss: 0.4719 - learning_rate: 1.2500e-04\n",
      "Epoch 80/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8622 - loss: 0.6271\n",
      "Epoch 80: val_loss did not improve from 0.47185\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8621 - loss: 0.6270 - val_accuracy: 0.8939 - val_loss: 0.4955 - learning_rate: 1.2500e-04\n",
      "Epoch 81/500\n",
      "\u001B[1m157/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8632 - loss: 0.6080\n",
      "Epoch 81: val_loss did not improve from 0.47185\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8630 - loss: 0.6082 - val_accuracy: 0.8795 - val_loss: 0.5265 - learning_rate: 1.2500e-04\n",
      "Epoch 82/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8617 - loss: 0.6022\n",
      "Epoch 82: val_loss did not improve from 0.47185\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8617 - loss: 0.6023 - val_accuracy: 0.8697 - val_loss: 0.5469 - learning_rate: 1.2500e-04\n",
      "Epoch 83/500\n",
      "\u001B[1m156/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8411 - loss: 0.6841\n",
      "Epoch 83: val_loss did not improve from 0.47185\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8419 - loss: 0.6816 - val_accuracy: 0.8811 - val_loss: 0.5093 - learning_rate: 1.2500e-04\n",
      "Epoch 84/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8467 - loss: 0.6708\n",
      "Epoch 84: val_loss did not improve from 0.47185\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8468 - loss: 0.6707 - val_accuracy: 0.8689 - val_loss: 0.5476 - learning_rate: 1.2500e-04\n",
      "Epoch 85/500\n",
      "\u001B[1m160/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8576 - loss: 0.6274\n",
      "Epoch 85: val_loss did not improve from 0.47185\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8579 - loss: 0.6267 - val_accuracy: 0.8947 - val_loss: 0.4779 - learning_rate: 6.2500e-05\n",
      "Epoch 86/500\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8744 - loss: 0.5735\n",
      "Epoch 86: val_loss did not improve from 0.47185\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8743 - loss: 0.5736 - val_accuracy: 0.9008 - val_loss: 0.4767 - learning_rate: 6.2500e-05\n",
      "Epoch 87/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8551 - loss: 0.6691\n",
      "Epoch 87: val_loss improved from 0.47185 to 0.45863, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8551 - loss: 0.6686 - val_accuracy: 0.8970 - val_loss: 0.4586 - learning_rate: 6.2500e-05\n",
      "Epoch 88/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8711 - loss: 0.5939\n",
      "Epoch 88: val_loss improved from 0.45863 to 0.45244, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8711 - loss: 0.5937 - val_accuracy: 0.8992 - val_loss: 0.4524 - learning_rate: 6.2500e-05\n",
      "Epoch 89/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8708 - loss: 0.5819\n",
      "Epoch 89: val_loss improved from 0.45244 to 0.43887, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8710 - loss: 0.5816 - val_accuracy: 0.9106 - val_loss: 0.4389 - learning_rate: 6.2500e-05\n",
      "Epoch 90/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8785 - loss: 0.5653\n",
      "Epoch 90: val_loss did not improve from 0.43887\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8784 - loss: 0.5653 - val_accuracy: 0.9015 - val_loss: 0.4447 - learning_rate: 6.2500e-05\n",
      "Epoch 91/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8620 - loss: 0.5929\n",
      "Epoch 91: val_loss did not improve from 0.43887\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.8621 - loss: 0.5927 - val_accuracy: 0.9061 - val_loss: 0.4431 - learning_rate: 6.2500e-05\n",
      "Epoch 92/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8450 - loss: 0.6597\n",
      "Epoch 92: val_loss did not improve from 0.43887\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8457 - loss: 0.6578 - val_accuracy: 0.9008 - val_loss: 0.4652 - learning_rate: 6.2500e-05\n",
      "Epoch 93/500\n",
      "\u001B[1m157/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8724 - loss: 0.5862\n",
      "Epoch 93: val_loss did not improve from 0.43887\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8725 - loss: 0.5852 - val_accuracy: 0.8962 - val_loss: 0.4586 - learning_rate: 6.2500e-05\n",
      "Epoch 94/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8666 - loss: 0.5773\n",
      "Epoch 94: val_loss did not improve from 0.43887\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8668 - loss: 0.5769 - val_accuracy: 0.9061 - val_loss: 0.4501 - learning_rate: 6.2500e-05\n",
      "Epoch 95/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8618 - loss: 0.5813\n",
      "Epoch 95: val_loss improved from 0.43887 to 0.43262, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8622 - loss: 0.5810 - val_accuracy: 0.9106 - val_loss: 0.4326 - learning_rate: 3.1250e-05\n",
      "Epoch 96/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8694 - loss: 0.5697\n",
      "Epoch 96: val_loss improved from 0.43262 to 0.41931, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8695 - loss: 0.5696 - val_accuracy: 0.9106 - val_loss: 0.4193 - learning_rate: 3.1250e-05\n",
      "Epoch 97/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8859 - loss: 0.5588\n",
      "Epoch 97: val_loss did not improve from 0.41931\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8859 - loss: 0.5583 - val_accuracy: 0.9152 - val_loss: 0.4223 - learning_rate: 3.1250e-05\n",
      "Epoch 98/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8913 - loss: 0.5312\n",
      "Epoch 98: val_loss did not improve from 0.41931\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8911 - loss: 0.5316 - val_accuracy: 0.9076 - val_loss: 0.4353 - learning_rate: 3.1250e-05\n",
      "Epoch 99/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8898 - loss: 0.5169\n",
      "Epoch 99: val_loss did not improve from 0.41931\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8898 - loss: 0.5170 - val_accuracy: 0.9098 - val_loss: 0.4274 - learning_rate: 3.1250e-05\n",
      "Epoch 100/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8834 - loss: 0.5254\n",
      "Epoch 100: val_loss did not improve from 0.41931\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8833 - loss: 0.5256 - val_accuracy: 0.9167 - val_loss: 0.4211 - learning_rate: 3.1250e-05\n",
      "Epoch 101/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8887 - loss: 0.5330\n",
      "Epoch 101: val_loss did not improve from 0.41931\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8887 - loss: 0.5330 - val_accuracy: 0.9121 - val_loss: 0.4251 - learning_rate: 3.1250e-05\n",
      "Epoch 102/500\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8779 - loss: 0.5426\n",
      "Epoch 102: val_loss improved from 0.41931 to 0.41572, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8779 - loss: 0.5426 - val_accuracy: 0.9129 - val_loss: 0.4157 - learning_rate: 1.5625e-05\n",
      "Epoch 103/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8773 - loss: 0.5288\n",
      "Epoch 103: val_loss improved from 0.41572 to 0.40492, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8774 - loss: 0.5289 - val_accuracy: 0.9152 - val_loss: 0.4049 - learning_rate: 1.5625e-05\n",
      "Epoch 104/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8757 - loss: 0.5470\n",
      "Epoch 104: val_loss did not improve from 0.40492\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8759 - loss: 0.5466 - val_accuracy: 0.9136 - val_loss: 0.4088 - learning_rate: 1.5625e-05\n",
      "Epoch 105/500\n",
      "\u001B[1m154/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8833 - loss: 0.5243\n",
      "Epoch 105: val_loss improved from 0.40492 to 0.40428, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8836 - loss: 0.5239 - val_accuracy: 0.9182 - val_loss: 0.4043 - learning_rate: 1.5625e-05\n",
      "Epoch 106/500\n",
      "\u001B[1m158/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8846 - loss: 0.5324\n",
      "Epoch 106: val_loss did not improve from 0.40428\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8848 - loss: 0.5319 - val_accuracy: 0.9129 - val_loss: 0.4084 - learning_rate: 1.5625e-05\n",
      "Epoch 107/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8792 - loss: 0.5331\n",
      "Epoch 107: val_loss did not improve from 0.40428\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8793 - loss: 0.5329 - val_accuracy: 0.9174 - val_loss: 0.4054 - learning_rate: 1.5625e-05\n",
      "Epoch 108/500\n",
      "\u001B[1m157/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8724 - loss: 0.5530\n",
      "Epoch 108: val_loss did not improve from 0.40428\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8728 - loss: 0.5522 - val_accuracy: 0.9114 - val_loss: 0.4085 - learning_rate: 1.5625e-05\n",
      "Epoch 109/500\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8864 - loss: 0.5221\n",
      "Epoch 109: val_loss did not improve from 0.40428\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8864 - loss: 0.5221 - val_accuracy: 0.9167 - val_loss: 0.4050 - learning_rate: 1.5625e-05\n",
      "Epoch 110/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8825 - loss: 0.5350\n",
      "Epoch 110: val_loss did not improve from 0.40428\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8826 - loss: 0.5349 - val_accuracy: 0.9189 - val_loss: 0.4057 - learning_rate: 1.5625e-05\n",
      "Epoch 111/500\n",
      "\u001B[1m156/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8916 - loss: 0.5034\n",
      "Epoch 111: val_loss did not improve from 0.40428\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8911 - loss: 0.5042 - val_accuracy: 0.9167 - val_loss: 0.4048 - learning_rate: 7.8125e-06\n",
      "Epoch 112/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8826 - loss: 0.5323\n",
      "Epoch 112: val_loss improved from 0.40428 to 0.40173, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8828 - loss: 0.5317 - val_accuracy: 0.9167 - val_loss: 0.4017 - learning_rate: 7.8125e-06\n",
      "Epoch 113/500\n",
      "\u001B[1m153/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8863 - loss: 0.5261\n",
      "Epoch 113: val_loss improved from 0.40173 to 0.39877, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8864 - loss: 0.5255 - val_accuracy: 0.9159 - val_loss: 0.3988 - learning_rate: 7.8125e-06\n",
      "Epoch 114/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8858 - loss: 0.5246\n",
      "Epoch 114: val_loss did not improve from 0.39877\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8860 - loss: 0.5243 - val_accuracy: 0.9174 - val_loss: 0.3994 - learning_rate: 7.8125e-06\n",
      "Epoch 115/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8864 - loss: 0.5313\n",
      "Epoch 115: val_loss did not improve from 0.39877\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8863 - loss: 0.5313 - val_accuracy: 0.9152 - val_loss: 0.3999 - learning_rate: 7.8125e-06\n",
      "Epoch 116/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8912 - loss: 0.5209\n",
      "Epoch 116: val_loss did not improve from 0.39877\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.8911 - loss: 0.5206 - val_accuracy: 0.9144 - val_loss: 0.4024 - learning_rate: 7.8125e-06\n",
      "Epoch 117/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8912 - loss: 0.5088\n",
      "Epoch 117: val_loss improved from 0.39877 to 0.39532, saving model to best_handsigns_model.keras\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8912 - loss: 0.5088 - val_accuracy: 0.9159 - val_loss: 0.3953 - learning_rate: 7.8125e-06\n",
      "Epoch 118/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8935 - loss: 0.4993\n",
      "Epoch 118: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8934 - loss: 0.4995 - val_accuracy: 0.9182 - val_loss: 0.3962 - learning_rate: 7.8125e-06\n",
      "Epoch 119/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8836 - loss: 0.5138\n",
      "Epoch 119: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8837 - loss: 0.5138 - val_accuracy: 0.9159 - val_loss: 0.4032 - learning_rate: 7.8125e-06\n",
      "Epoch 120/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8891 - loss: 0.5050\n",
      "Epoch 120: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.8888 - loss: 0.5055 - val_accuracy: 0.9152 - val_loss: 0.3991 - learning_rate: 7.8125e-06\n",
      "Epoch 121/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8908 - loss: 0.5044\n",
      "Epoch 121: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.8909 - loss: 0.5045 - val_accuracy: 0.9129 - val_loss: 0.4040 - learning_rate: 7.8125e-06\n",
      "Epoch 122/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8957 - loss: 0.5052\n",
      "Epoch 122: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.8957 - loss: 0.5052 - val_accuracy: 0.9174 - val_loss: 0.3961 - learning_rate: 7.8125e-06\n",
      "Epoch 123/500\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8855 - loss: 0.5119\n",
      "Epoch 123: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.8855 - loss: 0.5119 - val_accuracy: 0.9136 - val_loss: 0.3997 - learning_rate: 3.9063e-06\n",
      "Epoch 124/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8949 - loss: 0.5134\n",
      "Epoch 124: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.8948 - loss: 0.5135 - val_accuracy: 0.9167 - val_loss: 0.3973 - learning_rate: 3.9063e-06\n",
      "Epoch 125/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8784 - loss: 0.5260\n",
      "Epoch 125: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.8784 - loss: 0.5260 - val_accuracy: 0.9197 - val_loss: 0.3964 - learning_rate: 3.9063e-06\n",
      "Epoch 126/500\n",
      "\u001B[1m163/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8920 - loss: 0.5023\n",
      "Epoch 126: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8920 - loss: 0.5024 - val_accuracy: 0.9182 - val_loss: 0.3984 - learning_rate: 3.9063e-06\n",
      "Epoch 127/500\n",
      "\u001B[1m162/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8862 - loss: 0.5141\n",
      "Epoch 127: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8862 - loss: 0.5141 - val_accuracy: 0.9197 - val_loss: 0.3981 - learning_rate: 3.9063e-06\n",
      "Epoch 128/500\n",
      "\u001B[1m159/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8864 - loss: 0.5019\n",
      "Epoch 128: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8865 - loss: 0.5019 - val_accuracy: 0.9212 - val_loss: 0.3989 - learning_rate: 1.9531e-06\n",
      "Epoch 129/500\n",
      "\u001B[1m160/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8971 - loss: 0.4880\n",
      "Epoch 129: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 9ms/step - accuracy: 0.8970 - loss: 0.4882 - val_accuracy: 0.9220 - val_loss: 0.3974 - learning_rate: 1.9531e-06\n",
      "Epoch 130/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8938 - loss: 0.5042\n",
      "Epoch 130: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8937 - loss: 0.5041 - val_accuracy: 0.9212 - val_loss: 0.3965 - learning_rate: 1.9531e-06\n",
      "Epoch 131/500\n",
      "\u001B[1m161/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8909 - loss: 0.5167\n",
      "Epoch 131: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8911 - loss: 0.5163 - val_accuracy: 0.9182 - val_loss: 0.3980 - learning_rate: 1.9531e-06\n",
      "Epoch 132/500\n",
      "\u001B[1m164/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8946 - loss: 0.5029\n",
      "Epoch 132: val_loss did not improve from 0.39532\n",
      "\u001B[1m165/165\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.8945 - loss: 0.5030 - val_accuracy: 0.9182 - val_loss: 0.3982 - learning_rate: 1.9531e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAGGCAYAAACqvTJ0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADxsklEQVR4nOzdd3hVVdbA4d85tyc3PSGE3iH0JogiiAICYuOzN5RBsStiwzY4M1bUsdcRe29gQRF7BaT3khAIENJ7cvs53x8nuUlIQgohCbDe5/ExOWWffXcKO+uuvbai67qOEEIIIYQQQgghhBDNSG3pDgghhBBCCCGEEEKIY48EpYQQQgghhBBCCCFEs5OglBBCCCGEEEIIIYRodhKUEkIIIYQQQgghhBDNToJSQgghhBBCCCGEEKLZSVBKCCGEEEIIIYQQQjQ7CUoJIYQQQgghhBBCiGYnQSkhhBBCCCGEEEII0ewkKCWEEEIIIYQQQgghmp0EpYQQtbrsssvo3bs3F154Ya3XzJ49m969e3PXXXcd8vOWL19O7969Wb58+WG9RwghhBDiSHS0zM169+7Ns88+e8j9E0Ic+SQoJYQ4KFVVWbt2Lenp6dXOlZaW8tNPP7VAr4QQQgghjk0yNxNCHE0kKCWEOKi+fftis9n49ttvq5376aefcDgcxMfHt0DPhBBCCCGOPTI3E0IcTSQoJYQ4qJCQEMaOHVvjxGfx4sWcdtppmM3mKsc9Hg/PP/88kyZNYsCAAUycOJFXXnkFTdOqXPfBBx9w2mmnMXDgQC699FLS0tKqPSMtLY1bb72VESNGMGjQIKZPn87mzZsb9BrcbjdPPPEEEydOpH///gwdOpQrr7ySLVu2VLnul19+4cILL2Tw4MGMHj2a+++/n8LCwuD5nTt3csMNNzBixAiOO+44Zs2aRXJyMlB7qvpll13GZZddFvz8lFNO4aGHHmL69OkMHDiQe+65B4CtW7dyww03cPzxx9OvXz9OOukk/vOf/+B2u4P3er1ennrqKU499VQGDhzI1KlT+fzzzwF499136d27NykpKVWev2jRIhITE9m/f3+DxkwIIYQQrdPRMDc7UGZmJnPnzmXs2LEMHDiQc889lx9++KHKNX/88Qfnn38+Q4YM4bjjjuPaa68NzsMAUlNTueaaaxg5ciSDBg3iggsu4JdffjmkfgkhDj8JSgkh6jRlypRqaeLFxcX8+uuvTJ06tcq1uq5zzTXX8L///Y/zzjuPl156iUmTJvHUU0/xz3/+M3jdO++8wz//+U/Gjh3LCy+8wKBBg7jvvvuqtJWbm8uFF17Ipk2buO+++3jiiSfQNI1LLrmkyiSkLnfccQeffvopV199NQsWLGDu3Lns2LGDOXPmoOs6YLyzOGvWLGJiYnjqqae47bbb+P7775k9ezYAGRkZXHDBBezatYt58+Yxf/58srOzmT59Ovn5+Q0az3fffZcBAwbwwgsvcO6555KZmckll1yCy+XikUce4dVXX+X000/n7bff5q233gred9ttt/H6669z3nnn8fLLLzN69GjuuusuvvrqK8444wxsNhuLFi2q8qyFCxcyatQoEhISGtRHIYQQQrReR/rcrLLs7GzOPfdcVq5cyezZs3n22Wdp3749119/PV988QUAe/bs4brrrqN///68+OKLPPjgg6SkpHD11VejaRqapjFr1ixcLhePPfYYL7zwApGRkVx77bXs3r27Uf0SQjQPc92XCCGOdSeffDIOh4Nvv/2WK664AoClS5cSExPDsGHDqlz766+/8ueff/Lkk09y+umnA3DiiSdit9t5+umnufzyy+nRowcvvPACU6ZM4e677wZg9OjRFBcX88EHHwTbevPNN8nPz+f999+nffv2AIwZM4YpU6bw9NNP88wzz9TZd6/XS0lJCffeey9TpkwBYMSIERQXF/PII4+QnZ1NXFwczz77LImJiTz33HMoigKA1Wrl6aefJjs7mzfeeAOv18vrr79OXFwcAH369OGiiy5i3bp12O32eo9nu3btuO2224Kf//777yQmJvL000/jdDoBOOGEE/jjjz9Yvnw5V199Ndu3b2fJkiXcfffdTJ8+HYBRo0axb98+li9fztSpU5kwYQJffPEFN998M4qikJ6ezrJly5g/f369+yaEEEKI1u9Inpsd6PXXXyc3N5clS5YE2xw7dixXXHEFjz32GFOnTmX9+vW43W5mzZoVXJrYtm1bfvjhB0pLS3G5XOzcuZPrrruOsWPHAjBw4ECee+45vF5vg/skhGg+kiklhKiT3W7nlFNOqZIm/vXXXzN58uRgAKfcihUrMJvNTJo0qcrxM888M3h+586d5OTkMG7cuCrXTJ48ucrnf/31F4mJicTHx+P3+/H7/aiqypgxY/jzzz/r1Xer1cprr73GlClTyMjIYNmyZXzwwQfBIqBerxe3283mzZsZP358ldczZcoUlixZQmxsLKtWrWLw4MHBgBQYk6GffvopOPmpr8TExCqfjx49mnfeeQebzUZSUhI//PADL774Irm5ucGJ1KpVqwCYOHFilXufffZZ/v3vfwNw7rnnsm/fPlauXAkYWVKhoaFMmDChQf0TQgghROt2JM/NDrRixQqGDBkSDEhV7l9WVhY7d+5k0KBB2Gw2zj33XB588EF+++03+vTpw+zZs3E6ncTGxtKjRw/uu+8+7rzzTr788ks0TWPu3Ln07NmzUf0SQjQPyZQSQtTL5MmTueGGG0hPT8dms/HXX39xyy23VLuuoKCAqKgoTCZTlePlwZyioiIKCgoAiIqKqvGacvn5+ezevZt+/frV2CeXy1Wvvv/222889NBD7Ny5k9DQUPr06UNISAhgpLQXFBSg6zoxMTG1tpGfn0+HDh3q9by6lD+7nKZpPPnkk7z77ruUlpaSkJDAwIEDsdlsVZ4PHLSPxx9/PB06dGDhwoUcd9xxLFy4kClTplRpRwghhBBHhyN5bnZg/zp27FjteGxsLACFhYX06NGDd955h1deeYVPPvmEt956i/DwcC6++GJuueUWFEVhwYIFvPjiiyxdupSFCxdisVgYP348DzzwABEREQ3ulxCieUhQSghRL2PGjCE0NJRvv/2WkJAQOnToQP/+/atdFxERQV5eHoFAoMrkJzMzEzAmO+UTnpycnCr3HlibKSwsjBEjRnDHHXfU2Cer1Vpnv1NTU7n++usZP348L7/8Mh07dkRRFN59911+++03AJxOJ4qikJubW+Vej8fDsmXLGDRoEGFhYdXOg/GOYYcOHYLvSh5YMLSkpITQ0NCD9vGVV17hjTfe4IEHHmDixImEhYUBRuZTufDwcMCo5dC2bdvg8eTkZPLz8xk2bBiKonDOOefw9ttvc9FFF5GSksKjjz5a5xgJIYQQ4shzpM7NaupfVlZWtePlx8r7Vnk53qpVq/jwww956aWX6NOnD5MnTyY+Pp558+bxz3/+k61bt/Ltt9/y6quvEhUVVaV2lhCidZHle0KIerFarYwfP54lS5bwzTffBGsSHGjEiBH4/f5qO8KUF6ocNmwYXbp0ISEhodo15UvqKreVkpJC165dGTBgQPC/RYsW8cknn1R7x68mGzduxOPxcPXVV9OpU6dg8Kg8IKXrOqGhoSQmJlZ7/q+//srVV19NZmYmw4cPZ926dVUCUzk5OcycOZNffvklWAuqcsHRgoKCehX9XLVqFT169OD//u//ggGpjIwMtm/fHgxyldeH+PHHH6vc+/jjj/Pggw8GP582bRqFhYU8+uijdO/enUGDBtX5fCGEEEIceY7UudmBjjvuONasWcO+ffuq9S8uLo7OnTvzxhtvMG7cOLxeL1arlVGjRgXLF6SlpbFmzRpOOOEE1q9fj6IoJCYmMnv2bHr16lXjDoJCiNZDMqWEEPU2ZcoUZs2ahaqq3HvvvTVeM2bMGEaOHMm9995LRkYGffr0YcWKFbz66qucc8459OjRAzB2kpszZw733nsvkyZNYu3atbz//vtV2rriiitYtGgRV1xxBTNmzCAqKorFixfz0UcfMXfu3Hr1uV+/fpjNZubPn8+MGTPwer189tln/PzzzwCUlpYCcNNNN3Httddy6623cvbZZ5Odnc2TTz7J+PHj6dWrF1dccQULFy5k5syZzJo1C4vFwosvvkjbtm0544wzcDqdJCQk8Pzzzwczr15++WUcDkedfRw4cCAvvPACr7zyCoMHD2b37t28/PLLeL3eYBp8nz59mDRpEvPnz8ftdpOYmMivv/7KTz/9xHPPPRdsq127dpxwwgn8/vvvVYqpCyGEEOLocyTOzQ505ZVX8sUXX3DFFVdwww03EBkZycKFC1m2bBkPPfQQqqpy/PHH8/jjj3P99ddz6aWXYjKZ+OCDD7BarYwbN4727dtjt9u54447uPHGG4mNjeXPP/9ky5YtXH755Y3qlxCieUhQSghRbyeccALh4eEkJCTQvXv3Gq8pD8Y888wzvPHGG+Tm5tKhQwduvfVWrrzyyuB1U6dORVVVXnjhBRYtWkSvXr3417/+xa233hq8Jj4+ng8++IAnnniCefPm4fF46NKlCw8++GCVpW0H07lzZ5544gmee+45rr32WiIiIhg8eDBvv/02l112GStXrqR3796MGzeOl156ieeee47rr7+e6OhozjjjDG688UYAEhISeO+995g/fz533XUXVquVkSNH8t///jdYp+CZZ57hoYce4tZbbyU2Npbp06ezc+dOUlJSDtrHWbNmkZeXx1tvvcXzzz9PQkICZ511VnAsCwsLCQ8PZ/78+Tz33HO8+eab5OXl0b17d5555hnGjx9fpb2TTz6Zv/76i7POOqteYySEEEKII9ORODc7UFxcHO+//z5PPPEE//nPf/D5fPTp04cXXniBU089FTDenHvppZd4/vnnufXWWwkEAvTv358FCxbQrVs3ABYsWMATTzzBgw8+SGFhIV26dOFf//oX06ZNa1S/hBDNQ9F1XW/pTgghhGg6M2fOxGaz8fzzz7d0V4QQQgghhBCiVpIpJYQQR4nnn3+elJQUfv/9d957772W7o4QQgghhBBCHJQEpYQQ4ijx448/kpqayh133MHQoUNbujtCCCGEEEIIcVCyfE8IIYQQQgghhBBCNDu1pTsghBBCCCGEEEIIIY49EpQSQgghhBBCCCGEEM1OglJCCCGEEEIIIYQQotlJUEoIIYQQQgghhBBCNDsJSgkhhBBCCCGEEEKIZmdu6Q40t5ycIg7HfoOKAjExYYet/SOdjE/dZIzqJmNUNxmjuskY1e1YH6Py1y9qJ/OpliNjVDcZo4OT8ambjFHdZIzqdqyPUX3nU8dcUErXOazfEIe7/SOdjE/dZIzqJmNUNxmjuskY1U3GSNRG5lMtT8aobjJGByfjUzcZo7rJGNVNxujgZPmeEEIIIYQQQgghhGh2EpQSQgghhBBCCCGEEM1OglJCCCGEEEIIIYQQotkdczWlDkbXdfx+X6PuVRRwu934fF5ZL1qDph4fk8mMqkpMVQghhGiNNE0jEPA3+D6ZT9WtKcdI5lNCCCFamgSlyvj9PnJy0tF1rdFt5OaqaFrj7z/aNfX4OBxOwsOjURSlydoUQgghROPpuk5hYS4uV3Gj25D5VN2acoxkPiWEEKIlSVAKYwJVUJCLqqpERMShKI17x8hkUggE5G292jTV+Oi6jtfrobg4D4CIiJhDblMIIYQQh648IOV0RmG12hoV6JD5VN2aYoxkPiWEEKI1kKAUoGkBfD43ERGxWK32RrdjNqv4/fLOXm2acnysVhsAxcV5hIVFSeq5EEII0cI0LRAMSDmd4Y1uR+ZTdWuqMZL5lBBCiJYm//JAMP3ZZJIY3ZGkfCLVmJoVQgghhGhagUAAqPj3WRwZZD4lhBCiJUlQqhJZS39kka+XEEII0frIv89HFvl6CSGEaEkSlBJCCCGEEEIIIYQQzU7Wqx2hHnxwHt9881Wt55955iWGDh1e7/ZuuOFqhgwZxj/+MaspuieEEEJUp+uopRmY8pIx5SdjKtqL4spFdeehuPPBZEGzR6M7otAccfjaj8LXdjioppbuuWgGuq6TXuTBYTURabc023NlTiWEEEK0HAlKHaFuvvk2rrnmBgB++GEpH3zwDq+++mbwfHh4RIPae+ih+ZjNzTcBFEKII41akoEpd7sRJLE4ql/gc4HZDrUthdH8mLM3Y9m/AlP2FrSITvjaDscXPwQsIfXrRMALAR9YQxvW96J9mDPXoTti8LUZZPSzvnQd9ACotU8Z1PwUbCnfYU35DlPBLrSIzvgjuxGI7I6ieTHlJWHK34kpLxnVV9ygvmv2aLxdxuNrOwy9vA+KirfTyeghcQ1qS7RuvoBOXqmPQre/WYNSMqcSQgghWo4EpY5QTqcTp9MZ/FhVVWJiYhvdXkMnXEII0ZIUTyFqaSaBqB4Hv9DnInTF45hzt+LqdynerqeBUsvKdV1HLdiF6i0kENEV3WbsHmbKS8ax5kXs2z5D0bwEQttSOmIO7j7ngWrGnLkex5qXsCV/hT9+KEVjHyIQ2zfYrCl7M6F/P4k19VcUf2n1x6pmAhFdqwR9dEuIkTFkj0KzhGIq2msEdgpTQdcIRPfCl3AcvoThBCK7l2UXRaOb7JiK9gQzkcxZG4wgWPH+Ss+z4I8bgK/tULSQeDRHNLo9mkB4BwJRvSqykgI+bNs+xbH6RUw52/B1PAl34oV4up0GqgVzxpqyQNRSzHnbq7wmU2kGlv0rah5mRSUQ3olAZHcC4Z3QQ2LR7NFo9iiUgBfVnYvizsNUsAtr6s+o7lzsWz/CvvWjKu14ukyk8PQFtX/txRGnPJ6r6XqzPlfmVEIIIUTLkaDUUWj//jTOO+9MZs68hg8+eJeJEycxe/YdvP3263z55UKysjKJiIjkrLOmMWPG1UDVVPMHH5xHeHg4WVlZ/PHHr0RERHL11dcxadLpLfzKhBDHOrUoDce6/2Hf/C6qr4TSAVdScuJ9YLJWu9acuY6wpTdhzk8GwJr6C/7I7riGzIJeo7Ckly0dK0rDkrEKy/6VqK7s4P2BkHg0Z1vMmetRMP5I1qxhmErSCfvpdhxrX0ELaYN13x/BeyzpK4n6aDKuQTNxJ15AyOoXsG37tNL94fjaDsMfNwBTwS4jYFSSjjlvR4PGwZy7DXPuNhyb3qnX9bpiwh/TB1NJJqorC0vGaiwZq6tdp1nD8Lcdhj+6N6QsJqxgT/Ccdc+vWPf8imaLRDdZMZVmVrSvmvG1Ox5P14n42wzCVLjHWJ6XvxNUC/6oHgQiuxGI6kEgojOY6rk7W8CHZf+KsgyslIrjigl3/0vr14Y4YpQHpXTdWMrXGgpwy5xKCCGEOLxaNCjl8Xh44IEH+O6777Db7cyYMYMZM2bUeO3vv//OY489xp49exg0aBD3338/3bp1O2x903Udt19r0D1mTccfaNg9ldnNapNOwNavX8drr72Npml8++3XfPTR+8yb9yDt23dg+fI/efzxRzjxxDH07t2n2r2ffvoRV111LbNmXc8nn3zI/PkPMXr02OA7iUIIUc6S+jOmor24Ey9qsto/iqcQ+9aPUAt2B4+prmxsO79B0Sq2LQ/Z8DqWzHUUTnoJzdnOuNeVg2PjW4SsfBpF8xMIicfTfQr27Z9hzk8m7Kc74CeoKZdBV63otghUVxam0gxMpRmAkZVTOvQ6/HH9cWx8m5CVTxuBpLwd6IoJT8+zcCdegGPjm9iSFxOy9mVC1r4cbNfdfSquYTfgj+1bNVNL11GL9pUFXPTgMcVfiuoyMoZUbxGBsPZGZlFUd3TFhCV9JZb9K7Gkr0Qt3m9kF/ndxu1mO/7I7sb1Mb2rLhHUddTC3Vj2r8ScvbHiGe5cTHlJqN4irKk/Y039GQAtJI7Sgf/A2/kUbMlfY9/6UTDrSrM48XYeh7frRLydT0G3VYyov+2wxn7pqzJZ8HU4EV+HE5umPdEi6jun0jQdjz8AQIk3gElt3JyoqedTIHMqIYQQ4nBp0aDUY489xsaNG3nzzTdJS0vjzjvvpF27dkyaNKnKdTt27GDWrFlcffXVnHHGGXzyySdMnz6db7/9ltDQhtXVqA9d15n5wTrWpxU2edsHM6hdOK9eOKjJJlLnn38R7dt3ACArK5O77/4nw4ePAODss8/l9ddfJSUlucYJVI8evbjkkukAzJw5i48/fp+UlGQGDBjUJH0TQhwdrDuXEP7NTBR0LHv/pGj8UzVmLdWXWpJuZEJtfKfW2kPe9qMoHXIdiuYj7PtbsGSsJurDSXi7nIo5fRXm/J3Ba909zqB47EPo9ihKj78T++b3cWx8E1PAhd8aieaIRnPEGsvZEo7DHzcAzHYUT6GR6VO4B39s3yrLBF2Dr8KdeAH2jW+h+F24Ey9CCzd+1/o6nIh11w84f70XU9EevO1HUTLqbvzxQ2p+wYqCFt4heH99ebtNxtttctWDPheKrwTdEV37EkVFQYvogieiCx7OrXpO82PO2Yp5/wosOVuwdxtJboep6Caj/lRpbF9Kj7sVS9oy0DV87UbUP+NJNBmv18u0adO47777GDlyJHfddReff/55tetGjhzJW2+9Ve14QUEBI0aMqHIsMjKS5cuXH5b+tsScqqnnUyBzKiGEEOJwabGgVGlpKR9//DGvvvoq/fr1o1+/fuzYsYN33323WlDq/fffZ8iQIdx8880A3H777fz88898+eWXXHjhhYelfy2fMH7oEhLaBT8eOnQ4mzZt5KWXnmP37hS2b99GTk4OmlbzO5cdOnQMfhwaaryT5/f7a7xWCHFsMmesJXzp9cGlafakL1C9hRRMegUsIagFuwlZ9wrmrE14epyBq/+lBw1iOFY9R+iKJ1A0HwD+qF54u05AV8qyr1QT3s6nVAnw5J3/DeHfzsKSvRH71o+Dx/3RvSkddgOenmcH1wTpVqcRUBpyFbGxYeRnF1Fb6RrdFo4/fkitwSTdFo5r2A01nvN2OZXcDidiKtxjBLOaawmSxYFeUwH2+lLN+OP644/rj0cBe2wYZBcFE7iMa0yStdSCPB4Pc+bMYceOiuWe99xzD3PmzAl+vm/fPi677DIuv/zyGttISkoiMjKSr76q2G1OVWsJYjYRmVPJnEoIIYSoTYsFpbZu3Yrf72fIkIoJ/7Bhw3jppZfQNK3KBGnPnj0MHDgw+LmiKPTq1Yu1a9celqCUoii8euGghi/fM6mtavme1VqRrfDllwt55pknOeOMsxg79hSuv/4WbrrpmlrvtViq7xqjN3PhUSFEzRRXDro9qvZsmGagFu4h4usrUfxuvJ1OxjXgCsKXXIs19Wciv7iIQFgHbElfoujG70RL+koc61+jZOTteHqeVa3vIX//l9AVTwDgSxhB6ZBr8XY5tc7XqEV0Jv//Psex/g1UTwG+hOHGLm32qMPzwuvLbCcQ3bNl+yCOKklJScyZM6fav8VhYWGEhYUFP7/rrruYNGkS48ePr7GdnTt30rVrV+LimmfnwobOqbZnFqPpOl1jQrCZG7cc+HAs35M5lRBCCHF4tFhQKisri6ioqCr/yMfGxuLxeMjPzyc6OrrK8YyMjCr3p6enExHR8N1Napqj1HxMwWFp2GTIbFbx+1vn+4ELF37KlVfO5OKLjXdOi4qKyM3NOSomRYrSfIkIh1P5azgaXsvhImMEltRfCP9qOoGYPhROehktonOV800xRmrRPkL+fAhTfgrebqfh6XMeWlhZloCuYcrdQdiSa1FdWfhjEima9CK6NYyCs94n/KvpWNJXYUlfBYC301h87U/Avm4BpsJUwpfeiH/1C7iGXoen5xmgmnGsqAhIlZxwN66h1xmvod6D4sA97Nqq43CQy+X7qG7H+hi1xte9YsUKRo4cyezZsxk8eHCN1/z111/8/fffLFmypNZ2kpKS6NKly+HpZC0aMqcKsZrwBXTsZhP2Bs7DmsvRPKcSQgghmluLBaVcLleVgBRUvAvl9XqrHJ88eTLXXXcdU6dO5aSTTuLLL79kw4YNjBw5ssHPjYkJq3bM7XaTm6tiMimYzYeWeXCo9zeGWlYItPzZJlPF/8uPRUZGsGrVCk4+eRylpSW8+OJz+P1+AgE/5rJ3FFVVCX5c02up3F5jNeX4aJqCqqpERYVit9ubrN2WVtP3qKjqmB0jXYeFTxm1f7I2Ev3xFDjnZeg9udqljRqjgA+WvwQ/PQy+EgAsWeuNgFG3caCaYc9ycOcb14clYL78U2IiygJWseOgzTfw5c0Q1RVOvAlr2wFYAcbdCMtehD+expyzhbClNxL293zoeDxs+Mi4f/wDhI6+haavFFizY/b7qAFawxhpms77f6eSUejh2rHdcVhbZ6DicLv44ovrvOaVV17hnHPOISEhodZrkpOT8fv9nHvuuWRkZDB8+HDmzp1LmzZtGtSf+r7J11DGHERHa8UBnoiICFauXMHo0WMpLS3llVeex+/34/N56765FTta3uQDCazXRcanbjJGdZMxqtuxPkb1fd0tFpSy2WzVgk/lnx8YYBgzZgzXX389N954I4FAgJEjR3LWWWdRXFxzEdyDycmpXkPE5/OiaRqBgI6/gUv2KjMypRp/f2NpmvGCyp8dCFT8v/zYTTfdxkMPPcCll15IVFQUp546AZvNwdatW/D7NXRdR9P04MeV2ytXub3GaOrxCQR0NE0jL68Ei8XXZO22FEUx/gCs6XtUGA7bGJU31sr/xTCnLSdy79/oJhv+2L5YMtbA+xdSOvR6SkfdCYra6DFSi/YR/tUVmHO2AMYSOk/vc7BtX2QUtk7+IXitbrbjSziOktH/JOALN+oOlTN1grMrFV2ufK7vLJRu52Pf8BaO9QtQ81MhPxWAklFzcfX5R9XrDxP5WasPndjY8HqNkdevYT3ENxz25bv437JUYkKsnDekHfFhRu2x9EI3877Zxso9BQB8sz6NR8/sS6eoQ6idVQ/l3yNHkj179rBs2TLuueeeg163c+dOoqOjmTt3Lrqu89///pdrrrmGjz/+GJOp/gG/w/Umn1r2e1hRD/2NsEY9vx5v9N166+385z/zuPLKi8vmVBNxOBwkJW0/It/oO1rf5IMj7+e4ucn41E3GqG4yRnWTMTo4RW+hXOPVq1dz6aWXsn79esxmIza2bNkyZs2axZo1a2osuun1eikqKiImJoabb76Zdu3aceeddzboudk1FLb1+bzk5OwnJiYBi6Xxu0a1VFDqSNHU49NUX7fWQlEgNjasxu9RYTgsYxTwEPXhaejWMPL/74vDFphSi/dj2/Yp7n6XNLreUfhX07Ht/gFXv0spPulfhP75ICHrXwOgZOSdlA6/sdFjFPb9Ldi3fYJmi6TkhHtxJ54frOek5qdgS/4aTDZjh7rYfmCqXiOlQfwu7Fs/xr7tU9w9z8I9cMahtdcAR+rPWkpOKc/+upOMIg+PndWX9hGHJzCzfHced36xmVCbma7RDrrHhtK7jZPju0QRHVLxu3ZnTgmv/pnKD9uzOGtAW+ZO6BkMKAC4fAGe+zWFmFArl4/oiFmt/rPlC2i8s3Ivry1LxVP274NJVZjQO45+bcN4+c9dFHsC2M0qDouJPJePUKuJByb3ZmyP2MPy+qHie6S16t27N2+99VaVjPH//e9/LF68mM8+++yg97pcLhRFCQYfcnJyGD16NO+++y5Dhw6tdx9qe5MvO/vQ/l1OySnF5QvQMdJOmP0Qf88cxZpyTlU+n4qNPTrmUyBvPtRFxqduMkZ1kzGq27E+RvV9k6/FMqUSExMxm82sXbuW4cOHA7Bq1SoGDBhQLSD11VdfsW7dOu655x5iYmJwu90sX76cRx55pCW6LoQ4iphztmLOSwJALdiFFtm19ot1nZDl8zGV7Mcf2Z1AVHcCkT0IRHYD9SAZBj4XEV9dZjwrexNFp73Y4H6acrZi2/0DOgqlg2eByUrJSQ8QiOpB2C9zCfn7STxdTkWL69vgthVvEbZkYyeugqlv4m87rMp5LbJrrTvNNZrZgbv/5bj717xD2KHSdL1KgKQp292X72ZrZjHbMouJDrHwf4PaYWvCjI7sEi9uX4CYUCsOi4kit59X/trNx2v2ESib0NyxaDOvXTS4Ss2dYo+fP3bmAuC0mXHaTNjNpioFtjpE2gm11v5P/46sYu78YjMl3gAl3gCZRR6W784HjGYGtgtnTPcYtmUWs3RbVnBjvoUb0rGZVeaM646iKJR4/cz+fBNr9hoZTmv3FfDQ1EScNuPZuq7zd2o+j/+UTEpOKQDDOkag67B6bwHfbsnk2y2ZAPRPCONfk/tgt6jM/XIL69IKuW3RZu44tQfnDW6HMPz222+ceuqpdV7ncFQNZsbExBAZGVmtdmdddJ1qE+ymmHCXxy7lLb7mV9PX9Eh3NL6mpiTjUzcZo7rJGNVNxujgWiwo5XA4OPvss5k3bx4PPfQQmZmZLFiwgIcffhgwCqGHhYVht9vp0qULc+fO5bjjjqNXr17Mnz+fhIQExowZ01LdF0IcJczZW4IfW7LW4zlIUMqcsZrQVc9UO65Zw/C3HYqv7XF4O43FHz+kynnnr/diztkKgD3pS1wDZ+BPOK5B/QxZ8xIA3u5TqgTO3P0uxbrnF2w7vyX8+5vIP/9roGEZHrYdX6D43fijeuKPr3+mREsq9vjZlVtKl+iQYKAjoOn8kZLLZ+v2s3x3HmcNaMstY7tVK5Zc7PET2cCdUv2azuvLUnlv9V6KPYEq5z5dt597JvZkaIfIGu91+wK8vmIP2zKK8Wsafk1H06FbTAiD2oczuH0EdrPK99uz+W5rJmv3FQbvDbWa0HUo9RnPPKlbNBv3F7E9q4SHlu7ggcm9URSF1DwXsz/fSGqe66Cvw6QqDEwIY2SXKI7vHEXftmHB5UUZRR5u+WwjJd4AQztEcM8Z/ViTnMWOrBLWpxWyJaOYdWmFrEur6N+4nrH0axvGc7+l8OGaNMLtZi4a2oGbP9vAhv1FhFpN+DWdv3blMeO9tTxxdj9S810sWJbK+rJ2ohwWbjm5G5MT26AoClsyinhv1T6W78rjvCHtuHJkp2CW1UvnD+SZX1N4f/U+Vu3Jl6BUGV3X2bBhA9dcU/sOcADFxcWMGzeOZ599luOPPx6AjIwM8vLy6NatW3N0tU7l348yeRdCCCGODS0WlAKYO3cu8+bNY/r06TidTm688UYmTpwIwOjRo3n44YeZNm0a/fv3Z968eTzyyCPk5+czatQoXn755RqX+AkhREOYciqCUuaMdXh6nlXrtZa0ZQD4o3vjj+2HKT8Zc+4OVG8R1tRfsKb+QuiKx3H1vYiSE/+JbnVi3/wBjq0foisq/rbDsexfgfP3B8g/94vg8ji0ALbkxfji+teYqaUW7cO2YyEApUOq7jKHolA09hEs+//GnLOVkOVPwpkPNWgM7Fs+BMDd5/xWX1cLoMTr56oP1pGUbRRj7xhpp0eck83pRWQUeYLXfbpuP+v2FfLQ1ES6xoSwN9/FGyv28PWmDOLD7Vw1qhOT+rTBVMOyssr2Fbi47+ttbNhvBFGsJoUecU56xobyR0ouqXkuZn24nnMGtuW60V2JdFQsOdqb7+KuL7ewLbN6DcQ1ewv4dN3+ascVwGpW8fg1SrxGMKpLtIM547pzfJdoVu3J5/qP1/PNlkz6tg2je2wId325hUK3n9hQK52jHRR7ApR4/cElcQD+gE6ey8eafYWs2VfIS3/spn2EndP7xjO2Rwzzvt1GZrGXrtEhPH52X7p1iKJzqDkYHMgo8vBrcg5/7MzFaTNx2XEd6d3GCYDDojL/x2Re/SuVLzZmkFHkIdxu5tn/G4CqwJyFm0jJLeW81/8OZntZTQrnDEzgqlGdiag0ZonxYfx7Sp8avxZmk8qt47pz3uB2tCmrOyVg3759lJSU0KNHj2rn3G43RUVFxMXF4XQ6GTZsGA8//DD//ve/MZlMPPjgg5x00kn07t27BXpeXTBTSqJSQgghxDGhxWpKtRSpKdVypKbUwR2pdW6a08HGSPEUYsrbYWT6NCCwErHwfKz7/gTAmzCSgmmf1npt+FeXY9v9I8Un/hPX4KuMg5rfWJa3/2+sacuwJi9GQScQ3onSYTfi/PVelICHkpF34Eq8kOh3T0L1lVA4/hk8vadBwEP40huxJS9GszgpPH0BvvYnVHlu6O8PELLuVbztT6Dg7I9q7Jt15zdEfHMVuqKizFhCtiOx2hiZ9/+NJW05roH/AIuxhMeUu4Po98ehKyZypv+NHtqwHbiam6br3LFoM78k52BSFQJa1RcZYTdzZv+29G7j5Mmfk8kt9WE3q4zsHMXvO3OCAZFyPeNCuWpUZ2xmlfQiDxlFHjw+jQiHmUiHBZcvwCt/7qbEGyDUauLO8T2Y0CsOc1nx4yK3n2d/28nn69MBsJgUTu4Ry1n92+INaPzzm20UefxEOixcNaoTTpsZs6qg6bAlo4h1+wrZmllMQNNJjHdyWp82TOgdR5zTSok3QHaJF5cvQM/Y0OAzAd5btZf//rwTU9m3ekA3lrnNP6sfsaG1/z7cm+9ixe48lu3OZ/muvGAGVrmYUCuvXzyYdhH2Bv8+WrAslRf/2AUY2U/PnTuAXmVBq+xiD3MWbWZzehEOi8r/DWrHJcPaE+tsnYGlI62m1Lp16zj//PPZsGFDtZ2NP/vsM+bOncu2bdsAKCgo4JFHHuGnn37C6/Vy6qmncu+99xIREdGgPhyu+dS+AhcFLj/xYTZiDvK9fKw7HDWljpb5FMicqi4yPnWTMaqbjFHdjvUxqu98SoJSSFCquUhQ6uCO9V9a9VHjGOk6tu2f4/zjX6iubIrGPIh7wPT6NajrxLw2ANWTb3xqDiH7qi0114fSAsa13kLyzluMv83AGpu07PuLsB9mYyraGzzm6TSOwqlvgqISsvJZQpc/SsCZQN753xL+3Q1Y9/5W0SWTjcKJL+DtdhqKp5DQ5Y9h3/AmCjr5Z7yDr9PJtb6csO9vxr7tU4jsTO7ZnxIIbRs8Z97/N5GLLkQJeHD3PIuiCc+BohD6538IWfMSni4TKDz99fqNWwt66Y9dvLYsFatJ4eULBtEhwsG2zGJ2ZJfQxmllbI/YYH2n7BIv877ZGqyJBHBC1yguP64ju4q8PPfjjmpL8WozqF04/5rSh3YRNe9MtXpvPv/9aSdba8iI6p8QxsNTE2kbXvO9bl+AYm/goMGkA+m6zv3fbAvWXZqU2IZ7J/ZqUG0rly/Az0nZLN6UyfLdeTgsJl66YCCJ8WGN+n2k6zpvrtjDst153HFqD7rFhFY57/FrLNuVx6B24USGtO4C1q09KNUaHK751P5CN3mlPuKcVuJaadCyNZCg1MHJnOrgZHzqJmNUNxmjuh3rY1Tf+VSLLt8TQojKFE8B4YtnoFtCcQ2eZWQMHSTryZSXjPOXu7Hu+yN4LGT187j7Xlyv3eHUknRUTz66YgKTDcVfiikviUBM9WUsppytqN5CNEso/tjai4n72o8i78KlOH/7J/atHxFwtqdowjPBpXqlg2di3/QOpuJ9RL87BtVTgG4OofC0F7Fvfg9byhLCv70a16CZ2LZ/jqnUCDq4+l6Mr+PYg76e4pP+hWX/35jydxO+8HwKzv4ILbQtan4KEYtnoASMpW32HYvwx/bDNegq7FuNzDB34gV1jldluq6TUeRhW1nB7/RCD26/htsXwBfQGd4pkguGtKtWz+lA6YVutmYUsyu3lF15LvwBjcuP6xjMsKls6bYsXluWCsDdE3rRPyEcgJFdohjZpfqOhrGhVp75vwF8uCaN7ZnFnD+kXTDgMik2jPHdoliwLJUftmcTbjcTH2ajbZgNu8VEgctHvstHscfPCV2jufS4mnePKze0QyRvXzaUrRlFLNqQzrdbMyn2BDhvcDtmn9wNi6n2YJHdYqpznA6kKAr3TOhJlMNCxygH5w5KCNbiqS+HxcTkxHgmJ8aTU+IFOKTMFEVRuGJkJ64Y2anG8zazytgeMY1uXxwbyr+Nj8XJuxBCCHEskqCUEKLVsCV9hTVtufHx7h/xtRlE6ZBr8XabXDV7SQvgWPsqocseQ9G86CYbpcNvwr7hTUzFadh2LMLT59w6n2cuqycViOyO5ojCmrYcc+a6GoNSlv1Gv/wJw0E9+K9O3RpG0alPUjpoJpozAd1eKWBidlAyai7hS29A9RSg2aMomPoW/vgheDuNJeynO7Bv/YiQtS8bz4vsRvGYh/B1HF3n69FtERSc/SHRiy7AnL+TiIXnUzjpFcK/uQrVnYevzSA8Pc7A+ed/CP3rYUzFaaiuLDRHLN7Ode/aVe6vXbk88O32YCCjJst25/HJ2jRuOKkrE/vE1Rgw+X1nDrcv2oz/gCV4P2zP5qpRnbl8hBEIKnL7+XJTOi/8vguAS4Z14PR+8fXqq6ooXDS0fY3nIh0WZp/cndknd69XW/XRJz6MPvFh3Dy2G9klXjpEOuq+qZHsFhO3jmuavssyKdFaqGXbRUpNKSGEEOLYIEEpIUSrYd31PQC+2P6Y85OwZK4jYsk1BMI7UzpkFp7E8yAvl4iFV2EpC155O42laMxDaBGd0RUTzmWPELLmRTy9/6/O2lLlRc79sYloIfFY05ZjyVyHJ/H86n0re54vYWS9X0+glowqT8+zcO9aiikvmaIJzxKI7mmcUM0UnfI4Wkgc9i0f4BpwBaVDrwNT/ZewaOEd4YqvCCyYjDl/J1EfTDBqXIV1oGDK6+ghcZjyd+LY/B6ODW8A4O41rV6ZZWDsXDfvm23klvowqQrdYkLo3cZJpygHDosJu1nF7dd4++89pBd5uHfxVj5Ys6/a8jW3L8Cj3yfh13S6RofQJ95J52gHWzOK+Tkphxf/2MUvyTkkxjtZvDkDl89YpjKqSxQ3jql9h8TWwm4xHdaAlBBHq2CmVMt2QwghhBDNRIJSQojWwe8K1lYqOvVJtNB4HOtfx7HhDUyFuwn75W5CVzwBAS8WbxG6OYTik+bhTrwo+FeMu/9lhKx6DnPuNqy7f8Tbxcj+UTyF2De9jbfLBALRvYKPNGeXBaViEo1gDmDOXFe9b7qOJW0FAL529Q9K1UpRKJr4fC3nVEpGzaVk1NzGtx/VmYJzPibis/MwFe9Ds4ZTcPqbwSLmxWP+gzl3O5b0lQC4E8/H7QuwZGsmJd4A/oCOX9NpH2FnQp841ErBvf/9lUpuqY9OUQ7euWwojlqWnZ09oC3vrdrHGytS2bi/iDkLN/HaRYODy9ReX55KepGHtmE23rp0SPC4rut8syWT+T8msTm9iM3pRQB0iwnhgiHtmNqvbZ275Qkhjlzlv28kU0oIIYQ4NtS/IqpoVa67biYPPHBvjee+++4bJk0ah9db89Ka/fvTGD16OPv3pwEwevRwVq9eWeO1q1evZPTo4fXu148/fk9eXi4Ar732MjfccHW97xXHNuveP1D8bgLO9gRiEtEdMZSOvI2c6SsoOulfBMI6oLpywFuEr+1wci/8zqgdVSlgotsicPe7BADH6hcAUAt2E/npWTj/epiwH2+r8szg8r2YRHxtBhnHsjdDoOrPjqkgBdWVha5ag9e1dlp4JzLO+JDkzheTPvmtqksSTVYKJr2Cr80g3H3OIxDTh/k/JvGf73bw35938uxvKbz4xy7uXbyV+T8kUb4fxs6cEj5Ysw+AOeO61xqQAiNTaMbxnfhg+nCiHBa2Z5Xw0NId6LpOap6Lt1caheBvHde9Sj0lRVGY0jeeD6cPZ2LvOMb3iuXF8wbywfRhTBvUDmsDCnkLIY48ajPXlJL5lBBCCNGyJFPqCDV+/Gm88srz+Hw+LJaqy25+/HEpJ598SrVtoWuzaNG3hIc3bCvomqSn7+f+++/i44+/AOCiiy7jvPMuPOR2xbHBmvIdAN6u46suu7OE4B44A3f/y7Ht/IZwm5+CDmcaxclr4Bo0E8f6BVj3L8ex7n+ErHwG1W1M7C0Zq1ELU9HCO0HAgyk/GSjLlHImoNkiUD0FmHO2Vtldr3ypoC9+CJhr3kGtpWzNKGJbZjHdY0PpFefEZlHJK/Hy6p+7+XDNfvJdU+mdp/LS+X6ctopf+XpoG/LP+xqAtXsL+GJjBgATesdhNasENJ0lWzL5ZN1+LCaV2Sd34/EfkwloOmO7x3BC1+h69a9dhJ2Hz0jk+o/X882WTPq2DeOPlFx8AZ1RXaI4uZbC123CbDw4NfEQR0cIcaRRmjlTSuZTQgghRMuSoNQRaty48Tz99OOsXLmcUaMqCiCXlBSzYsUy5s9/ut5txcTENkmf9AMmkCEhIU3SrmidLHv/QDfb8bcdduiN6RrWXT8A4OkyoeZrVDPenmdAbBhkF9VacERzJuDuNQ3H1g9x/j4PMGpUoZqwZK7DlvQlrqHXY8pLRtH8aLYINGcCKAq+uIHY9v7GJ98uJubE9pzU3QiYBINS7UY0+iWuTM3nnZV7OX9Iu3oHdGrj9gX4blsWn67bH1zeBmBWFXrGhbI7z0WpNxA8vi2zmDkLN/HM/w3AdkCmkT+g8cgPOwA4a0Bb7p1YsbzxuI6R/Pu77by/eh87c0r4OzUfq0nhlpO7Nai/wzpGctPYbvz35508+VMyOmAxKdx2So8G7xgnhDi6NXemlMynhBBCiJYl6yCOUFFRUQwfPpJffvmpyvHffvuF8PAIOnXqzL333sGkSeMYN24UM2Zcwvr1a2tsq3K6eUlJMf/8591MmDCGCy+cxtatm6tcu379Wq699h+ceuqJjB8/mttuu4ns7GwAzjvvzOD/Fy/+slq6+YYN67j22n8wfvxozjvvTBYu/CR47sEH5/Hss09y//1zOfXUE5k27XS+/fbrQx4ncXiYcrYSsehCIheej1q8/5DbM2dtwFSagWYJxdd+1CG35xpyTfBjT9fTyJ/2Ge6+FwFg2/Gl8cwc43vbH9MHHfhxRzYfZxg7uoXlbWTuV1vYmmEEfCz7D62e1O7cUm5btIk/UnK55bONvL48tdofHfX1S1IOU19Zzr+XbGdzehFmVWFI+3CiHBb8ms6WjGJKvQF6tQnlwdP78MYlQwi1mli9t4B7v95Sbae791fvIzm7lEiHhRtOqlpA/MwBbbnz1B4ALN+dD8Dlx3VsVAHvi4a257Q+ccFY4mXDO9ApSgqBCyGqqsiUap7nHYnzqY0b13P11TNkPiWEEOKoIEGp2ug6+Eqb978G/pE6fvxEfv/9FwKBioyIH3/8nlNPncC//nUfgYDGyy+/zoIF7xIX14Ynnnikzjbnz3+Y1NRdPPfcK8yefTsffPBu8FxxcTF33HELI0Ycz9tvf8STTz7H3r17eeed1wF49dU3g/8/9dSq2S67dqVwww3XMHjwUBYseIcZM67mueeeqjIJ/PTTj+jduw9vvfUhY8eewvz5D1FcXNygMRHNI2TVsyjoKAEPjrUvH3J71pSlAPg6jW3QTnO1CUT3pGDSyxSNe4zCya+CJQRPtynoiglL9kZM+TuDRc6TlM5c9s4a7vxiM7+WGMXOR1h34fFr3L5oM4VZuzEVpqIrKv629a8HUq7E6+f2LzZT4g0QHWJBB174fRd3fLGZEq+/3u3ous5bK/Zw+6JNFLj9tI+wc+NJXfl61kheuXAwS649noUzj+ORMxL54OrjefeyoUzs04Z+bcN44ux+WE0KPyfl8O8l20grcAOQXujmlT93A3DTmK5EOqrvwHfu4HbcOq47AO0j7Ewf0bHBYwDGH5r3TuzF8E6RDEgI58qRnRrVjhDiCNSAOZXJV4rqLwVficynaplP3XTTtQwZMkTmU0IIIY4KsnyvJrpO5GfnBHemai6+hOPIP+ezOrexLzd27Djmz3+YdevWMHTocIqLi/n772XMmHE18fEJnHzyKbRpY2R+TJt2PrfffvNB2ysuLuann77nmWdeonfvPgBcccVMnnzyUQA8HjfTp8/kwgsvQVEU2rVrz8knn8KWLZsAiIyMCv7fZqtad+fLLz+nV6/ezJp1PQCdOnVh164U3nvvLcaOHQdAjx69uOSS6QDMnDmLjz9+n5SUZAYMODIKSx8r1PwUbElfBj93bHqH0mE3ojsOqA0U8IKpfnU4rLu+Bw6ydK8RvN1Pr/K57ojG1/EkrKk/o21eyP6k1XQH3toVzrZAMQ6LSt8BJ8Hm/9JV30PPSJUd+R4WfbOQWwF/bH90q/Ogzyx0+8go8tAtJhSTqqDrOv9esp2UnFJiQ628fdlQfkvOYf6PSfyclMNFb65iSt94Tu0VS4/Y0FqXsnn9Gg8t3c7XmzMBOHdQAnPGdcdsqnhfQVEU2kc46BDpIDY2jOzsouDfZcM6RvLQ1ETu+GIzizdnsnhzJgnhNmxmFbdfY0j7cKb2i6/1dV00tD0jOkUS57RWKUreUHaLiRfPG1j3hUKIo0cj5lSdD/GRx8J86tprb8Tv12Q+JYQQ4ognQanaHAF1TkJCQjnhhNH8/PMPDB06nN9++5mEhHb06ZNI9+49+P77JWzcuJ7du3exbdtWNE07aHt79uwmEAjQs2dFTZnExL7Bj2NiYpk8eSoffvguO3ZsZ9euFJKSttdrkrNr1y769etf5diAAQNZtOjT4OcdOlRkYISGGn/8+/31zyQRzSNk9fMouoan8ymopdlYstbjWPc/So+/07gg4CV8ybVY0pZTcPob+BMOnl2kFqVhyd6IjoK38ymHte/uHmdiTf2ZwrUfE64VggKZ9u5cP6QLZw9IINJhJrCrDabSTJ4eDTO/c9En/xcwwQZTXz7+KZnMYg+do0O4YEg7okOMoJum63y+fj/P/ppCiTdAhN3M8V2iCLGa+GF7NmZV4dEz+xIbauWcgQn0jAvlzi82s7/Qw2vLUnltWSqdohx0iKz44yOg6ZR4AxR7/OSV+ihw+zEpcOu4Hpw/pF2DX/vYHrE8dmZf3vp7L5vSi9hf6AHApCrcOb5nnbWduseGNviZQggBtPo51ZE2n+rbt1+VYzKfEkIIcSSToFRNFMV4h83vatBtZrOK33/wicrBG3A0eOI2YcIknnpqPrNn38GPPy5l/PjT0DSN2bOvp6ioiFNPncCJJ47B5/Nxzz2316vNyrVuzOaK5TxZWZnMnHkZvXsnMnz4SM488xz+/PN3Nm3aUGebNe1cEwhoBAIV43XgrjcH9kW0PLUoDfs2Y+JbOuwmVFcWEd9chWPDG7iGXINuDcf581xsKUsACF96A3kXfIduC6+1TetuI0vK33ZY9WyrJpYSPZZEzHTT94ACOgoPXTkNk60i4OJvMwjTrqX0Xn47v5vSUHVjOceLqe1Yumtf8Lp3V+7l7AFtGdczlpf+2MXafYWAUWy8wO1nydas4LW3ndKdge0qxqB/QjgfX3kcvyRn8+P2bP5MySU1z0VqXu2/c8JsZh6emsjILlGNfv1je8Qytkcspd4A69MKWLuvkMR4pwSchBCHTwPnVF5/gJ05pZhUhZ5xB89OrZXMpw7aFyGEEKI1kaBUbRQFLA3c7cSsgnIIQalGGDXqRB5++AFWr17JqlV/c9NNc9i1aydr167myy+XEhVl/AH72WcfAweflHTq1Bmz2cyWLZsZPtzYZWzHjm3B87/++hNhYRE89thTwWOffPJh8OODZVp06tSZdetWVzm2adN6OnU61CR90Zwca15E0Xx4248yMqB0DX90b8y523BsMGpgOLZ+iK6oaI5YTEV7cf4yl6IJz9X6B0J5PSlP16ZbuleTXTmlXLcwhYcCg5hgWgVAIKJLlYAUgD9+MLZdSzEV7QEgJ6Q73+qjUDtN5LLwEKJDrXy/LYtN6UV8uCaND9ekAeCwqFw7uiv/NzCBzelF/JGSy8o9+QzvGMm0gQnV+hNiNTE5MZ7JifGUeP38vTuf4ko1plRFIdRqwmkzE2o10THKQai1aX5lh1hNHN8lmuO7HNougEIIUS8NmFMpqoZmBhQaPg87BEfSfGrtWplPCSGEOHpIUOoIZ7VaGTNmHM8991+6detBx46dyMzMQFVVfvhhCaNHj2XLlk0sWGAUo/Z6vbW2FRrqZNKk03nqqfnMnftPPB43Cxa8EjwfHh5BRkY6K1euICGhHT/99D2//PIjffoYKel2u7GTVlLSdiIiIqu0fc455/HJJx/w8svPM3nyVDZt2sBnn33M7Nl3NPGIHLnUwj2QuxeijseYjbcuSmkWjs3vAVA6rKyehqJSOvR6wr+/ySh+XvZOePGYB/HH9iXys2nYdyzC2+lkPH3Oq96mOw/r3t8B8HaZeMh91HSdXbmlbNpfxKb0IjKKPHj8Gm6fxq7cUoo8fpZHjGGCpywoFZtYrQ1X/+kopdloEZ3xdJmAFtGZiUDl3l0yrD0rUvNZsCyV1XsLOKFrFHeN70lCuLH8bnCHCAZ3iKh3v0OtZk7u2TRbiQshxJGsPB6j6Ubgp66lxU3lSJpPffzxB7z44rOcdprMp4QQQhz5JCh1FJgw4TQWL/6SG2+cDUCbNvHMmXMXb7zxP15++Xk6duzMzTffxn/+80927NhGTEztf/zOnn07//3vfGbPvp6wsDDOPfdCnn/+KQBOOWUC69at4d5770RRFBIT+3LDDbfw2msv4/V6iYyM5LTTJnP//XO59tobq7Tbtm1bHn/8KZ599ik++OAd4uPbcsMNszn99DMP27gcaZw/3gZ7/8A68Xk8Pc9q6e5UE7LuNZSAB1/8EHwdTgwe9/Q8k8CKJzAVGru4lQ6ehbv/ZcbHI+YQuvwxwn65B1/b4WiRXau0aUv6EkXz4YvtTyC6Z6P7llnk4Y0Ve/hmSwbFnkCt1/WKC+XCs/6B/sGLKH43/pjqQSndHknJmH8f9HmKojCycxQjO0eR7/LVuGudEEKIhlMrvSmj681bjupImU899th/eeGFZ3jvPZlPCSGEOPIp+jG2yLzyjlTlfD4vOTn7iYlJwGKp325hNTnkmlJHuaYen6b6urUW0W+NxFS0D390b/IuXApKpZ3VvMXYtn+Op8cZ6PbIlunf2ydiKtxNwWkv4e0xtco527bPCP/+Jtw9zqBo4vMVfdcCRCy6AGvaMnzxQ8n/v0VV/sKI/PRsLOkrKT7xflyDr66zD4pClZ3lsoo9vLliD5+v3483YPxg280qifFO+iWE0znKgcNiwmZWCbWZGNw+AotJxfnL3dg3vUP+/y3CHz+k6QapFThwjER1MkZ1O9bHqPz1i9odrvmUjs6W9GLAeCOh8i6jokJTzqmOtvkUyO+wusj41E3GqG4yRnU71seovvMpyZQSopVQXbkAmHO3YU35Dm+3ScYJXSfs+5uxpSzBtvMbCs54t9l3MlILdmMq3I2umvF1OrnaeU/vaeS0G4nmbFe1b6qJovHPEP3eyVgyVmPd/QPeLuODbVrSV6Irao2ZYcUeP++v2sfKPfncfkoPesRVrf2Umufi8ndWU+I1MqOGtA/nH6M6M6xjJGb14ONTfNK/KBlxG7pDaioJIURroqCgKmXL91q6M0IIIYQ47OTtJyFaA58rWI8JIGTVs5SH063JXwd3s7Pu+RXb1o+bvXvWPb8Z3Ywfhm6teTckLax9jcEyLawdroFXABCy4sng67Jv/9xos8NJaKHxweuLPX7+99duznx1Ba/8tZvVewt4bdnuau0u2rCfEm+ArjEhPH/uAF6+YBAjO0fVGZACQDVLQEoIIVqp8jpS2rH4trIQQghxjJGglBCtgOrOMz5QTOhmO5bMdVj2/IriziPs13sB8Mf0AcD5xwMoJZnN2j/r3l8B8HU8qVH3lw6ehW4OwZK1HuvuH0DXsW37FAB373OC1+3OLeX/FvzNy3/upsjjp32EUTj8t525lFTamU7Xdb7flgXArBM6M6JzVLMVwxVCCHF4lb+3IDEpIYQQ4ugnQSkhWgHVbSzdIzQOd79LAAhZ9QzOP/6F6srGH9WTvP/7Al/cQFRPAWG/3dt8ndMCWPb+AYC3kUEp3RFTJVvKnLEGc0EKutmBp+tkADx+jblfbSG31EfHSDsPnt6HT2ccR6coBx6/xi9JOcH2NqUXkVbowWFRObGrZDwJIcTRRJVMKSGEEOKYIUEpcezyuUDz131dM1DKg1Ih0biGzEJXLVjTlmPf+jE6CkWnPA6WEIpOeRxdNWNLXow1+esm74c5fTXm/SurHstch+opQLNF4G8zqNFtG9lSDiNb6vvbAfB0mwRWo1bUf39OZkdWCVEOCy9fMIiJfdpgUhVO6xMHwHdbs4JtlX88pnsMdoup0X0SQgjR+lQs32vhjgghhBDisJOgVCXH2EaERzxdb/yuM2rhHmLeGEr4t7OasEeNF1y+FxKD5myHu895wXOugTPwtx0GQCC2L6VDrwcg7Jd7UbzFTdYHS+ovRH52DpGf/x+mvKTgcevesnpS7U8AtfF7I+iOGEoHXAFAaME2ANZETADgu62ZfLpuPwAPTOlNnNMWvG9i7zYALNudR77Lh6bp/LDdCEqN7xXX6P4IIYQ4PA7l32eQ5XvN7VC/XkIIIcShkN33AJPJDCgUFxfgdEY0ujaNpikEAjKDqk1TjY+u6wQCfoqK8lEUFbPZ0uA27NsXonqLsKUsQS1OM3aNqye1JANL6s94ek0D0wHP1jWsyYvxJwxHC21b7zYVV0WmFEDp0Oux7ViEFtKGkpF3VLm2dPhN2Ld9iqloL5Z9f+HtOqHez6mNKXsz4d/OQtGNnexCVjxB0WkvAmDZY9ST8nYcc8jPeck3hWv1BYQoHrL0cC79LYyRezewbl8hAFeO7MioLlWX43WJCaFXXCjbs0r4cXs2+QHIKPISajUxSpbuCSFEq2E2W1AUlYKCHJzOSEwmc6PmVKrmR9ED+HwefCYJmNSkKeZUTTGfEkIIIQ6VBKUAVVWJioojLy+L3FxX3TccpB1Nk8lTbZp6fKxWO+Hh0Y2a8FpTvq34eOe3uAfOqNd9akk6kZ+eg6loDyVFeykdMafKecfaV3D++R/cPc+maOJz9e5PsKZUSAwAWkRnci/9Hcz24PK2IJMNb/sTcWz9EHPm2kMOSqkl6UR8PR3VV4wvtj/m7E3Yk76kdOgNBCK6YElfDTS+nlS5z9bv59mVRdjMk7jBvIjNcVMhzcyfKUaW2JD24Vx9Qpca753Ypw3bs1JYsjWTtBIfAGN7xGAzS7KnEEK0FoqiEBPTloKCXAoKshvdTkmpD7dPI99nxmuVJdo1aco51aHMp4QQQohD1aJBKY/HwwMPPMB3332H3W5nxowZzJhRc3Bg6dKlPPnkk6Snp9OnTx/uvfde+vXr12R9sdkctGnTgUCgcTWGFAWiokLJyyuRdPMaNPX4qKqKqpoa9w5sURqWzHXBz23Ji6sFpRRvEfg96CGxFcfceUR8cQmmoj0AONa9hmvQTHRbhHGBr5SQ1S8AYCra27A+HRCUAtBDal+a5o8fAls/xJKxpkHPqcZbQvhXV2Aq3o8/qgcFZ32A89d7sO9YROiK+bj7XYai+QiEd0KL6HLQpvyajlmt+evxa3IOj36/A4CCYbeS3/US+rYdzgf5fp79LYXsEi//Pj2x1vsn9onjud9SWL2ngOScUgAm9Jale0II0dqYzRaio9ugaYFGBU0UBd75dRe/J2Xxj+M7MymxzWHo5ZGtKedUhzKfEkIIIZpCiwalHnvsMTZu3Mibb75JWload955J+3atWPSpElVrtuxYwdz5szhX//6F0OHDuWNN95g1qxZLF26FIfD0WT9Mf5htjbqXkUBu92OxeKToFQNWtP4lGdJ+SO6Yi5IwbJ/BUppdkUAKuAh8uOpmPJ34u0+mdIh1+GP7kXEV9Mx524jEBKPbnVizk/Gse5/wWwpx4Y3g8ElxVPQoD4proqaUvXhjx8MGEXI0TVQGpcxFLr8MSzZG9EcMRSc/ia6PZLS427FlvQltl3fo3qMZXXeDifx+84cvtuaxS0ndyM6pOrPya/JOdz15WaGd4zkjlN70CHS+Ln0BzTeXrmX//21G02HM/vHc9WJ3fAp3QHoEmPlibPrDi4nhNsZ2C6c9WmF5Jf6CLebGdk5qlGvWQghxOGlKAomkxlTI5KcFAW8mNhXFKDACxZL4+ZlR7PWNKcSQgghDlWLrX0pLS3l448/5p577qFfv35MmDCBmTNn8u6771a79o8//qBHjx6cffbZdOrUiVtvvZWsrCySkpJqaFmIg7PtNIJS7v6X4YsbiKJr2Cot57Nv+QhzfjIKOrbkxUR9MpWYt0/EkrEazRZJwZnvUTLS2D3Ose41IwDlKyVk7UvBNpSyYE591ZQpdTD+6N7oJhuqpwBTfkqDnlWZbdf3ABSNfRgtojMAgajuuHsbhdYt+1cAkNPmBO79eivfbMnkyZ+Sq7Th9gV47IckfAGdv3blceGbq1iwLJV1+wq47J01vPD7LrwBnVN6xjJ3fM9Gvxs7sVJm1Mk9YrCYZOmeEEIcjewW4/e7xx9o4Z4IIYQQ4nBrsb/qtm7dit/vZ8iQIcFjw4YNY926ddXSvSMjI0lKSmLVqlVomsZnn32G0+mkU6dOzd1t0cqZ01dh3v93rVv2KO48LGnLAfB0m4Sn+xQAbMnfGBcEPISsehaA0sGzcPc5D101o7qy0M0hFEx9i0BMb7zdp+CP7o3qLcSx7jUcG99CdeWglS3lUz35Deq3ekCh8zqZLPjbDDRec2bjlvCphXsxFe5GV0z4DihiXnrcLeiqUfBUV1SeSE6gxGv8cbBkaxar9uQHr31v1T4yijzEh9kY0SkSj1/jxT92MfODdSRllxBhN/PA5N48ckYi5kMIJI3vHRfckWliH1m6J4Q4Nnm9XqZOncry5cuDx/7zn//Qu3fvKv+98847tbbxxhtvcNJJJzFkyBDuvvtuXK7G19M8HGxmI8XK7ZM6nUIIIcTRrsWW72VlZREVFYXVWpGWHRsbi8fjIT8/n+joij/Op0yZwo8//sjFF1+MyWRCVVVefvllIiIiGvzcw7VkvrxdWZJfs+YYHzU/hcjPpqHoAQIRXXAnXoinz7lozopd8Gy7lqLoAfyxfdEjOuHtPgWWPYJl3x+onnxsSV9hKk4jEBpP6fG3g9lO6cjbsW3/HF+H0QTiB6EAKCqlI2YT/u01ONb9L7gLX+mI2Th/m4cS8KAE3Eah8npQyjOlHNH1HiN/m8FY9v+NJWMN3j7nNmCkDNa0P8vaGQQ2J5Ufq0d0xN3vYhwb3iQ/oh+f73CjKjCicxTLduXx2A9JvHf5UPJdPt5YkQrAjWO6clqfOJZszeLJn5LJLfUxuW8bbj25G1Ehh778ItZp5fZTepDn0xjROUp+1mohv4vqJmNUt2N9jFrr6/Z4PMyZM4cdO3ZUOZ6cnMycOXM455xzgsecTmeNbSxZsoTnnnuO+fPnExMTw9y5c5k/fz7333//Ye17QzjKipt7/BKUEkIIIY52LRaUcrlcVQJSQPBzr9db5XheXh5ZWVncf//9DBo0iPfff5+5c+fy+eefExNTv+VO5WJiwg6t4y3c/hFL18FdQExMwwOJVQT8sPUr6H4K2MOrntu1EnQjm8dUsIvQZY8Qunw+nHIvjJ5t/JWx11iuZu5/FrGxYRA7CNr0RcncTEzGj7Da2DHPNGYOsW3LsnFie0PXu6r3JfoCWPU0atYW4/OoLjjHXg+/PQDoxIZqEFaP7wddh/LMqpAYYqLq+T3UcxSsexVHzgYcsY34vsv+GwBLz5ONsTjQlH/hDwnhnvVdAbh8VBdmj+/FuCd+ZmdOKV9tz2F7RhEun8aQTpFcMrobiqJwaVw4Z4/oTEahm+5xNf9R1FjXTujdpO0dzeR3Ud1kjOomY9R6JCUlMWfOHPQaMoGTk5P5xz/+QVxc3Vmkb731FtOnT2fcuHEAPPDAA/zjH//g9ttvb9I6nYfCXp4pJcv3hBBCiKNeiwWlbDZbteBT+ed2e9Xskscff5xevXpxySWXAPDvf/+byZMn8+mnn3L11Vc36Lk5OUWHpSikohiT98PV/pEuZMWThPz9FIWnv4a3y4RGt2Pb/D5hP96OO/ECik99oso55/ZfsQOlQ2YRiOqFfcsHWPb/DT88gCtnPyUj5hCT9AMKkNd2HIHsIqNvnU8jJHMz2pJ7UL1FBELiyes8DcrOH4x12M2Ef3sNAEVDbsST7yHaFo7qKSBv/z4CnpC6X5SvlFi/2/g4JKbe30NqSB+iAT19Az+u2kl8VBhtw+uXmYWuE5X8CyagIHo4vhpfq4n/+S9lcd5uYkKtXDGsHb5SN9eN7sx/luzg8SXbgu9i3zS6Czk5xVXujlAgux5j2BDyc1Y3GaO6yRjV7Vgfo/LX35qsWLGCkSNHMnv2bAYPHhw8XlxcTEZGBl26dKmzjUAgwIYNG7jhhhuCxwYPHozP52Pr1q1VSiq0JIe1vKaUZEoJIYQQR7sWC0rFx8eTl5eH3+/HbDa6kZWVhd1uJzy8agbMpk2buOyyy4Kfq6pKnz59SEtLa/Bzdb3WckNN4nC3f6SyJn8DukbIn4/g6XRqo3eLM2dtMtpLWYquVd11rrxWlLfjOHwdR+NOvADH2ldx/vEAjrWvYN77J0rAQyC8M/7oRCj7Orm7TyHk7/+ieo0ASumw69FN9uD5g/F0m4K7xxkofg/uXtNAB90WCZ4C8BTWL7hUaizd0002FGsoul5cr/sCzo5ojhhUVw7PfvIlqY5E3rlsKHFOW5XrUvNcFLp99E+o+LlSC3ZjKk5DVy142x5X42tds7eABcuMpXm3ntyNUKsZXYcz+rVl4fp0Nu43xuu0PnH0Twhv1u97+Tmrm4xR3WSM6iZj1HpcfPHFNR5PTk5GURReeuklfv31VyIjI7nyyiurLOUrV1hYiMfjoU2bNsFjZrOZyMhI0tPTG9Sfw1kOwW6pqCnVWpdStqRjfXltfcgYHZyMT91kjOomY1S3Y32M6vu6WywolZiYiNlsZu3atQwfPhyAVatWMWDAAFS1asCiTZs2JCdX3fErJSWFAQMGNFt/xSHwlWLK3QaAOXcb1pSleLud1qim1KK9xv/duZizNgaLfauFe8uCLGZ8bYcGr3cNvgrNFkHYT7djyd4IGAXOK/+EBKL74I/oirkghUBIPO6+NU/8a6SoFJ32YpVDmi0cE6C68+v3msrqSWn2KEwN+Y2lKPjaDMa2+wcGqcmsLe3B3C+38OqkSJxb36d00ExWZJuZ/fkm/JrON7NGBms7WfeV1ZOKHwKWqss1fAGNl//czVsr9qADx3eJYkKlne9UReHOU3sw/d01WEwqN5zUtf59FkII0aR27tyJoih069aNSy+9lL///pv77rsPp9PJhAlVM5PdbiMrt6byCQdmr9flcGaS2S35AOiqUvPycgG0vmy+1kjG6OBkfOomY1Q3GaO6yRgdXIsFpRwOB2effTbz5s3joYceIjMzkwULFvDwww8DRtZUWFgYdrud888/n7vuuov+/fszZMgQPv74Y9LS0mp8F1C0PpasDSh6RQp+yKpn8Had2KiQsalwT0W7e34NBqUs+5cB4I8bAJaqS+Y8ieej2yII/+46lIAnuONekKLg7n8Zzj/+Rcnxd9S7OHlt9LId+BRPQb2uLy9yrjtq33kvo8jD5+v3M7VfPB0iK4JI20w9GcgPDDcl86nZxMa0PPyf3kKIJ4m9LjOzN4wKLn/IKPIEg1KWvUZQytt+VJXn7Mwp4f7F29iWaSzFO6NfPHNO6Y5ywNeqT3wY/7twMFazWv8lg0IIIZrc2Wefzbhx44iMjASgT58+7Nq1i/fff79aUMpmMzJpayqf0NB6UoezHEJ5plRhqbfJl4EfDY715bX1IWN0cDI+dZMxqpuMUd2O9TGqbzmEFgtKAcydO5d58+Yxffp0nE4nN954IxMnTgRg9OjRPPzww0ybNo0pU6ZQUlLCyy+/THp6OomJibz55psNLnIuWoY5c53xQcfj0fevxZK5Dsve3/B1HNOwhnQ9mCkFYE39Gdcwoy6GJW0FAL52I2u81dvtNPLO/RJT0V78bYdVO+8adBXu3uceNDBU727ajGVyirewXterrvJMqZqf7fYFuOWzjSRll/DVpgxev3gwcU4bfk3nrb1teBw4wbGLeSf3YctXj9HOkwTA75uS8PgrxqPI4y/roI6lLFPK1/6E4HmvX+O6jzeQU+Ilwm7m7om9OKVnbK39HtAuvNZzQgghmoeiKMGAVLlu3bqxbNmyatdGRkZis9nIzs6me/fuAPj9fvLz8+tVJL2yw7m0026uqCl1LE7i60uW19ZNxujgZHzqJmNUNxmjuskYHVyLBqUcDgePPvoojz76aLVz27Ztq/L5eeedx3nnnddcXRONYElbjuLOxdttcpXj5oy1xgc9J+CO7odj3WuErHyGgrKglHXXDzg2vI6r/+VGBlUtFHceqq+k4nnpK1G8xehWZ7CelC+h5qAUQCC2L4HYvrU0rjRJQApAK8uUUuuZKVW+fE+3R1U7p+s6j/yQRFK28bozijzM/nwTr1wwiKXbMlla2AHsEOPZyymRGZxp+wzKktJsmptRXaLId/nYklFMkdsISpnykzGVZqKbbPgqBejWpRWQU+IlOsTCu5cNJfaA2lRCCCFan6effpo1a9bwxhtvBI9t3bqVbt26VbtWVVUGDBjAqlWrGDnS+Pdy7dq1mM1m+vTp01xdrpPDamRKSaFzIYQQ4ujXuGrTQhxICxC+eAYR31yFKWdLlVOW8kyp9sNwDZmFrlqwpi3DtuNLwr+5ioivp2NN/RnnL3Mh4Kv1EaYiY+leICSeQHhnFM2PZd9fKKXZmPONmmO+hOGH5/U1QMXyvfplSinuPAC0GoJiizak8/WmDFQF7pvYiyiHhW2Zxdz15WZe/SuVApzk2TsCELF4BlbNhYax1K6TU2f+Wf2ICTWW7JVnSgWzpNoOrbJU8a8Uox+jukZLQEoIIY4Q48aN4++//+a1114jNTWV9957j4ULFzJjxgzAqCOVlZUVvP7iiy/mtdde4/vvv2f9+vXMmzeP888/v8HL9w6nikLngRbuiRBCCCEONwlKiSZhKtwdzAyy7VwSPK64cjEV7jY+aTcEzdkOdx8j4y38u2ux7fwGXTGhm0MwlWRgTVlSre1yalk9KS28A95OYwGw7vkZy34jS8of06fGbKPm5jUb62YVT369rlfLglIH9n1rRhHzfzSW4l1zYhfOHNCW/57TD5tZ5a9deWQUeWjjtGLtYATiTEV70VUzpf2mAzC8rQWbWSXMZiREFpZlSpXXk6q8dA9g2e6yoFTnlh9DIYQQ9TNw4ECefvppFi1axNSpU3n77bd54oknGDJkCACLFy9m9OjRwetPP/10Zs2axf3338+MGTMYOHAgt99+e0t1v0YOi2RKCSGEEMcKCUqJJmHK3hz82JryXfBjS+ZaAPyR3cARCUDp0OvQFWPC6Ws7nLzzv6F00EwAHBvfrP0ZZfWkAmEd8HY0glKW1F8q6kkdZOlec/lw9T6e+CsHgJ1701ifVohWxwJipYaaUiVeP3d+uQVvQGd0t2imjzCyofolhPPg6X0oLzt+1ajO6G0HB+9zDboKLcHYfdDkLwUIBqWKPX7QdaxpfwFVg1JZxR52ZJWgACMlKCWEEK3atm3bgsvvAMaPH88XX3zB+vXr+eabb4L1OQGmTZtWrSTC1VdfzZ9//snKlSt56KGHggXQWwu7xZieuiUoJYQQQhz1WrSmlDh6mCst2bNkrUctSkMLaxcscu6PHxz8ZtMiulBw1vsongK8XU8DRcVtiyRk9XNY9/2FKWcrgZjqtS3Kl+9pYR3xdTgBXTVjLtiFkvQVUHuR8+ag6TpP/7KT91bt40zV2P2vID+Hf7y/lnYRdl48byDtImrepa68plTl5Xuv/LmbtAI3CeE2HpjcG7XS7ndje8Ty6Jl92ZlTwtT+bfHmnYiOghbWgZLjZmPd8xsASnlQym6MfJEngCl3G6orB91sxxc/ONjmsl1GllRi2zAiQyxNNCpCCCFEw9klU0oIIYQ4ZkimlGgS5uyqdaSsu4xsqfIi5/42g6qc97U/wSiIrhjfglpYu2CRc8fGt2p8RvnyvUB4R3RrGL54o0i3qTTDaLPdiCZ4JUZG0efr9/PRmjT8gbonxG5fgLu+3MJ7q/YBcFI/o7hsB4eHEIuJtAI3vybn1Hp/RaFzIyi1PbOYD1cbbd01vifh9upBonE9Y/nH8Z0xqwqBmD7kn/cVeed+AZYQdIsRFFPKisJXLN/zYSqrveWP6QuminfGy4NSx3eRLCkhhBAtq3JQqq5sYyGEEEIc2SQoJZpEeaaUp/OpANhSvgNdDxY591fKyqmNa8CVxr3bPkXxFlU7byosW74Xbixl83UaEzwXCO+MFtq28S8AWL03n39+s5VJLy3joaU7mP9jEld/uI69+a5a78kq9nDtx+v5aUc2FpPCf6b0YfzAHgC0t3m5aFh7AJKySmptQ3FVFDrXNJ2Hl+4goMP4XrGc0LV+OwL62wxCDzG2864ISlXNlCr2BFC8Rj90W1jw3oCms1zqSQkhhGglyoNSAF7JlhJCCCGOahKUElV5S4zd8/T6TwIVT2FwaV3p8JsBsOz7C1POFlRXNrpqxh/br852fO1PwB/VE9VXgm3rJ1VP6nql5XsdjK6W1ZWCQ1+69+Hqfcz6cD2LN2fi8Wt0jQ7BaTOxYX8Rl769msWbM6rds25fAZe9s4aN+4sIt5t57twBnJbYptLuewX0iA0FICm7lqCUrlfKlIrig7/3sGF/ESEWE7NP7t6o16JbjGcGg1KVCp0rvuKya5zB67dmFFHg9uO0mejfLrxRzxRCCCGait1cMT2VulJCCCHE0U1qSh3DFG8xpvydmPJ2YM5YiyV9JebsTSi6RslxsykdMade7ZhyjQKqAWcC/rZD8Uf1wJyXROjKpwDwxySCueZ6SlU7pODqfzlhv92HY+NbuAdcAWW1lBR3LorfhY5CIMzIPvLHDUCzRaJ68vEeQlBK03XeWWlkYY3vFcfFw9rTPyGM9CIP9329lXVphfzzm218sHofwztGMqxTJPvyXTz5804Cmk6P2FDmn9WXDpHGdtpaWVBK9RbSI9p43TtzStB0vUptKADFV4yi+QDI0Zw8+q1RMH7WiZ1pE9a4wrMHLt8Lt1cUOi8PVGmVglJ/lS3dO65TFGa1av+EEEKI5mY2qZhVBb+m4/YFwCG1DoUQQoijlQSljjV+F6ErnsC2fSGmkvRaLwtZ8zKuAVeiO+pePla+dM8fkwiAt+tEzHlJ2JIXG8fbDK539zx9ziV02SOY83ZgSVuGr/0oAEyFqQBoofEVtZBUEyUn3IN11/d4u59e72ccaNWefNKLPDhtJuZN7o2t7B3ahHA7L10wiNeXp/LaX7vZklHMloxi3i4LYAFM6B3Hfaf1Cm5fDaDbKrKNOjr9WE0KLp9GWoE7GLgqV77znl+1c/OXOylw+ejVJpTzh7Rv9OsJZkr5XaAFcJZnSnn8qN6yTClraPD6v6SelBBCiFbGblEp9gSk2LkQQghxlJPle8cQc9ZGoj46nZA1LwUDUpojFm+7kZQOuJLCiS+Qc/kKfHEDUPylhKx9uX7tlhU5D5QFpTxdT6ty/sAi5wejW8PwdpsEgGXPr8Hj5fWktLJ6UuXcfS+icMpr6FYnjfX1JmNp3oTeccGAVDmzqnDVqM58efVIHpjcmzP7x9M+wo7TZuKmMV158PQ+VQJSRmet6GYj+GTxFtI1xggA7TigrpSm6yxda2SZZQRC2ZxehN2icveEnoeUsVSeKQVGYKp8+Z6RKVW+fM/oU5Hbz6b9hQCMkqCUEEKIVsJmNv5tleV7QgghxNFNMqWOBbqGY/ULhK54AkXzoTniKBrzb3wdRqPbI6tdXnrcbCIWz8Cx/nVKB8+qM1vqwEwpf/wQNEccqisLAF89ipxX5m1/IvZtn2Ld9xelZcfUsnpSgbJ6Uk2l1Bvgxx3ZAJzeN77W6+KcNqb0jWdK2TW6rqMotQeONFs4Jr/LWMIXG8K2zGKSsksY1zM2eM3n6/ezbPVWLrRCoRLO9BEduWpcD+yBAIe02ZDJjo6Cgg6+UsLLdvXz+DU0T9Wg1N+peQR06BLtICG8HksshRBCiGZQXldKMqWEEEKIo5tkSh0DHGtewrnsERTNh6fbZHIv+gFvj6k1BqQAvF0m4IvtX5Yt9crBG9c1ozA6FUEpFBVP1/HGaXMIgaieDepv+ZI9c+ZaKKuBZCoq23kvrGNttzXKjzuycPk0OkU5GNiAIt8HC0gB6LZI4zp3AT3ijCyu5AOKnf++M5cojF0Gu7bvwI1jutIhKoRDpiiVip2XEGI1Ud7bQHlQqiyzbEVqPgCjutRvlz8hhBCiOZRnLrt9gRbuiRBCCCEOJwlKHeUUdx4hq54FoPiE+yic9ErddaIUhdIRtwJg3/B6sO5RTdTCPai+EnTVSiCqYrc4T8+zAfB2GA2qqZa7a6aFdyQQ1gFF82NJXxl8Tvm5ylbszuPFP3bh16qnFuWUeHn6l5088O025n65hVs/38j8H5Io9viD15Qv3ZvSt02dgaaGqNiBL58esUagKanS8j1/QGP1ngKiFSMoRUjTBoUq78CnKgphZcXOdU/V3ff25bsB6BkXWkMrQgghRMuQTCkhhBDi2CDL945yISufRfUW4Y/pi2vwVcHd7OpSni1lyd5IyNpXKBl1V43XBZfuRfcCteLbydfhRPLO/6bRy+187Y7HtO0TLPv+wtdxDKbg8r2KoFR6oZvbFm3C5dPo08ZZZWkcwDsr9wZ31atsXVohz/xffzx+jZV7CgCCy/KailZW7Fz1FtKjrRHw2ZPvwu0LYLeY2JJRTKkvQFu7EajS7E0dlDJqWil+I9PMaTNT6PajH1DoPLfUC0B0qLVJny+EEEIcCntZvUYJSgkhhBBHN8mUOoqphXtwbHgDgOIT7galAV9uRaH0uNlAWbaUp6DGy8qDUoHYxGrn/HED0O2NK57tLVvCZ933F+g6prJMqUC4EeTSdZ3HfkjC5TMmqxvSCqu1sW6fcez0vm24bVx37ji1B1EOC9syi7nqg3W8ucJoc3jHiCavpxTMlHIXEBNqJcJuRtMhJdcIEq3ckw9Az1CPcX0jx6nW51davgcQXlbsXPFWrSmVW+oDICZEttsWQgjRegSX7/ll+Z4QQghxNJNMqaNY6IrHUTQv3vYn4us4tsH3e7tOJOBMwFS8H1PONvztRlS75sAi502lcl0ptTAVJeBBR0FztgPgpx3Z/LazYlnhxv1Vg1K+gMa2TGNp3D+O70zHKCNzaESnSG74ZAOpeS5S81wAnN6vabOkADSrkSmleAtRFIUecaGs2lNAUlYJifFh/F1Wy6mj3QUloNW1pLKhDghKOcuW75nKMqd0SyiarpPnMoJSUSGSKSWEEKL1sFtk+Z4QQghxLJBMqaOUKXsztm2fAVBywt31XrZXhaKghRgBG9WTX8tzDk9QSgvrSMDZHkXzY9+x0DjmTACTlWKPn/k/JgMwvpexZG9zRjH+QMXEdXtWCd6AToTdTIfIiiyoztEhvHrhILpEG0Eqh0XllJ5xTdp3qMiUUssyzHrEGkGipOwSPH6N9WWZXXFqWeZSky/fM+pYKT4j8FaeKWXyl5Sdd1Lo9hMoq8UVLZlSQgghWpGKQucSlBJCCCGOZhKUOlLoOs5f78H50+2gVy/qDcbSLHPmOmzbPiXs57tQ0HH3OBN/m0GNf2zZDn2KO6/6SV8ppoJdQNMHpVCUYLaUfctHQEU9qed/SyG7xEunKAf/nNQbp82Ex6+RnF0avH1jWdCnf0J4tQLmbcPtvHLBIE7vF8/tp/QgxNqwQuz1ERy3A4JSydklbNxfiMevERtqJSRgnG/6mlLlQSkjCBVWFpSyBMoypaxO8sqW7oXZzFhM8qtACCFE62E3S00pIYQQ4lggy/eOEGpxGo4NbwJQOuI2tNCqS84cq57DueyRKsd01UzJyNsP6blaWa0j1Z1f7Zw5dxsKOoGQNughsdXOHypfu+Oxb/sEU+Fuoy/hHVifVsin6/YDcNf4HtgtJvq1DWP57nw27C+kd7yxq9zGdGPpXv+EsBrbjgqxMm9S7ybvc7ny5XvBTKmy3e12ZJUEl+4N7xSJmm4E+5p6+d6BNaXC7GYs+DHrvrLzIeTmlxU5lywpIYQQrYzUlBJCCCGODZIecYQwZ6wJfqyWpFc7b0teDBgZN952x+Pqewn5Z32EFtn1kJ5bEZSqnillzt4MQKAeWVIBTSe72NOgZ5cXOy/nCW3PA99uQ8eoA3VcJ6Nv/RKMAFB5IAoqakzVFpQ63IKFzsuCUt1iKgqLf78tC4DjOkSguI26WE1f6Lw8U8rIjAqzmQnBXem8M1jkXIJSQgghWpvyoJRkSgkhhBBHN8mUOkJYKgelivfDAUvyTMVG9lDBme/hj+vfZM/VbZEAKDXUlDLlbgPAH9On1vuTskr4enMG327JJLvEy52n9uDcwe3q9WwtvBMBZztMxWkALN1vJzXPRZzTyq0ndwteN6As8FS+ZC+v1MvefCMA069teL2e1dR0W1mhc4/RpxCrifYRdvYVuNldVmB9RIIJRTfeAdbsUTSi6lftzzdXDUo5bWacGM/VTTYwWcgrLcuUCpUi50IIIVoXu0WW7wkhhBDHAglKHSHMmWuDH1fLlAp4UVzZxofOhCZ97sEypdSSTOOZYe2rncsr9TL7801sqpS9BDD/xyTaRdg5oWvV5Wp+TcekULX+U1ldKdO2TwH4dLeR0XPvxF6E2yuye/q1NYJSu/NcFLp9wWd2jQ4hzN4y3+LaAYXOAXrGhbKvwAiWtYuw085SVnTcHAJme/VGDsGBy/fC7WZCFXeVczllmVJRDsmUEkII0bpUFDqX5XtCCCHE0UyW7x0JND+WzPXBT03FVYNSakkmCjq6am36XdyChc7zq51T3Tll11R/5rdbs9iUXoRZVRjXM5bHz+7LecM6oOlw91dbSMo2giXFHj+Pfr+D0U/9xit/7q7Wjq9dxRK+PXoc5wxsWy2gFRViDe6wtym9iA37jaBUvxZaugeVM8wKgoXpu5cVOwc4rmMkatnSvaauJwU11JSqnCllNepuSaaUEEKI1souy/eEEEKIY4JkSh0BTLnbUfyu4OcHZkqpJcbSPc2ZAEpTLgKrI1PKVR5Uial27s8U49x1o7tw2XEdURQ4c3hnkjOKWL23gDmfb+TKkZ146c/d5JQYwZGP1qbxj+M7Ya60E5y3wwloKLh1K4ozgZvHdqv2LDCypfbmu9m4vyi4jG9AiwalypbvaT7wu8HiCO7AB2VFzt2pQNPvvAegWxzG88u+b8LsZkIUT9k5Y2lfbonUlBJCCNE62Szlhc4lKCWEEEIczSRT6ghQuZ4UVA9KldeTCjjbNvmzKzJ+agpKGZlSBwalXL4Aq/fkAzC6W8U5q1nlsbP60inKQVqhhweX7iCnxEunKAcRdjOFbj+r9hZUaSvFH8u13puZ5ZvNPZP7EWqtOY46oKzY+fq0wuDyvf4JLVNPCoxMJV0x6mGoZfW4ynfgAxjeMQKlLKinO5q2yHn586FqplRoeaaUxciUqih0LplSQgghWhe72fg3VIJSQgghxNGtRYNSHo+Hu+++m+HDhzN69GgWLFhQ43WXXXYZvXv3rvbf3Llzm7nHLaO8npQvfghQQ6ZUWVBKC23aelJQOVMqv+oJXUMpy57SD1h+tjI1H29Ap124jS7RjirnIh0Wnjy7HxF2M1aTwtUndOb9y4cxrmcsAD/tyK5y/VebMliijUDrfDLDOkbW2s/yXfb+3p1HiTeA3azSrVJmUrNTlGrFzjtHObh0eAeuPbELsU4b5rztAGiOuCZ/fLWglN2Ms2z3Pc1SvhNg2fI9yZQSQgjRygSX70lNKSGEEOKo1qLL9x577DE2btzIm2++SVpaGnfeeSft2rVj0qRJVa579tln8fl8wc/XrVvHLbfcwsUXX9zcXW4Rloy1AHi6TcKSsSYYhCpXsXzvMGRKldeU8ruMZWhlBbkVT0GlneOqBqX+KFu6N6prdNXC5WU6R4fw6Yzj0HWILAuIjOsZy8IN6fy0I5vbT+mBSVUIaDqLN2cAcEb/+IP2s1cbJ1aTgjdg1G/q2zYMs9q0SxkbSrNFoLrzjLpSGEXcg8sPA17sWz8BwNPttCZ/9oG774XZzIQqRqaU32wEpfIkU0oIIURrogUIXzwDOg3GFj4dkEwpIYQQ4mjXYplSpaWlfPzxx9xzzz3069ePCRMmMHPmTN59991q10ZGRhIXF0dcXBzR0dH897//ZebMmQwYMKAFet7MvCWYcrcZH3abDIDqK0HxVuxqZzqMmVK6NbzaMjSoVE/KGg6miqCGruvBelIndq29VlKEwxIMSAEc1ykSp81EbqmPDWU1oVak5pFZ7CXCbuakbtXrVlVmMan0buMMft6SS/fK6TXswFfOmvIdqiubQEg83s7jm/7ZlqpBKZtZJVw1MqM8aghuX4DSsnefoyRTSgghRCugFqdh3f0DLHsJu8WYe0ihcyGEEOLo1mJBqa1bt+L3+xkyZEjw2LBhw1i3bh2aVvsE5LPPPqOgoICrrrqqObrZ4izZG1B0jYAzgUBkNzSrsUxNrbQDnxqsKdX0QSkUpdIOfBV1pZRgPamqgadduS72F3qwmhSGd4qs92MsJjUYePopyVjC99VGI0vqtD5tsJrr/latHIjq34JFzsuVB6UUb/WglGPzewC4Ey8AU9MHhQ5cvgcQZTYKnbsVe7CelNWkEGo1NfnzhRBCiIYq3x0WXwk21ZgLumX5nhBCCHFUa7GgVFZWFlFRUVitFVk2sbGxeDwe8vPza7xH13X+97//cfnllxMa2oL1gpqROd0ocu5vMxioyIaqXFeqyu57h4FWVuy8cl0p1W0EpfRalu4N7RiJw9KwYMcplepKFbp9/FwWnJpax9K9cpUDUa0hKKWVZ0q5qwal1ILdWPf8io6Cu++Fh+XZwUwpf2nwWJTJCEq5FEelelLWGpdYCiGEEM2tfCMOAKduvKkimVJCCCHE0a3Fakq5XK4qASkg+LnX663xnuXLl5Oens7555/f6Ocerr+/y9tt6vYtZUXO/fGDUZSyulF52zGVpONXAM2PWpIJgO5MOCyvTy8vdu7JC7Zfeee9ys+svHSv8vH6jM+orlHYzSr7Cz08+2sK3oBOj9hQEuOd9Xpdw8qWAHaOCqFNmK3er+9wCRY69xZW6b9jy/sA+DqNQY/oRPmpJv0espZlSvndRu0v1US4agSlSnCQ5yqvJ2U5bD8Th8Ph+jk7msgY1U3GqG7H+hi15tft9XqZNm0a9913HyNHjgRg7dq1PPLII2zbto02bdowc+ZMzjvvvFrbGD58OEVFRVWOrV69uuXf8DNZ0M0OFL8Lh2YEpaSmlBBCCHF0a7GglM1mqxZ8Kv/cbrfXeM+SJUsYM2YMkZGRjX5uTMzhzaBp8vaz1wMQ2utEQmPDIKYj7IEwPYew2DAoTAM9AIqJ6E7dQG3apVgBTUcJi4F0CDe7ILbs9anFANii4rGVHSty+1i7z8gKmjqsI7E17H5X1/icktiGxRvSWbjByAS7cGQn4uLqVx8qNhZ+um0cdotKmL0V1EmKNHbVC1VdxtcOIOCDrR8BYD1+JrGx1cejSb6HfBWvPzZcBXsYEWYPeMFvC8OnGkmSbaNCauxDa3e4f46PBjJGdZMxqpuMUevi8XiYM2cOO3bsCB7Lysriqquu4qKLLuKRRx5h06ZNzJ07l7i4OE4++eRqbWRkZFBUVMT3339fZb4VEhLSHC+hTpotHJPfhUM3Mn09fg1d1yWrVwghhDhKtVhQKj4+nry8PPx+P2az0Y2srCzsdjvh4TUHIX777TduuOGGQ3puTk4Run5ITdRIUYzJe1O2r5RkElOwBx2FXFsP9OwiQswxhACuzFRKsoswp+8gEgiExpOXW1pHi/Xj8gZYtjuPX5Jy+C05h3/h5iygJDsdV7bxzmpozn4cQKkSTmnZsZ92ZOML6HSMtBOGRnZ2xbuw9R2fEztHsrgsIGVSFcZ0iqjSTl0UwOMBT7G7oS+7yTk0O6GAOz+b4rLXYE36mvCSTLSQNuTGjIZGjFG96DoxiglFD5CTkYkeqhCiG7vvZblUdmeUfR3NSoPGt6Udjp+zo42MUd1kjOp2rI9R+etvTZKSkpgzZw76AV+Q77//ntjYWG699VYAunTpwvLly/nyyy9rDEolJycTFxdHx44dm6PbDaZbw6EkA3ug4t8mj18LFj4XQgghxNGlxYJSiYmJmM1m1q5dy/DhwwFYtWoVAwYMQFWrl7rKzc1lz549DBs27JCeq+sc1gl2U7ZvyVgLQCC6F5rFCToEymtKFaej66AUV9STaorn/pKUw32Lt+DyVaTLZ5lDwAy6Ky/4DKW0bPmePSZ47I+dxtK9E7pG19qXusbnhC7RWEwKvoDOiV2jiQqxHrF/EGnWSAAUT0HwNdg3GQXOXYkXoKsWqOG1Nc33kIJuCUHxFqF4S9BCCAalCgMVhc6jj9DxPdw/x0cDGaO6yRjVTcao9VixYgUjR45k9uzZDB48OHj8pJNOIjExsdr1xcXFNbaTlJRE165dD1c3D5letqGLLVACGBnXEpQSQgghjl4tVujc4XBw9tlnM2/ePNavX8/333/PggULuPzyywEja8rtrsh22bFjBzabjQ4dOrRUl5udOcMocu6LHxw8poW2BSoKnZvKd94LPfQi55lFHh74dhsun0a7cBsXDW3P/DP7UmoyMtd27t0XvFYt24lPcxg75gU0PVjk/MRu0TSW02bm1F7GsrfzBh+ewu3NJbj7nicfALUwFeueXwBw973o8D+/vNi5z8igC8EISuUHbOSWlBc6bwXLHIUQQtTp4osv5u6778bhcFQ53qFDhypBqpycHL7++mtGjRpVYzvJycm4XC4uu+wyRo8ezVVXXUVKSsrh7HqDlNdjNPuKManGkj0pdi6EEEIcvVosUwpg7ty5zJs3j+nTp+N0OrnxxhuZOHEiAKNHj+bhhx9m2rRpgDHJCg8PP3ZqCgR82Hd8AYC/7fDgYc1ZNSilFjfNznu6rvPvJdsp8vhJjHey4KLBmE1GzHJHSlfYAemZ+ynJKqFHXChKWaFz3WEEoP7alUtWsZcIu5mhHSIPqS/3TOjJVaM60ynKUffFrZhWNrFWPYUA2DcbBc69HceihXc67M/XLWXFzn1GsVi7ZgSl8vxWcgMVmVJCCCGODm63mxtvvJHY2FguuOCCGq/ZuXMnBQUF3HrrrTidTl599VWuuOIKvv76a5xOZ4331ORwTcfKg1KqtwC7uR0l3gCegNaqi883t2N9I4L6kDE6OBmfuskY1U3GqG7H+hjV93W3aFDK4XDw6KOP8uijj1Y7t23btiqfT5kyhSlTpjRX11qcbftnmAp3ozlicfc8K3g8UJ4pVZoFAV8wOHWoQalP1+1n2e48bGaVByb3CQakAPp17QQ7IIJi7vtmK29cMgTVXbH7HsBn64zg2On94rGZDy0Bz24xHfEBKaicKVVgBBm3fAiAq9/FzfN8c1nR2rJMKWvZ8r0cv5XcUiNTKkoypYQQ4qhQUlLCddddx65du3jvvfeqZVSVe+211/D5fMGd9h5//HHGjh3LTz/9xBlnnFHv5x22mlvhxptdoSYvDquZEm8Ah9N+RG7Kcbi1trpnrZGM0cHJ+NRNxqhuMkZ1kzE6uBYNSolaBHyErnwGgNIh14ClYkcc3RGDrlpQNB9qaSZqcVlQ6hCW76XmuXj6l50AXH9SV7rGVN2BR7cbE8QYtYTtWSW89tdu7nUZS/U0ezTphe7g0r1zBhzZS+6aUvm7vYqnEOuupZhKM9EccXi7TGye5x+QKWUNGMGpHK+VvLKaUjGSKSWEEEe84uJiZs6cSWpqKm+++SZdunSp9Vqr1YrVWvG7v7w0QkZGRoOeebiK4IfqDhyAKz8ba9l7XOlZRcRZjtG3mWtwrG9EUB8yRgcn41M3GaO6yRjV7Vgfo/puHCNBqVbItv3zsiypGFz9L696UlHRQuMxFe1FLUnHVFJWU6qRmVIBTWfeN1tx+zWGd4zggiHtql2j2yMBaG91gRs+XrGd+2wewMiUWrQiHU2HYR0j6BLTOraUbg00WyQAqq8Yx8a3AHAnng+m5slOqlJTKuDDpBnZUekeM/kuIyglmVJCCHFk0zSNG264gb179/L222/TvXv3Wq/VdZ0JEyZw3XXXBcsjlJaWsnv3brp169ag5x6uIviatfwNnQJsZcXN3T7tmJzM10U2IqibjNHByfjUTcaobjJGdZMxOjgJSrU2mp/QlU8DUDrk2ipZUsFLQtsaQani/ZUypdo26nErUvPYsL+IUKuJ+yf1Rq1h4admjwLA7i/klB4x7EjeDIButuM3OVi00ejDtIGSJVVZeaYUgHXv7wC4mqHAeVB5UMpfiuKr2IUpuUhBBxQg0iFBKSGEOJJ98sknLF++nBdffJHw8HCysrIAsFgsREZG4vV6KSgoIDo6GpPJxMknn8yzzz5L+/btiY6O5umnn6Zt27aMHTu2hV+JoXz3PcVbhL2sHIDbH2jJLgkhhBDiMJKgVCtj2/ZZ7VlSZQKhbbEA5uxNKJoXHQUttE2jnvfN5kwAJie2ISHcXuM15Rk/iubljrHt+PfelQAUqhH8sTOHrGIvkQ4LJ/eIbVQfjlqqGc0Silq2fM7bcQxaRJdme3zl5XvlO/B5dAuugPHOc6TDEtzZSAghxJFpyZIlaJrGrFmzqhwfMWIEb7/9NmvWrOHyyy/nhx9+oEOHDtx+++2YzWbmzJlDcXExxx9/PK+88gomk6mFXkFVwaXv3qJgjUrZfU8IIYQ4eklQqjWpnCU1+Joas6Sgoqi5JX218XlIHJgaXhvI5Qvwc1I2AJP7xtd+oSUEXbWiaF7iTKVc2T8ENkKqO4RX/twNwBn94rEeYoHzo5Fui4CyoJSrb/MUOA8+u9LyPcVrZEqVYAuejw6VLCkhhDgSVd4M5rXXXjvotSNHjqxyvc1m46677uKuu+46bP07FBXL9wqxm41AmQSlhBBCiKOXRBFaEeuu740sKXs0rgHTa72ufKmeOXOd8Xkj60n9kpSDy6fRPsLOgISDFCBTFLSyulKqO48RbYzJYY4ezvYsI+Byjizdq1H5O76aIxZv1+YpcB58duWgVNnyvRK9YjemKClyLoQQopXRbcZ8RPUUBjOl3D5ZvieEEEIcrSQo1YrYUr4DwN17Wq1ZUgCa0whKqWWBhsbWk/pmi7HTzqTENig11JKqTC+rK6W481HLdt4rUIyAy4hOkXSMqnnr6WNdeT0uo8B58waBqi7fK8vWUiq+TjFS5FwIIUQro1srlu/ZLeU1pSRTSgghhDhayfK91kILYN31PQDeLhMOfukBQajGZErllnpZvisPMIJSdXavfCc5dx6qOweAXl060zHTztUndG7w848VrsHXoIW0MZZjNrOaglJuVTKlhBBCtF5SU0oIIYQ4tkhQqpUwZ6xBdeeiWcPxJYw46LWBA4JQB35eH0u3ZhHQoW/bMLpE156VVU4vW76nePKCmVId23XgszMO3tdjnbfLqXi7nNoiz65YvudC8RpBKY9a8bWOlkwpIYQQrUxw972AB6fqByRTSgghhDiayfK9VsK2aykA3s7jwHTwYIEWGn/A5w0PSn2zpWLXvfooX4amuvNRXEamlO6IbvBzRfPRzeVBqZJgTSm/SYJSQgghWi/d6gSMkgLhqguQmlJCCCHE0UyCUq1EfZfuAWCyodkrAkINXb6XmudiU3oRJgUm9I6r1z3BTCl3HmpZUEqzxzTouaJ5VVm+V7b7nt9cEZSS5XtCCCFaHUWFsiV8kWVBqVKvBKWEEEKIo5UEpVoBtWA35txt6IoJb6eT63VP5bpSDV2+9/Vmo8D5iM5RxITWLzARzJTy5KO6jeV7mkOCUq1Z1d33SgEIWJzB81LoXAghRKtkN4JSMSYjKFXo9rdkb4QQQghxGElQqhUoX7rnazcimJFUl4CzIihV39338l0+/vPddhYsSwVgct/6Ld0D0MsKnSvuPFm+d4QIBqX8pcHle+XZUyCZUkIIIVopewQAUSY3AIVuX0v2RgghhBCHkRQ6bwUatHSvTHkdKc0eDWb7Qa/VdZ3FmzN56ped5LuMid20gQlM7F3/oFQwU6okA7VsJzfJlGrdqi7fM75mWCsypaSmlBBCiFapbPlehFoKRFIgmVJCCCHEUUuCUi1M8RRiSVsGgLfL+Hrfp5VlStUnS+qnpBzmfbsNgG4xIcwd35PBHSIa1M/yDC5T/k7jc9WMbg1vUBuieVUEpUpRyzKlTDYjKBViMWG3mFqsb0IIIUStypbvhWMsPS9wSaaUEEIIcbSSoFQLs6b+gqL58Uf1IBDZrd73BSK6Gv+P7Frntct2GTWgTusTxz8n9cZiaviqzWCmVHmWlD0aFKXB7YjmE1y+F/CgeAoBUMuCUtGhkiUlhBCilSrLlHKWBaWkppQQQghx9JKgVAuz7voOaFiWFICn+xSKfI/i7Ti2zmuTsoxA0pjuMY0KSEFFTang51JPqtUrD0oBqKWZAISFRwLQMdLREl0SQggh6lZWUypEM4JSbr+Gx69hM0spVCGEEOJoI0GplqTrWFN/BhpWTwoAkxV3v0vqvEzTdZKyjaBUrzhnHVcfpJ2yTKmKz6WeVKunWtFVM4rmRy3NAqBTfBxPT+tPz7jQOm4WQgghWkjZ8j1boAiTAgHdKHYe57S1cMeEEEII0dTkLacWZCpIQXXnoZts+OKHHpZn7Mt34/IZ7y52iDqE7BizHd1ccb8UOT8CKAq62ciWUt3GEk6sTk7oGi0TeyGEEK1X2fI91VtEmN1Ybl7gkiV8QgghxNFIglItyJyxFgB/XH8wHZ4aPzuyjALX3WJCMKuHVgNKKyt2DrJ870hReQmf8blkSAkhhGjlypbvKd4iIuxGUn+BW4qdCyGEEEcjCUq1IHPmOgB8bQYdtmfsKKsn9f/t3Xl4VOX5//H3mT37nrDKDkKEsAlasSoiotWqqK3WutS1Ktpv+2tVoBV3irZqq9YdxWpdUKui1rpvdQcBAcGwGghk3zP7nN8fkwzEAJOBJEOSz+u6csGcOXPOfW4iPtx5nvtpj+VapnPnEj7NlOoafliEMu37voRTRESkUzQt3zN8taQ2zZRSs3MREZHuSUWpOLKXLgcgkDu2w+7RXJQauh/9pJrtOlNKRamuodVMKYdmSomIyAHO2TRTyltLWkLTTCm3ZkqJiIh0RypKxUvQj61sFQCBvLEddpvCSJPzdpgptUuz85BLy/e6Ai3fExGRLqdp+Z5ll+V7miklIiLSPcVclLr22mv58MMPCQaDHRFPj2GrXIcR9BJyphFMG9gh96j3Biiu8QAwNHv/ixEhZ3rk9+op1TXsWoQyLQ6wOuIYjYiISBs0L9/z7ly+p55SIiIi3ZMt1g8kJyczd+5c/H4/06dP58QTT2Ty5MkYxv410e5pdjY5HwNGx0xY29A0Syo32UFawv43Um85U0rL97qCFkUpLd0TEZGuwNncU6qONJcVgBrNlBIREemWYq6G/OlPf+LDDz/k73//Ozabjd///vcceeSR3HrrrSxfvjyma3m9XubMmcPEiROZMmUKCxcu3OO569at4+yzz2bMmDGcfPLJfPbZZ7GGfkCxNfWT8nfg0r3vIk3O26e5tXpKdT2mbefyPTU5FxGRLqF59z0zSKYjXIzS8j0REZHuaZ+m6BiGwaRJk7j++ut54403OOOMM3juuec4++yzOfbYY3nwwQfxer1Rr3P77bezatUqFi1axLx587j33nt54403Wp1XV1fHhRdeyNChQ1myZAnHHXccs2bNoqKiYl/CPyB0RpPz9e248x5AqGmmlInRYtaUHLh27SmlmVIiItIl2BMwLeHJ/NnWcBsCNToXERHpnmJevgfQ0NDAe++9xxtvvMHHH39MXl4ev/rVrzjxxBMpKyvjL3/5C1988QWPPvroHq/R2NjI4sWLefjhh8nPzyc/P5/CwkKeeuopZsyY0eLcf//73yQmJnLDDTdgtVq5+uqr+eCDD1i1ahVHHXXUvjxCfPkbsVZ+B0Agr6DDblNYVg+0X1GquRBlutLBYm2Xa0oH23X5npqci4hIV2AYmI4UDE8VmVY3oJlSIiIi3VXMRanLL7+cTz75hNTUVE444QSeeOIJxowZE3l/+PDh1NbWMnfu3L1eZ+3atQQCAcaNGxc5NmHCBB544AFCoRAWy85JXF988QXHHnssVuvOQsgLL7wQa+gHDHvZNxhmiGBSL0JJvTrkHiHTZH15+y7fC6b2D//aQY3Zpf21mCml5XsiItJFmM5U8FSRbgkXpdToXEREpHuKuSiVnZ3Ngw8+uNfm5hMnTmTx4sV7vU5ZWRkZGRk4HDt3A8vOzsbr9VJdXU1m5s7d3YqKihgzZgx/+tOfePfdd+nbty/XXnstEyZMiDX8A4KtdAUAgdyOmyW1rdqD2x/CYTXon5HQLtcMZo2k+qR/Ekwf3C7Xk46n5XsiItIVmY5ws/NUww0kaKaUiIhINxVzT6mbb76ZDRs28Nprr0WOXXnllTz99NOR1zk5OQwZMmSv13G73S0KUkDktc/na3G8sbGRhx56iJycHB5++GEOPfRQLrroIrZv3x5r+BhGx3219fqRflJ54/b5XpWNPq5bsoZPN1fu9v3mWVJDspOwW412e8bAwGMw0wd0aH568ld752jXQpRpT4778x2IOeqOX8qRcqQctc/zS/yEHCkAJBNuReANhPD4g/EMSURERDpAzDOl7rrrLl588UVuvPHGyLHJkyfzj3/8g8rKSq688so2XcfpdLYqPjW/drlcLY5brVZGjhzJ1VdfDcCoUaP43//+x8svv8yvf/3rmOLPykqJ6fxYten6ZSsASBp2GEnZ+xbPw198yzvflVNY3sgHEw/ih7PWtn4dLtgd0i+d7H28R0fo6Px3B+2ao4ydMw5dqRm4DqDvhf2h76PolKPolKPolCOJF9MZninlCjZgteQSDJnUeAK47OppKSIi0p3EXJR64YUXuPvuu5k4cWLk2HnnnceIESP4wx/+0OaiVF5eHlVVVQQCAWy2cBhlZWW4XC5SU1NbnJuTk8PgwS2XjA0cOHCfZkpVVNRhmjF/LCrDCA/eo13fcFeSVb0lHItrGGZ5Xcz3CoZMXli6FYDvKxt5e8U2xvVLa3HOyi2VAByU6qR8H+7R3tqan56sI3Jk91hp/s5oDNppPAC+F/aHvo+iU46iU46i6+k5an5+iZ/m5XsWfx1pLhuVjX5qPX7yUpxxjkxERETaU8zL99xuN8nJrRsmZ2RkUFfX9n/wjhw5EpvNxvLlyyPHli5dyujRo1s0OQcYO3Ys69ata3Fs48aN9O3bN7bgAdPsuK+2XN9WEn7eQPoQQo60fbrP51uqKG/YOcvslW92tDrnu7Lw8r2h2Ukd+sztnZ+e/tXuOdqlp1TInhz35zsgc9QNv5Qj5Ug5ap/nPxD5fD5OOukkPv/888ixoqIiLrjgAsaOHcuJJ57Ixx9/vNdrvPrqq0ybNo2CggKuvPJKKisrOzrsmJnOcFHQ4q0jzWUHoMatvlIiIiLdTcxFqSOPPJJbb72V4uLiyLGSkhIWLFjAlClT2nydhIQETj31VG644QZWrlzJ22+/zcKFCznvvPOA8Kwpj8cDwFlnncW6deu455572LJlC3/7298oKirilFNOiTX8uGuPJuevrS4BYFSv8IDt7e/KaPTt7LNQUueluCacu6E5am7dk5m2XXff0/eCiEhX5vV6+d3vfkdhYWHkmGmaXHnllWRnZ/PCCy9wyimnMGvWrBbjtF2tXLmSuXPnMmvWLJ599llqa2uZPXt2Zz1CmzXPlDJ8taS6wjPqa7UDn4iISLcTc1Hq+uuvx+/3c+yxx3LYYYdx2GGHcfTRRxMKhbj++utjutbs2bPJz8/n/PPP58Ybb+Sqq65i+vTpAEyZMoXXX38dgL59+/LII4/w3nvvcdJJJ/Hee+/x0EMPkZeXF2v4cWffsRQAf97Yffp8vTfA++srALhm6hD6pbtw+0O8W1gWOefvH2wEYGzfVNIT7PsXsHRpuxaiTEfrGY4iItI1rF+/np/97Gd8//33LY5/9tlnFBUVcdNNNzFkyBAuu+wyxo4dywsvvLDb6zz55JOccMIJnHrqqRx88MHcfvvtfPDBBxQVFXXGY7RZqKmnlOGtJa1pLFOtHfhERES6nZh7SmVmZvLMM8+wdu1aNm/ejM1mY+DAgQwdOjTmmyckJLBgwQIWLFjQ6r0fLtebMGECL774Ysz3OKCYIWw7lgEQ6H3oPl3i3e/K8QZCDMxMYFSvFE7Kz+OB/23h1dUlnJTfi6++r+bNdWVYDPj9MbH/mUj30qIotctSPhER6Vq++OILJk+ezG9/+1vGjh0bOb5ixQpGjRpFYuLOv+MnTJjQoj3CrlasWMEll1wSed27d2/69OnDihUr6N+/f0eFHzOzafc9w1e3c6aUWzOlREREupuYi1IAgUCAjIyMSENy0zTZtGkT3377LSeeeGK7BtidWCsLsfhqMW0JBLJG7tM1XlsTXrr3k1F5GIbBT0bl8eD/trC0qIYtlY3c/s56AE4v6MOIPM2M6el2LUSZdn0/iIh0Vb/4xS92e7ysrIzc3NwWx7KystixY8duzy8tLY3p/D35waa/7SZy3aaZUhZfLWnJzcv3Ah12366kOQfKxZ4pR3un/ESnHEWnHEXX03PU1ueOuSj19ttv86c//Ynq6upW7+Xk5KgotRf2HV8B4M8bB5bY64Hbatws21qDAcwYGR5Q9kp1cehB6XzxfTW/e2k131e5yUiw8+sjBrRn6NJFtShKafmeiEhcbNiwgdzcXFJSUvjoo4949913GTVqFGeeeeZ+X9vtduNwOFocczgc+Hy+3Z7v8XhiOn9POnp3wpSccIsGe7CBPtnh/395gexs7YrYTDtERqcc7Z3yE51yFJ1yFJ1ytHcxV0b++te/ctxxx3HBBRdw9tln89BDD1FdXc3NN9/MFVdc0RExdhuRolSvifv0+f+sKQVg4kHp9Ep1RY6fdEgeX3xfzfdVbgBm/XgQqS71khLA6sC02DFCfjU6FxGJg2effZabbrqJxx57jOTkZC6//HIOO+ww3nrrLYqLi/nNb36zX9d3Op2tflDo8/lwuVx7PP+HBSifz0dCQkJM962oqOuQXQoNIzx4r/bYSAeCjdVYg+HNXEqr3ZSXt32n5+6qOUcd9WfQHShHe6f8RKccRaccRdfTc9T8/NHEXJQqKiriwQcf5KCDDuKQQw6hrKyMadOmYbFYuP3225k5c+Y+BdwT2LaHi1KB3rEXpUzT5PWmpXsn5bds8H7M0GySHOtp8AUZ3Tu11fvSswWyDsZavYlQSt94hyIi0uM88sgjLFiwgEmTJnHzzTczcuRIHnnkEb788kt++9vf7ndRKi8vj/Xr17c4Vl5e3mqJ3q7nl5eXtzo/JycnpvuaJh06wA4195Ty1pLW9IO2Gre/Rw7q96Sj/wy6A+Vo75Sf6JSj6JSj6JSjvYt5973U1FTc7vCMnEGDBrF27VoABg8ezNatW9s3um7EcFdgq9kEgD9vfMyfL6nzUlTtwWrA0UOzW7znslu5cPJB9Et3Mee4YVh66qJV2a3q016k8tz/RZrGiohI5ykpKWHChAkAvPfee0ybNg2AXr160dDQsN/XLygoYPXq1Xg8nsixpUuXUlBQsMfzly5dGnm9fft2tm/fvsfz48V0pgFg8deT6gyPa2q0+56IiEi3E3NR6qijjuLGG29k/fr1TJ48mZdffpnVq1fz7LPP7vGncgL2HeEBYCBjOKYrPebPF5aFB66DspJIdFhbvX/epP78+6JJDM3REi35AXsCZkJWvKMQEemRBg8ezJIlS3j++ecpLi5m2rRp+P1+Fi5cyMEHH7zf1580aRK9e/dm9uzZFBYW8tBDD7Fy5UrOOOMMILw0r6ysjGDTErizzz6bl19+mcWLF7N27VquueYajj766ANq5z2gxQ9SMm3h5YYqSomIiHQ/MRel5s6dy4ABA1i1ahXTpk2joKCAM844g6eeeoprr722I2LsFiL9pHpP2KfPf1dWD8AwFZ1ERES6jGuvvZZHH32UP/7xj/ziF79gyJAhzJ8/n7feeou5c+fu9/WtViv/+Mc/KCsrY+bMmbzyyivcd9999OnTB4Cvv/6aKVOmsH37dgDGjRvHTTfdxH333cfZZ59NWloa8+fP3+842p3VgWl1ApBhaQSg1uPH1PoHERGRbiXmnlLvv/8+11xzDRkZGQD85S9/4YYbbsDpdGK3q7n2nti3Nzc5P3SfPt88U2p4rnZQExER6SoOP/xwPv30U+rq6khLCy9Ju+KKK5g9e/Y+j5vWrVvX4vWAAQN48sknd3vu5MmTW50/c+bMLtEDNORMw9pYSqoRbhvhD5q4/aHdzhgXERGRrinmmVI33ngjVVVVLY4lJyerILU3QR+20hXAvjU5B/iuVDOlREREuqKPP/6YQCC89Oz5559nzpw53Hfffa12wZOWmpfwJYTqsVvDfaVqPf54hiQiIiLtLOai1OTJk3n11Vc1kIqBrWwVRtBLyJVBMG1QzJ9v8AUoqg43MB2uopSIiEiXcd999/Gb3/yGrVu38sUXX3D99dfTu3dv3nrrrQNz2dwBpLkoZfHVkdq8A5/6SomIiHQrMS/fq6io4B//+AcPPPAAmZmZOJ3OFu+/88477RZcd9Hc5NzfayLsw85465uW7uUmO8hIdLRrbCIiItJxnnvuOe655x4KCgqYO3cuhx56KDfeeCPffPMNF198MfPmzYt3iAes5h34DF8taa5MKhp81Lg1U0pERKQ7ibko9bOf/Yyf/exnHRFLt2Xf8SUA/n1dutdUlBqWo35SIiIiXUlNTQ2DBw/GNE3ef/99LrnkEiDc+qB5RzzZvVDTTCnDW0eaKzxkrdVMKRERkW4l5qLUaaed1hFxdF+mia2pyXmg1/71kxqeq6V7IiIiXcnBBx/Mo48+Snp6OpWVlRx33HGUlJRw5513Mnbs2HiHd0AznTuX76UlNC/f00wpERGR7iTmotS5556LsZclaE888cR+BdTdWOq2Ym0sxbTY8OeO2adrRHbe00wpERGRLuWGG27g2muvZdu2bfzud7+jb9++3HrrrWzbto2//e1v8Q7vgGY6UgEwvDWkaqaUiIhItxRzUWry5MktXgcCAYqKivjggw+4/PLL2y2w7sJe8jUAgex8sCXE/PlAyGR9efPyPc2UEhER6UoOPvhgXn755RbH/vCHP+BwqEdkNCFXBgAWTxVpTY3Oq9VTSkREpFuJuSg1a9as3R5/8cUXefPNN7nooov2O6juxFa6AoBA7th9+nxRlRtvIESC3UK/9NiLWiIiIhJfa9as4dFHH2Xjxo0Eg0EGDRrEOeecw6RJk+Id2gEtlJgLgKWxlNRczZQSERHpjiztdaFDDz2UTz/9tL0u123YSpcD4M8t2KfPF5aF+0kNzU7Gaol95z4RERGJn7feeouf/exnmKbJzJkzmTlzJoZhcOGFF/L222/HO7wDWigxBwCjsYzUpp5SKkqJiIh0LzHPlCouLm51rKGhgUcffZS+ffu2S1DdRiiIrWwVAIF97Ce1rrSpn5SanIuIiHQ5f/vb3/j973/PBRdc0OL4448/zj333MO0adPiE1gX0DxTytpQSnpTT6kaLd8TERHpVmIuSk2dOhXDMDBNM9Lw3DRNevfuzW233dbuAXZl1uoNWPwNmLZEghnD9uka3zXNlBquflIiIiJdTlFREcccc0yr48cccwx33nlnHCLqOkJJ4aKU4akg1Rme3K+ZUiIiIt1LzEWpd955p8VrwzCw2+1kZ2fvdVe+nqi5n5Q/ZzRYrPt0jcjOe7naeU9ERKSrGTJkCB9++CHnnntui+MffPCBZphHYboyMQ0Lhhki26gFoMajmVIiIiLdScxFqb59+/LUU0+RlpbGSSedBISbnx9xxBGcffbZ7R5gV2Zv6ie1r0v3yht8VDT4MIAh2ZopJSIi0tVcddVVXHXVVaxYsYKCgnB/yeXLl/Pf//6X22+/Pc7RHeAsVkIJ2VgbS8kIVQFQ4wm0mK0vIiIiXVvMjc7vuusu7r//fhITEyPHJk2axD/+8Q/uu+++dg2uq7OVrgQgsJ9Nzg/KSCDBvm8zrURERCR+jjnmGB5++GG8Xi9PP/00L774IqZp8q9//YsTTzwx3uEd8JqbnacFKwEIhkwa/cF4hiQiIiLtKOaZUi+88AJ33303EydOjBw777zzGDFiBH/4wx+48sor2zXALivow1a+BtiPnfdKtXRPRESkqzv88MM5/PDDWxzzer0UFRXRv3//OEXVNYSbna/G6avAaeuLNxCixh0gyRHzEFZEREQOQDHPlHK73SQnty6SZGRkUFdX1y5BdQe2ynUYQS8hZxqhtIH7dI21peGZUsPU5FxERKRb+eKLL5g+fXq8wzjgNe/AZ2ksI7V5Bz71lRIREek2Yi5KHXnkkdx6660UFxdHjpWUlLBgwQKmTJnSrsF1ZbaScJPzQM4Y2Me+ByuLw009D+md0m5xiYiIiHQVZtPyPUtDCdlJDgDK633xDElERETaUcxFqeuvvx6/38/UqVM57LDDOOywwzjqqKMIBoPMmzcvpmt5vV7mzJnDxIkTmTJlCgsXLtzjuZdffjkjRoxo8fXee+/FGn6nsZU1FaX2cenejloPJXVerAYc0ju1PUMTERER6RKae0pZGsvITXYCUFrvjWdIIiIi0o5iXpCfmZnJM888w7p169i0aRM2m42BAwcydOjQmG9+++23s2rVKhYtWkRxcTHXXnstffr0YcaMGa3O3bBhA3fccUeLngxpaWkx37Oz2JtmSvnz9q0otWJbeJbUiLwUNTkXERGRHimYlAc0FaXSwkWpkjoVpURERLqLmItSPp+Pu+++m759+3LOOecAMHPmTH70ox/xm9/8Brvd3qbrNDY2snjxYh5++GHy8/PJz8+nsLCQp556qlVRyufzsXXrVkaPHk1OTk6sIXc+vxtr5ToAAjn7VpRavq0GgII+miUlIiLSlXz55ZdRz1m3bl0nRNL1RZbvNZaQ2ze8fK9URSkREZFuI+ai1C233MLSpUu56aabIseuuOIK7r77bjweD3/84x/bdJ21a9cSCAQYN25c5NiECRN44IEHCIVCWCw7VxZu3LgRwzC6zA41tvLVGGaQUEIOoeTe+3SNFU39pMb2VVFKRESkKzn33HPbdJ6xjz0ne5IWy/dSmmZKqaeUiIhItxFzUerNN9/kscceY+TIkZFj06ZNIy8vj8suu6zNRamysjIyMjJwOByRY9nZ2Xi9Xqqrq8nMzIwc37hxI8nJyVxzzTV88cUX9OrVi6uuuoqjjjoq1vA7hb10l6V7+zDgrPMEWF/WAMCYvgfuEkURERFpbe3atfEOodsIJjYt3/M30CchCGimlIiISHcSc1HKNE283taDAdM08fvbvkWv2+1uUZACIq99vpY/Adu4cSMej4cpU6Zw6aWX8tZbb3H55Zfz7LPPMnr06Jji76gfSjZf1zBaNjnfl/ut2lGLCfRPd5GT7Ih6flewa35k95Sj6JSj6JSj6JSj6Hp6jnrqcx+QHEmYtkSMQCN9bOFZ5CV1XkzT1EwzERGRbiDmotTxxx/Pn/70J+bNm8eoUaOA8E8Eb7nlFqZNm9bm6zidzlbFp+bXLperxfErrriCc889N9LY/OCDD2b16tU899xzMRelsrJSYjo/VllZKVCxGoCkoYeRlB37/b5bWgzApMHZZO/D5w9kHZ3/7kA5ik45ik45ik45ik45kgNBKDEHa+0WcqgGwBsIUesJkJbQtj6mIiIicuCKuSg1e/Zs5s6dy/nnn08oFMI0TWw2G6eeeipXXnllm6+Tl5dHVVUVgUAAmy0cRllZGS6Xi9TUln2ULBZLq532Bg8ezPr162MNn4qKOkwz5o9FZRjhwXtFRR0Z9WVYgCozg2B5XczX+qSwDICR2QmU78PnD0S75qcj8t8dKEfRKUfRKUfRKUfR9fQcNT+/HBhCSblYa7fg9JaTnpBFtdtPab1XRSkREZFuIOaiVEJCAnfeeSe1tbVs2bKFYDDI5s2bWbJkCdOmTWP16tVtus7IkSOx2WwsX76ciRMnArB06VJGjx7dosk5wHXXXYdhGMyfPz9ybO3atQwfPjzW8DFNOnSAbZpgBBoBCNmSYr6XPxhi9Y5wIaqgT1q3+8dAR+e/O1COolOOolOOolOOolOO5EAQSswFws3O81L6hItSdT6GdYENmUVERGTvYi5KNSssLOSll17ijTfeoL6+niFDhjBnzpw2fz4hIYFTTz2VG264gdtuu43S0lIWLlwYKTyVlZWRkpKCy+Vi6tSp/O53v2Py5MmMGzeOJUuWtNoB8IARCmIEPACY9sSYP762pB5vIESay8aAzIT2jk5ERESkS9m5A18puckO1pVCSZ0nzlGJiIhIe4ipKLVt2zZeeuklXn75ZYqKikhNTaW+vp6//vWvnHjiiTHffPbs2dxwww2cf/75JCcnc9VVVzF9+nQApkyZwvz585k5cybTp09n3rx53H///RQXFzNs2DAeeeQR+vXrF/M9O5oRcEd+b9piL0qtKA438RzbN00NPEVERCSqF198kdmzZ7c6bhjGbncC/OlPf8q6detaHFuyZMk+zUDvDDtnSpWSm+IEoKTet7ePiIiISBfRpqLUCy+8wEsvvcRXX31Fbm4uU6dOZfr06Rx66KEUFBTs8yAmISGBBQsWsGDBglbv/XCwdOaZZ3LmmWfu0306lT+8dM/EAJsrysmtrdhWA0BB39QoZ4qIiIjAiSeeyJFHHhl5HQgEOP/88zn66KNbndvcduHJJ59k4MCBkeMZGRmdEOm+2TlTqoy8nHBRqrSu9U7QIiIi0vW0qSg1d+5cBgwYwIIFC/jpT3/a0TF1aYa/AWhauhfjTCfTNFm+LTxTqqBvWpSzRURERMK7Fu+6c/GDDz6IaZr8/ve/b3Xu1q1b8fv9jBkzBqfT2Zlh7rPITKmGUnIHqSglIiLSnViinwK33XYb/fr1Y/bs2Rx++OHMnj2bd955B69XA4Ifiizf24ele1uq3FS7/ThtFg7OTW7nyERERKS7q66u5uGHH+b//b//h8PhaPX++vXr6d27d5cpSEF49z1obnTetHxPRSkREZFuoU0zpWbOnMnMmTOprKzkP//5D6+//jqzZs3C5XIRCoX4/PPPGTBgAHa7tuY1mpfv7UOT86+3hpfujeqVgsPWpnqhiIiISMTTTz9Nbm4uM2bM2O37GzZswG63c9lll7Fq1SoGDRrENddcw5gxYzo50raLLN9zl5ObFB66ltZ7MU1T/TdFRES6uJganWdmZnLOOedwzjnnsGPHDl599VVef/11br75Zu655x5OOeWU3Tba7En2pyj11ffVAEzop6V7IiIiEhvTNFm8eDEXX3zxHs/ZtGkTNTU1nHnmmVx99dU899xznH/++bz++uv07t27zffqqFpQ83V3vb6ZmI2JgWEG6e0It0lw+0M0+IKkuPZ5I+kua3c5kpaUo71TfqJTjqJTjqLr6Tlq63Pv8//Je/XqxcUXX8zFF1/M5s2bIwUqFaV26SkVA9M0+aqoGoCJB6W3c1QiIiLS3X3zzTeUlJTwk5/8ZI/n3HzzzXg8HpKTw20CbrjhBpYtW8bLL7/Mr3/96zbfKysrZb/jjen6SdnQUEafRDfpiXaqG/34bDayszs2jgNZR/8ZdAfK0d4pP9EpR9EpR9EpR3vXLj9eGjhwILNmzWLWrFntcbkuzQg0zZSKsafU5ko3lY3hflKje2vnPREREYnNRx99xMSJE0lL2/OMa5vNFilIARiGweDBgykpKYnpXhUVdZjmPoe6R4YRHrz/8PrprmxsDWXUbNtMblIK1Y1+1hVVktXzJkrtMUeyk3K0d8pPdMpRdMpRdD09R83PH00P/F95xzL84Ubnsc6U+rJp6d6YPqnqJyUiIiIxW7lyJePHj9/rOeeeey6TJ0+O/CAxFAqxbt06zjnnnJjuZZp06AD7h9cPJeZCxbcYjWXkpmTzXVkDO2q9PXKQ36yj/wy6A+Vo75Sf6JSj6JSj6JSjvVP1o53t6/K9pc1L9/qnt3NEIiIi0hMUFhYydOjQFseCwSBlZWX4fD4Apk6dyuOPP84777zDxo0buemmm6irq+O0006LR8htFtmBr6GE3OTwDnyl2oFPRESky9NMqfbmj335Xsg0I0WpCf3V5FxERERiV15eTmpqyxYA27dv59hjj+WJJ55g8uTJXHDBBXi9Xm655RbKy8spKCjgsccea7Gk70AU2YGvsYzcFAcQ3oFPREREujYVpdpZpKeUPanNn1lf1kCNJ0CC3UJ+LzVBExERkditXLmy1bF+/fqxbt26yGvDMPj1r38dU1PzA0EosWmmVGMZuX2bZ0r54hmSiIiItAMt32tnRvNMKXtCmz/TvOve2L5p2Kz6IxERERHZ1c6ZUiXkpYSLUiVaviciItLlqQLSznYWpdq+fO+rpibn6iclIiIi0lqLmVJNRSkt3xMREen6VJRqZ0aMPaWCIZOvt9UAMPGg9I4KS0RERKTLalGUamp03uALUu8NxDMsERER2U8qSrWzWHtKrSutp94bJNlpZUTugd1kVERERCQeIsv3fHUkGj5SnOG2qJotJSIi0rWpKNXOYl2+17x0b3y/dKwWo6PCEhEREemyTEcKpjU8Q8rSWKq+UiIiIt2EilLtrLkoha1tjc6bm5xP6J/WQRGJiIiIdHGGQSipFwDWhu3kpjgAKFVRSkREpEtTUaq9Nc+UckRfvhcyTVZsqwXU5FxERERkb4JpAwCwVm+O9JUqrfPFMyQRERHZTypKtTPD3wC0rdH591VuGv1BnDYLQ7Lb1oNKREREpCcKpg0CwFqzKbIDX4l6SomIiHRpKkq1MyPgBtrWU+q70noAhuUkqZ+UiIiIyF4E03cWpfKS1VNKRESkO1BRqp1FGp23YabU2pJwUUq77omIiIjsXWSmVPUmNToXERHpJlSUak8BH0bID7RtptS6UhWlRERERNpi50ypzfRNCxeltlW7CYbMeIYlIiIi+0FFqfbU1E8KohelTNNUUUpERESkjYIp/TENK0bATV9rNU6bBV/QpLjGE+/QREREZB+pKNWefE1L9yw2sDr2empJnZcaTwCrgZqci4iIiERjtRNK6QeAo24zB2UkALCpsjGeUYmIiMh+UFGqPTX3k7JHLzKtKw3PqhqUlYTTpj8GERERkWgiS/iqNzEoMzwrfVOFilIiIiJdlaoh7ckXXo5n2hKinvpdZOmeZkmJiIiItEUgbecOfIOymopSmiklIiLSZcW1KOX1epkzZw4TJ05kypQpLFy4MOpntm7dyrhx4/j88887IcIYNS/fi6HJ+XD1kxIRERFpk2D6YKBpplRTUWqzZkqJiIh0WbZ43vz2229n1apVLFq0iOLiYq699lr69OnDjBkz9viZG264gcbGA3TwEdPyPTU5FxEREYnFrsv3BjYt39tc2YhpmhiGEc/QREREZB/ErSjV2NjI4sWLefjhh8nPzyc/P5/CwkKeeuqpPRalXnnlFRoaGnb73gEhsnxv7zOlqt1+dtR5ARWlRERERNoq2Lx8r3YLB6U7sRrQ4AtSWu8jL8UZ5+hEREQkVnFbvrd27VoCgQDjxo2LHJswYQIrVqwgFAq1Or+qqoo77riDm266qTPDjE3T8j3se+8p1TxLqm+ai2RnXCeriYiIiHQZoZS+mBY7RtCLs3EH/dLDYy4t4RMREema4laUKisrIyMjA4fDETmWnZ2N1+ulurq61fl//vOfOe200xg2bFgnRhkjf9t6SjU3OT84T7OkRERERNrMYiOYehDQstn5RjU7FxER6ZLiNk3H7Xa3KEgBkdc+n6/F8U8++YSlS5fy6quv7vd9O6rdgGEAvvDSQtOetNf77NpPqqe0P2h+zp7yvPtCOYpOOYpOOYpOOYqup+eopz53VxFMH4StekNTUaof76+v0EwpERGRLipuRSmn09mq+NT82uVyRY55PB6uv/565s2b1+L4vsrKStnva+xRU1HKlZKGK3vP91nfNHA6dFgO2Xs5rzvq0Px3E8pRdMpRdMpRdMpRdMqRHIgifaWqNzEw83gANmmmlIiISJcUt6JUXl4eVVVVBAIBbLZwGGVlZbhcLlJTUyPnrVy5kqKiIq6++uoWn7/kkks49dRTY+4xVVFRh2nuf/w/ZBiQ1bR8rzFgo7G8brfnuX1BNpaFi1e9XVbK93Bed2MY4X/cdFT+uwPlKDrlKDrlKDrlKLqenqPm55cDU2QHvppNDBoWXr63STOlREREuqS4FaVGjhyJzWZj+fLlTJw4EYClS5cyevRoLJadra7GjBnDm2++2eKz06dP55ZbbuGII46I+b6mSccNsHdZvrene3xX1oAJZCU5yEp09LjBfofmv5tQjqJTjqJTjqJTjqJTjuRAFEwbDDTPlAoXpardfqob/aQn2uMZmoiIiMQobo3OExISOPXUU7nhhhtYuXIlb7/9NgsXLuS8884DwrOmPB4PLpeLAQMGtPiC8EyrrKyseIW/e81FKdueG53v7CeV1CkhiYiIiHQnkZlStd+TYDXpneoEtIRPRESkK4pbUQpg9uzZ5Ofnc/7553PjjTdy1VVXMX36dACmTJnC66+/Hs/wYteG3fd2bXIuIiIiIrEJJffGtDoxQn4sddsis6VUlBIREel64rZ8D8KzpRYsWMCCBQtavbdu3bo9fm5v78VVZPnenotSG8vD5wzN1kwpERERkZgZFoJpA7FVrmvaga8/n26uUl8pERGRLiiuM6W6nShFKdM02VAeHjANUVFKREREZJ8E0wYC4b5Sg5pmSm1WUUpERKTLUVGqPTUv39tDT6kddV4a/UFsFoODMhI6MzIRERHpxt566y1GjBjR4uuHOxc3++STTzjppJMoKCjgvPPOo6ioqJOj3X+RvlLVGxmUpeV7IiIiXZWKUu0pykypDU1L9wZkJmC3KvUiIiLSPtavX88xxxzDxx9/HPm65ZZbWp1XXFzMlVdeycyZM3n++efJzMzkiiuuwOxi2ywG08JFKVvNzh34Suq8NPgC8QxLREREYqTKSHuKNDrf/dK85qV76iclIiIi7WnDhg0MHz6cnJycyFdqamqr8xYvXswhhxzChRdeyLBhw5g/fz7btm3jiy++iEPU+y6YPhgAa9UG0hLsZCbaAdhc6Y5nWCIiIhIjFaXaU/NMKdvul+Y1z5RSPykRERFpTxs2bGDgwIFRz1uxYgUTJ06MvE5ISCA/P5/ly5d3XHAdIJA9CgBrXRGGuzKyhE99pURERLqWuO6+162YZqQoRZTle4OzVJQSERGR9mGaJps2beLjjz/mwQcfJBgMMmPGDK6++mocDkeLc8vKysjNzW1xLCsrix07dsR0T8PY77D3et2o13elEUgfjK16I/ayFQzO6s/SohrWldVzkpHXMcEdINqcox5MOdo75Sc65Sg65Si6np6jtj63ilLtJegBwv0Ydrd8LxAy2VzZvPPe7otWIiIiIrEqLi7G7XbjcDi4++672bp1K7fccgsej4c//vGPLc5tPm9XDocDn88X0z2zslL2O+79vv5Bh0L1RtLqvuXIkRNZvLyYb3bUkZ3dsbEdKDr6z6A7UI72TvmJTjmKTjmKTjnaOxWl2onh3zldfHfL97ZWufEFTVw2C33SXJ0ZmoiIiHRjffv25fPPPyctLQ3DMBg5ciShUIg//OEPzJ49G6vVGjnX6XS2KkD5fL7d9p/am4qKOjqiN7phhAfvbbm+Ky2fZMC36XOGD7wIgNXbatm0tYoUV/cd4saSo55KOdo75Sc65Sg65Si6np6j5uePpvv+H7uTNRelTKsTLNZW72+oaFq6l52EpafO3xMREZEOkZ6e3uL1kCFD8Hq91NTUkJmZGTmel5dHeXl5i3PLy8sZOXJkTPczTTp0gN2W6/tzCwCwla4gK9HBQRkJfF/lZtnWGn48JKvjgjtAdPSfQXegHO2d8hOdchSdchSdcrR3anTeToyoO+81NTnP0tI9ERERaT8fffQRkydPxu3eufPct99+S3p6eouCFEBBQQFLly6NvHa73axZs4aCgoJOi7e9BLLzMS02LO5yLHXbmNA/DYClRdXxDUxERETaTEWpdmL4m3be22OT83DRamiOmpyLiIhI+xk3bhxOp5M//vGPbNy4kQ8++IDbb7+diy++mGAwSFlZWWTJ3umnn86yZct46KGHKCwsZPbs2fTr14/JkyfH+Sn2gc1FICu8C5+tdDnj+6UD8PXWmjgGJSIiIrFQUaqdGIHwTyf3XJRqnimlopSIiIi0n+TkZB599FEqKys5/fTTmTt3Lj//+c+5+OKL2b59O1OmTOHrr78GoF+/ftxzzz288MILnHHGGVRXV3PfffdhdNHWAoGmJXz20uWM7xeeKbWutJ46TyCeYYmIiEgbqadUO4ks39tNk3NvIERRdbhopZ33REREpL0NGzaMxx57rNXxfv36sW7duhbHjjrqKI466qjOCq1D+fPGkrD6n9hKlpP7I2ekr9TybTUc2QP6SomIiHR1minVXvbSU2pzRSMhE9JcNrKSHK3eFxEREZHY7ZwptRJCQcY1zZZapiV8IiIiXYKKUu2kuacUu1m+t+vOe111eryIiIjIgSaYMQzTlogRaMRaVahm5yIiIl2MilLtxAg0z5TaTVFKO++JiIiItD+LFX/uGABspSsizc7XldZT71VfKRERkQOdilLtxPDvudF58857Q7LV5FxERESkPUWW8JUsJy/FSb90FyETVmyrjXNkIiIiEo2KUu2kefmeadvzTKmhKkqJiIiItCt/3jgAbKXLAZjQNFtKS/hEREQOfCpKtZPI7ns/mClV7w2wo84LwGDtvCciIiLSrppnStkqvoWAh/HNfaXU7FxEROSAp6JUO9nZU6rlbKhNFeHjOckOUl32To9LREREpDsLpfQjlJCFEQpgK1/N+KYd+NaV1KmvlIiIyAFORal2snOmVEKL40XV4V5TAzI1S0pERESk3RkG/tyxANhLvqZXqosBGQkETfh4Y2V8YxMREZG9UlGqnUSKUj/oKVVUFS5K9UtzdXpMIiIiIj2Bv88kABzfvwfAsSNyAHh7XVncYhIREZHoVJRqL3voKdU8U6p/ekKrj4iIiIjI/vMNmgGAfesnGN5ajhseLkp9srlSS/hEREQOYCpKtZPmnlL8oKfU1moPAP0yVJQSERER6QjBjCEEMoZihPw4vn+PIdmJDMpMxB80+XBDRbzDExERkT1QUaqd7Gn3va2RmVJaviciIiLSUXyDjgfAsfG/GIbBtBHZALylJXwiIiIHrLgWpbxeL3PmzGHixIlMmTKFhQsX7vHcV155heOPP54xY8Zw1llnsXLlyk6MNLqdPaV2zoiq9fip8YSnjPfT8j0RERGRDuNtLkpteReCXqY19ZX6bHMVtR5/PEMTERGRPYhrUer2229n1apVLFq0iHnz5nHvvffyxhtvtDrvq6++Yu7cuVxxxRW89tprjBs3jksuuYSGhoY4RL17O2dK7Vy+17x0LzvJQYLdGpe4RERERHqCQN5Ygol5WPz12Ld9yuCsJIZkJxIImby/Xkv4REREDkRxK0o1NjayePFi5s6dS35+PscddxwXX3wxTz31VKtzy8rKuOKKKzjllFPo378/V155JdXV1WzYsCEOke+e4Q8XyHZdvte8dK+flu6JiIiIdCzDgm/QdACcG/8LwHHahU9EROSAFrei1Nq1awkEAowbNy5ybMKECaxYsYJQKNTi3BNOOIHLL78cAI/Hw+OPP05WVhZDhgzp1Jj3KBTECHqBlkWpokhRSkv3RERERDqad3DTEr5Nb4IZYlrTLnxffF9NtVtL+ERERA40cStKlZWVkZGRgcPhiBzLzs7G6/VSXV292898+umnjBs3jnvvvZc5c+aQlJS02/M6mxFwR37fsigVXr7XX0UpERERkQ7n7/sjQo4UrI0l2EqWMyAzkeE5SQRDJu8Vlsc7PBEREfkBW7xu7Ha7WxSkgMhrn8+3288MGzaMF198kffee4/rrruOfv36MXbs2Jjuaxj7FO7erxlo7m1lYNh2LtXb1rzzXoarQ+7blTQ/f0/Pw94oR9EpR9EpR9EpR9H19Bz11OfuFqwOfAOm4ip8Geem/xLoNZ7jRuTwXVkD/11bymljesc7QhEREdlF3IpSTqezVfGp+bXLtfseTNnZ2WRnZzNy5EhWrFjBM888E3NRKisrZZ/i3SujNPyrI4ms7NTI4W214SV9owdmk53dAfftgjok/92MchSdchSdchSdchSdciRdkW/Q8bgKX8ax6b80HD6bGSNzuf9/m1laVMPmikYGZiVGv4iIiIh0irgVpfLy8qiqqiIQCGCzhcMoKyvD5XKRmpra4tyVK1ditVrJz8+PHBsyZMg+NTqvqKjDNPcv9h+ylpeTAWBPjFy/0RekrC5clEomRHl5XfvetIsxjPA/bjoi/92FchSdchSdchSdchRdT89R8/NL1+QbcAymxY6taj3WstX0yslnyuAsPtxQwfMrivn91KHxDlFERESaxK0oNXLkSGw2G8uXL2fixIkALF26lNGjR2OxtGx19fzzz7Nt2zYeffTRyLHVq1czatSomO9rmrT/ANvXGP7VkRS5flFVeOlemstGstPWIwf1u9Mh+e9mlKPolKPolKPolKPolCPpikxHCt7BJ+Ba/woJKxdSf+xfOXNsbz7cUMGrq0u4YsogEh3WeIcpIiIixLHReUJCAqeeeio33HADK1eu5O2332bhwoWcd955QHjWlMcTbhT+85//nM8++4xFixaxefNm/v73v7Ny5UouuOCCeIXfguFv6inl2Nl4fWukn5SanIuIiIh0JnfBRQC4vvs3RmM5kwZkcFBGAg2+IP/5tiTO0YmIiEizuBWlAGbPnk1+fj7nn38+N954I1dddRXTp08HYMqUKbz++usA5Ofnc++99/L888/z05/+lA8++IBHH32UvLy8eIYfYQSaZkrtsvPe1qad9/pp5z0RERGRThXoNQF/3jiMkI+E1f/EYhicXhBucv7c18WYmgIoIiJyQIjb8j0Iz5ZasGABCxYsaPXeunXrWrw+5phjOOaYYzortJgY/p3L95oVNc+USt9903YRERER6Tjugouxv3klCd88QeP4Kzg5vxf3f7yZjRWNLNtaw4T+6fEOUUREpMeL60yp7mJ3Ranm5XuaKSUiIiLS+byDTySY1AuLuwxn4RJSXDZmjMwF4PnlxXGOTkREREBFqXYRKUrtsnyvSMv3REREROLHasc9+gIAElY8AqbJmWP7APDe+grK6r1xDE5ERERARal2Eekp1TRTyhsIUVoXHuho+Z6IiIhIfHjyz8G0ubCXr8K+/XOG5yYztm8qwZDJws++j3d4IiIiPZ6KUu3AtDXNhkoN//StuMaDCSQ5rKQn2OMXmIiIiHR7JSUlXH311UyaNIkjjzyS+fPn4/XufhbQ5ZdfzogRI1p8vffee50ccecxXRl4RpwBQMLyhwG47EcDAXhhxXbW7KiLV2giIiJCnBuddxfuQ84jlNKX1PEnQ92uTc4TMAwjztGJiIhId2WaJldffTWpqak89dRT1NTUMGfOHCwWC9dee22r8zds2MAdd9zB4YcfHjmWlpbWmSF3OnfBxbhWP4Vz03+xVn7HxIOGM2NkLm98W8qf3y7ksV+Mw2rReE1ERCQeNFOqPdgT8Q07GZwpgJqci4iISOfYuHEjy5cvZ/78+QwbNoyJEydy9dVX8+qrr7Y61+fzsXXrVkaPHk1OTk7ky+FwxCHyzhPMGIpv8AwAEpfdB8BvjhpMksPKtyX1/Hvl9niGJyIi0qOpKNUBiqqai1LqJyUiIiIdJycnh0ceeYTs7OwWx+vr61udu3HjRgzDoH///p0V3gGjccJVADi/ewlLzRaykxxcMWUgAPd9vImKBl8coxMREem5VJTqAFubdt7rr5lSIiIi0oFSU1M58sgjI69DoRBPPvkkhx12WKtzN27cSHJyMtdccw1TpkzhjDPO4IMPPujMcOMmkDsG30FHYZhBEr9+AIDTC/owIjeZem+Qv7y7Ho8/GOcoRUREeh71lOoAW2vCM6X6aqaUiIiIdKI77riDNWvW8Pzzz7d6b+PGjXg8HqZMmcKll17KW2+9xeWXX86zzz7L6NGjY7pPR7XMbL5uR1y/ccJVOL7/ANe3z9I46f8wkvKYfdxQfvXUct7+rpyvt9Zw9oS+nDG2D8nOA3eI3JE56i6Uo71TfqJTjqJTjqLr6Tlq63MfuP/H7aJCpklJXXjHmz5pKkqJiIhI57jjjjtYtGgRd911F8OHD2/1/hVXXMG5554baWx+8MEHs3r1ap577rmYi1JZWSntEnOnXj9rGnx1GEbRZ2Stexym38LR2Snc9XO447/r2Fbt5t6PNrPoi63MmjqUi48cfEA3QO/oP4PuQDnaO+UnOuUoOuUoOuVo71SUamfVjX78QRMDyE7q3o1DRURE5MBw88038/TTT3PHHXdw/PHH7/Yci8XSaqe9wYMHs379+pjvV1FRh2nuU6h7ZRjhwXtHXd8+9grSij7D/PJRqgafSSh9MFP6p3LYrybwxtoynviiiI0Vjcz/z1r+s7KYG04YccBtXNPROeoOlKO9U36iU46iU46i6+k5an7+aFSUamel9eFZUplJDuxWtewSERGRjnXvvffyzDPPcOeddzJjxow9nnfddddhGAbz58+PHFu7du1uZ1VFY5p06AC7o67v638M/ux87OWryXzyx/h7TcQz/FQYdgo/GZXHCSNzWbJqB3e+t5Hl22r5xaJl/PbowZwyuhfGAbb+oqP/DLoD5WjvlJ/olKPolKPolKO9U9WknZXUhXdvyUtxxjkSERER6e42bNjAP/7xDy655BImTJhAWVlZ5AugrKwMjye8AcvUqVNZsmQJL730Elu2bOHee+9l6dKl/PKXv4znI3Quw6DuuHvx9T0CEwP7jq9I+fCPZP7rGCx1xVgMg1NG9+Zf549nXN9UGv1Bbn2rkCe/2hrvyEVERLolFaXaWWlTP6ncZC3dExERkY71zjvvEAwGuf/++5kyZUqLL4ApU6bw+uuvAzB9+nTmzZvH/fffz0knncS7777LI488Qr9+/eL5CJ0umDmMmlOfpfKCL6k/Yh7B1AFY3OWkvPs7MEMA9E1L4P6fFXDJ4QcBcO9Hm/h8S1U8wxYREemWtHyvnTU3OddMKREREelol156KZdeeuke31+3bl2L12eeeSZnnnlmR4fVJYSSeuEeewm+AVPJeO54HFs/JmHlQtwFFwNgtRhccvgAttd6eXV1CXNf/ZYnfjleG9n0ULbiL0j+343UH/1nAjmxbQwgIiJ7pplS7aykvnmmlIpSIiIiIge6YMYQ6o+4HoCkT+djrdhZyDMMg+umDWNkXjI1ngB/eHk1Hn8wXqFKHCV88zj20hW4Vj4e71BERLoVFaXaWalmSomIiIh0KZ78c/EedAxG0EvK21dD0Bd5z2mzcPtPR5GRYOe7sgZmv/otRVXuOEYr8WArXw2AvWRZnCMREeleVJRqZ5GeUipKiYiIiHQNhkH91L8QcmVgL19Nyju/w/DVR97ulepi/skjsRrw8cZKTl/4JX94eTVfb63B3JctlYJeDG9NOz6AdCh/I9bqjQDYqgr1Zyci0o5UlGpHpmlSWh/+yVpuihqdi4iIiHQVoaQ86o75CyYGrsKXyHhmGvat/4u8P6F/Og+dNZYpgzMxgffXV3Dpsyu45pU11HsDMd0r7dULyFw0KVLokAObreJbDHYWH20ly+MXjIhIN6OiVDuqavTjDYR3bclJ0kwpERERka7EN/h4ak59jmDqQVjrtpL+8s9J/nAu+MPL9cb0SeWu0w5h8QUTmTmmNzaLwfvrKzj3yWWsK62PcvUwW+lKHFs/wuJvwLXqiY58HGkntvI1LV5rCZ+ISPtRUaodba8JD1gyE+04bEqtiIiISFfj73s4lT9/C/ch5wGQ8M0iMp4/CWvld5FzBmYlMvu4YTxyVgG9UpxsrfZw0dPLeWnl9qjL+Vyrn9z5+7WLIaD+VAe65qJUyJURfr1DRSkRkfaiykk72lHjAdTkXERERKRLcyRRf9RtVP/0XwQTc7FVriNj8Yk4v30Wdik65fdO5Z/njueIQZl4AyFufauQs59YyutrSggEQ60ua/jqcH33EgCmLRGLtwbn+tc666lkHzU3Ofcc/DMgPFOqrM7D5orGeIYlItItqCjVjrY3FaVyk1WUEhEREenq/P1/TNXP/4uv/48xAh5S3/1/pLw1C6OhNHJOeoKdO0/LZ9aRg0i0W9lQ3si8/6xj5sIv+eeXReyo9UTOdX73MkagkUDGUBonzALAteqffLKpku/auPxPOlkoiK3iWwA8B5+BaXVi8dZw09NvcPYTS/XnJiKyn1SUakfNy/e0856IiIhI92Am5lBz8pM0TL4G07DgKnyZzKd+TMLyhyHoB8BiGJw/qT9LLp3EFVMGkpFgZ3utl79/uImTH/6CC/+1nH99VYS5fBEAnlHnUDroDIKGFUfJUu7/9+uc889lXPX8Nywtqt63Hf2kQ1hrNmME3Jg2F8GM4QRyCwDo07CKQMjkoU+2xDlCEZGuTUWpdrRzppR23hMRERHpNgwLjROvpvr0V/DnFmDx15P8vxvJePZ4XKv+iaX2ewBSXXZ+NfkgXrlkErOPG8a4fmkYwDfba3nnw7dJrfkWr2nnpE8GcMKTG/lPYCIAv3K+h9WAz7ZU8evnVnLxMyv4prg2jg8szZqX7gWyRoLFij9vHADjLOsB+GBDBat31MUtPhGRri6uRSmv18ucOXOYOHEiU6ZMYeHChXs89/333+eUU05h3LhxnHzyybzzzjudGGnbNPeU0kwpERERke4nkDeW6jOWUHfMHYRcmdiqviPlg9lk/fNHZDz1Y5I+vglLfTEuu5WZY3rz0M8LeO2yyfy/Y4bwf2kfA/BaaDKb3S48gRAfJp8EwJn2//Hv80ZxekFvHFaDlcW1XPT0cm5/Zz313sA+xVrr8fPPL4v4ZFMloS4+88rw1pL04Z9wrH+10+8dKUpl5wPgzQ0XpcZbChmUmQjAA//b3OlxiYh0F3EtSt1+++2sWrWKRYsWMW/ePO69917eeOONVuetXbuWWbNmcfrpp/PSSy9x1lln8Zvf/Ia1a9fGIeo9U6NzERERkW7OsOAZdTaV53xI/WHX4es9GdOwYqveSOKKh8h88kiSPr4Jw10BQE6yk7PzUzgm8CEAh59yNY+fM45F54zj9xecTyBtEBZ/PYNK3+S6acN4+eJJ/CQ/DxNYvLyYnz/+Ff/9tjSm4tRnmys5e9FS/v7hJn7z4irOfOwrnl22rc3XWF/ewJJVO/Dvpll7PCQsf5DEbx4j7b+/JunDP0HQ12n3/mFR6svgEAAOtnzPX38yMDzDbXMVy7fWdFpMIiLdiS1eN25sbGTx4sU8/PDD5Ofnk5+fT2FhIU899RQzZsxoce6rr77KYYcdxnnnhbfmHTBgAO+++y7/+c9/OPjgg+MRfiumaUaW76koJSIiItK9ma503BNm4Z4wC8Nbi33rxySsfBRH8eckrngI15qnCGaPwlJXjKWxBCMUIJAxDNtBh5NvGJHrePJ/SfInN5P45d/w95pIduZwbpgxghNG5jL/rUK21Xj44+trsRgwIjeZif3Tyc1IpLS6kUZfkEDQpG+6i8FZifTPSOC5r4t5YcV2AHqnOqn1BPi+ys1f3tvA/f/bzEn5eZw5tg8Dmmb5tHgm0+S5r4u5+4ONBEImL32zg/knjYzvKoCgH9eapyMvE795DHv5KmqPf4BQUl6H395avgaAQPYoAF7ZbOEQM5M+RiWD/YWcfEgvXvpmB/f/bzMP/GwMxi5/tiIiEl3cilJr164lEAgwbty4yLEJEybwwAMPEAqFsFh2TuI67bTT8Pv9ra5RV3fgrN+u9QRw+4NA+CdiIiIiItIzmM5UfENOxDf4BOxFH5D02QLsZd9g2f7lznOsThoP/T/4QdHCM/LnJKx6AmvtFtKf/yl10+/DN/BYJg/I4JnzxvPqRx/z6aYKPqzJ4duSer4tadtubz8f14dZRw4iaJq8vqaU95cuJ7F2PYu/HsOzXxdz+MAMThyVx8G5yfTPSMDtD3Lzf7/j3cJyAKyW8DLCc59cxm0njWRC//T2SldMHJvfxNpYSighh7qjbiXl3d9j3/4lzieOpiJpGI603qRk9cM/ZAaB3oe2672NhlKsjaWYGASyRuILhHh/fTknhIbSx/oFtpJlXHTYRby2poRlW2v48vtqJg3IaNcYRES6u7gVpcrKysjIyMDh2NkUPDs7G6/XS3V1NZmZmZHjQ4YMafHZwsJCPv30U84666xOizea0novEN4W2GlT/3gRERGRHscw8B90NNX9f4x968dYPNUEU/oSSu5NKDEPLNZWHzFd6VSd8Qqpb1yKo/hzUl+7gMaJV2MEPGRs+i+X12zm1xiU/OgPvJn2M1YW12F32rCGTBLtVjDg+yo3mysa2VTZSF6Kk2uPHRopjlgrC7mw4h9c7vs3hiPAhwnH8auq8/l0cxWfbq4CwGWz4LJbqXb7sVkMfnPUYI4YlMm1S9ZQWNbAlYtXclJ+LwZmJdInzUVmgp3vyhpYWVzDN8W1BM1wEezMsX1w2Vs/4/5IWPUkAO5RZ+EZfAKPb0rm+G+v5WCKSK5bBnXAVgiseJjLnHdQaBmMxYDjD+nNGYfkkp6w7xsQ2SrCs6SC6YPAnsin6yuo9wYpTDwYQl9g37GMXuOv5LTRvXlueTHX/2cd1xw7lKnDstvj0UVEeoS4FaXcbneLghQQee3z7XmdeGVlJVdddRXjx4/n2GOPjfm+HTWjtrQ+HHNeiqPD7tGVNedEudkz5Sg65Sg65Sg65Si6np6jnvrc0o4MC/7+P27z6WZCFjU/fZrkj64nYfWTJH31t53vWWwYoQC9lt3Oz4av58Spt5PdK4fy8jpMvxtr9abwN62RgmmkY/HVYK15H+uXm7GVrsCx+R0Mwo3OTQx+7H6LL0al8LeEq/i6uJ7CsgY8gRCeQIjeqU7mnzSS/N6pACw8eyy3vVXIf74t5eVVO/b6DH//cBNPfrWVCyYfxAkH55KWYIssZWvwBVi9vY6VxbWU1HmxGAaGARbDIMVlIyvRTlaSg+wkB4Ozkkhxhf+JYq3eiGPrR5gYVA37OXNfXsMHG+A+bmHW4HJcnlLqK4s5IvQlky1r+T/3PZzqu5kgVh78cCNPfLqZM8f25dyJ/UhPtMf0Rwit+0m9ta4UANdBk2DzE9hKvgbT5KLDD+KL76vYXOnm2lfWcPTQLP4wdag2PxIRaYO4FaWcTmer4lPza5fLtdvPlJeX86tf/QrTNPn73//eYolfW2VlpcQebBs0bAj/pKl/VhLZ2R1zj+6go/LfnShH0SlH0SlH0SlH0SlHIp3I6qD+qPkEskeRsPxhAnnj8A6ajv+go3Gue4Hkj67H9d2LWGs2wYhppK3/ENuOrzFC0Zt+ewcdT+OEWVhrt5Ly1iyyNr7InINt1P38z1i2L8W37i2cJcuw9ikgaE8hSLh/kstu5cYTRnDs8By+2V5LcY0HX1URaQ2baMgaw9B+fRjTJ5WSOi+PfPY9xTUe7nxvA3e+twG71SA7yYHLbmVLZSOhGDYA7JXiZFhOEr9yL2Qq8I3rUGa9XMb3VW4cVoO50w/hxFHhflKmabK1uAjfazMY7d/MfyasYFmfc3hqWTHfbKvhiS+LeGbZVvJ7pzK+Xxrj+6WR4rJRWuejtN5LrcfPyLwUxvdLaz3Lq3RnUcrjD/LRhkoADh7zI8zvbVgbS0n+YDbG4bN58twJLPxsC4u+3Mr76yv4Yks1BX1TOTgvmYNzk8nvnaq+syIiuxG3olReXh5VVVUEAgFstnAYZWVluFwuUlNTW51fUlISaXT+xBNPtFjeF4uKijo6YlfcDTvCO26kO62Ulx84va4OFIYR/sdNR+W/O1COolOOolOOolOOouvpOWp+fpFOZxh4DjkPzyHntTjsGX0+wfQhpP73MuwlX0PJ1zTP+wk508Bih1AAzCCmLZFg+kCCaQMJpg3CN/A4glkjAAjkhXu5prw1C9fa53CufwUj4Nl5o6qvYfXj+LMPwTfkRExbAgAzMPmJbx2Oqs+w1m4J37cqCU+vn+NOv5DQgIHMGJnLktUl/PPLIrZWe/AHTbbXeiOX7p3qZEyf1EiDddM0CZpQ6/ZT2einsb6aUN12vqzPYkedl6q6Ov7mfB0M+FvtkXwfcpOZaOcvp+Qzus/OfysYhkH/vgfhOXIejnf/H8PW3Uv2+FP5+awj+PcXW3jof1tYW1rP11tr+HprDY/uIfUJNrgsZw0jHBV8GBzFO1W9eMq/lGEWuO5zC6tXfk2jP0jvVCej+uXQOOFqkr68k4TVT+LY9Cb1R97E5Uf8hONG5HLLm9+xekddiyWSAIMyE5k8MINDD0rH4w+yubKRTRVuajx+RvdO4dCDMhjdJ1WtQESkR4lbUWrkyJHYbDaWL1/OxIkTAVi6dCmjR49uNQOqsbGRiy++GIvFwhNPPEFOTs4+39c06ZABdmnT/3Rzk509cgDfVh2V/+5EOYpOOYpOOYpOOYpOORI5cPj7T6HqjFdJ+vKvuFxO6rIm4O9zGMG0QTGtOfUOOxkwSXnrKoyAh5AzHd+Aqfj7TMJe9DHOTf/FXr4Ke/mq3X7eNCyEEnOwNpSQuHIhCSsfCxe7zCAX+Ru52NZIsF8GDSmDqUwYSKWzP3lpSaS5bEAFsPMvFiPkx1a2CnvVZ9iqV2GYQfy5A9nYbyYljZC5uZ5aRx7jDzudHzkdHDEok6yk3feI8h78M3zrXsSx7X8kv3cdxuBX+fGQLKYMyuT7KjfLttawbGsNy7fW4A+Z5CY7yE12kmiH7O9f57zA8wyr2gbACcA2M4teRnhm1OfuvpS5GwGYMTIXwzBonPQ7/H0PI/n967BVbyTtv7/GnzOG0UNPYtFPTmSVZyhrS+oo3F5Jecn3rKoIsakSNlU28syyba3i//L7ahZ+XoTTZiE7yYHbH8TjD+EJBElx2shODi9v7JXqYkzvVMb2S6N/umufdvuraPDxTXkpByXZSHXFvqxRRKQ9GaYZv+Hm9ddfz7Jly7jtttsoLS3l2muvZf78+UyfPp2ysjJSUlJwuVzcddddPP744/zzn/+kd+/ekc+7XC5SUmL7SWZ5ecf81PfK51fyxZZqbjhhBD8Z1fHb03Y1hgHZ2Skdlv/uQDmKTjmKTjmKTjmKrqfnqPn5Zc866nujp3/vtUV75chavgbDV0+g13iw7Pw5teGpwvndv7GXLAczBE39qELJffD3PRx/70Mx7cnYt35E4vKHcHz//n49z65Mix0j1HLH7YZJvw/vWtgGlprNZD59LEbQC33G47OnE3KkYDrTCCXlEUzqTSi5F4avHmv1RmzVG7EXfx6Z/eWxJrPFNYrB7pXYQ+EZZIGEHD478UOK67w0+oIcOzy75TK/gIfEpfeSuOwfLZZSBtIGYfHVY3GXhZ/NsFCScSjv2n7MU3UFWFzpDMpKYFBWEokOK1837d5X0RB9OWazzEQ7eSlOvIEQ/mCIYMgkK8lJnzQnfdJc9El1hX9Nc5GT7OSr76t56ZvtfLSxkmDIxGmzMG1EDmcW9GZUr5R9KnB1V/q7KDrlKLqenqO2jqfiWpRyu93ccMMNvPnmmyQnJ3PRRRdxwQUXADBixAjmz5/PzJkzmTFjBps2bWr1+dNOO40///nPMd2zo74hznzsSzZXunngZ2PitmXugayn/wfZFspRdMpRdMpRdMpRdD09RypKRaeiVPwcaDmyVm3AVr4a056IaUvAtCVgaSzFWrUeW1Uh1tqicHErUvAwMGneTQGC6UPw9zkMf5/DCDnTcK1/Gdfqp7CXrsC0JVL5yw8JJfVqczwJXz9I8ic3x/QMIWc67rGX4h59AaYzFQJuHFv/h33rx/j7HYlvYPTNlYzGcpwb/4Nz/avYiz/FMEOR90yrM1wo2+W176Cj8Q45Ad+AaZiudPC7sZV8Tf2mz/H5PATTBmCmDYT0g6hv9FFbV019XQ3VVaVUl24hVFtMjlmBGxcbzD5sCPWh0OxLJa3boOxOboqT0rqdMR2UkcBBGQn0bSpipThtOG0W7FYLLruFjAQ7GYkOMhPt2K3df3nhgfbf2YFIOYqup+eoSxSl4qEjviFM0+Soe/6H2x/ixYsOpX96QvveoBvo6f9BtoVyFJ1yFJ1yFJ1yFF1Pz5GKUtGpKBU/PSVH1oq1YHUQTB8c2wdNE/uOL0i31lNXUYbhq8fwVGFp2IG1fgeWhh2YNhfB9MFNX0PxDTgG05HcbrEb7gpsZd9gJmQRTO6D6crEUvs9rsKXcH73b2xV63eGa7ERTBuMtWYjRiiw3/felv1j3u51KSv9fSmu8VBc42F7rQdf0CTNZePEUXmcMroXkw/O471vinl+eTFvrSvDH2z7N5PDGt7P0W76ONhSRIWjP4kpGeQkO8lIsEfqj6ZpkhiqJT1QTmqggsRgHaucYykLpeINhPA27froDQTxBkKkOG0MzExkQGYCfdMSqPMGKK/3UlrvIxgyGZaTxMF5yYzITSbZaQt/3h8MX6NpqaNnl1/D1w9iMQwcVgsOW7jAlpUYXrq56w6RP7S3/878wRDFNR6q3X5qPAFqPX5CJozMS2ZwVhJWy55nnPkCIXzBEMnOuHXRaTc95e+i/dHTc9TW8VTX/6/hAFDvDeL2h38akpu8+3XuIiIiIiLSNsGsg/ftg4ZBoM9kyE7BG6d/CJoJWfgPOrrFsVDaABon/obGCVdjrfgW54bXcW78D7bKddiqvgMgmJSHv9ehmI4krDVbsNZuwVq/HdOwYNqTMR1JmI5UQsm9CSb3JpTUu2kp4npsVRuw1H5P3/IPOa/iYzwjzsRz5PkYPh9G3Q681dtw2W0YCemYNekYm3ozzu6k4Ig0/t+PcllTaVJc62VbjYfiGi+N/gB+f4CkQCWJvnIavOECjBkKMYIijrV8zRTLNyQZXmqDiTxQfhKPl8ygERcpNHKW9V3Ot71JP6O8RR5qzQTuDpzBouB0gvxgt0Pg25L6Peb1P9/u/5/NruxWg2SHrUVLNqfNgstuJcFmITnRgc00cdmtuOwWaj0BtlQ2UlzjYU81vAS7hVG9UhiYmUiay0Zagh2X3cqGsgZW7ajju9J6AiGTQZmJjO+fxri+afTLSMDVVDBz2awk2K04bZZIccs0TbyBEG5/kI0VjXxbUs/akjq213oZmp1EQd9UxvRJpW/a7nuM+ZqKc4kOG7a9FMxE4kUzpdrB+vIGzl60lPREO29fcXiPrIJG09OrxG2hHEWnHEWnHEWnHEXX03OkmVLRaaZU/ChH0XWlHFmrN2KtLCSQnU8opW/rpvWhABjWNjWzt1ZtIOnzBTg3vB5zHKZhDffecqVjOlKxeKqw1G9v0Sdrd0LWBCxBNwCN9kw2pB7G8Kr3cYYaI+c02tKot+dgNX1keb4HoCppCN8MuRLDkUQCblyml5qAjU3eVNa4Uyisd9HX0cBgezUDbFVYQl5WNmbxUXUGa2vt2Akw2ChmhFHEYGsZPmsCjZYUGm1pBK0JJFghwRrCaTWpM1LYTjaloTTq/eFG71Vu/26fB0wyqeMgo5S+RjnZRg1ZRg3Z1ODFwXqzL+tDfdlu7c2whDpG2YoZZtmGM9jIfxoP5i1fPg20z6oZh9XAMAx8gRBt+TZ22iwk2K0kNBW3Gv1Baj3+yOQJgES7lWSnlRSXjRSnjeSmL4sR3n8gZJrYrBZykhzkpjibJlwY1Hj81Lj91HrCs/ksFgObxSAlyYnH48OCgcViYLUYWA2wGAYWAwIhE3/QxBcMYTUM0hPspCXYSW+apeYPhpq+TPwhE38ghD8Uwhc0CTQfD4ZIsFtJTQg35k+yW8PnBEy8wRBWg/BzOGwkOcOFzlDTs4S/IBQK/95iGNitFuxWA4thUO32U9noo7LBjy8YIic5/Nw5yU4S7a2LprEK7+abTEVFfeTvIusueQLwBc2mjQ3CM/zckZl+QZKdNjIS7WQkOEiwW/AGQjT4gjT6ghgGJDqsJDYVMWPtCRcImXj8QVx2a4cVKzVTqhM1r8fuleqKcyQiIiIiItJVNC8j3CNL2/+5FswYQu2Mh7DtWErS53dgK11BKDGXUHIfQsnhzaIMTzUWXw12fy3BxkosnmqMoBfDDGJ4KrF4Kltc0zSshBKzwdgZRygpF9+AqfgGHkcgayTO9a+Q9PlfSKzdwuiKcEEskDEc99hL8Aw7FewJGEAoFKTu26dJ+vTPZDRs4Mcrf9fqGY7Yy/Od3PycaWlY/I2tmuITAvZSQzMtNkJJvQj26ksgqTd1zjz8phW7uxSHuxSHuwRnw1ZsgYa9RLELf9NXk+MtrxNKtFOcNoGt9oF4AibegIknCI7kDNIz88jL7YM9KYPvKnysLvexutTLdreVioCLyoAd9y4rOIPBAFZCWDEIYcEEhif7OTTLx+hUN70dbr6vDbC+KkBhVYjGoA1P0IHXY8dr2nGTiIcEYGcPsEZ/kEZ/kNL6tjfUl45jQJsKjtHONWgqUDnCM+1sFgNfMBRZJhtq3vG0qZ+fJxCMLNnNTXbw3K8mkuSIX2lIRal20FyU6qNeUiIiIiIiEkeBXhOoOeWZPb7fPHuhqnkmWcCNxVuD4anB4q3G8NZgOlMJpvQnlJQXtTDmHX4a3iEn4Vr7LLayVXgHHR9evvjDmRsWK578X+Id8hOSPv8L9qIPwOrEtCdh2hMx/A1YGnZgaSjFMIPhglhSHqHkPphWO9aazVjrt2P11gAQcqQQzDqYQNpgjKAHi6cKw1OFEXCDxYZp2MCwYHFXYGnYgREKYK3birVuKw4gcS/PFEzujTVzIF57JqGEbEKJ2eGlklWF2CoLsdYVEUrIIZA5jGDmcEzDimPLO9hqNtOv6jP68VnLCzYAJUDTEsT+wA/b55s2AzMhCUIBjJCvRbP8iEDTdUp+cNy+++cwDQshewqmK42APQ2fPQWvLRWvaScY9BMMBggGAtiDjTiDDTiD9VhCPnzY8Jh2GkN2fNgxbU6whr8shDDMAFYzgGGx4jbteAwXHsOFl/CvbsOJDwc2AxxGELsRImSGaAhYqPcb1PnDWx44jBAOSxCHYWKxGBgWC1bDgsViYLFYsRjhY/6gSaPfxN1UZLFYLFitVqwWC8EQeAIhPAETT9BsKtw0zRwyDMACRnjWWQjwhyAQhCCQZLc0zRgLF3JqPQHqPD7qPQFMmrdliGzNAE2vIVwIMn742mj+/c7yUci04MGBFzseHIQwWlyz+RpWS7j3mdNqwW6zYLcYuP1B6n1B/MFQ5O4ATqsFExPfLutIzYAR/v7YjR8+h4EJlvBrn20gNkt8Ny9QUaodVDaGS+S90jRTSkREREREuhBbAiFbAiT1Iriv17Da8eT/sk2nmq4M6o+6dc8nhIKRwlirgpjfjbV2C6YjhVBynzYtawxfM4ClsRRLXTHW+m2RXwkFCSX3IpSYRzApj1Bqf4Ip/TDsLrKzU6jb0xLQUKBVbA1TbsBavQHH5newuMuIfNAMhot+7gos7koMXx1G0AdBX3iWmr8BI+QPFw38e+6pFbm1KyM8A86VjhEKQsATvk7Qu/P3fneksGX11YCvBhuwz/9a3edvjE62p9qKSctpRs0r80KAu+lrV/FsE/3DGX9W2E37tZ3v7SfTZ6Mi8GNMW8b+X2wfqSjVDo4YnMlXRdX8bGL/eIciIiIiIiLSdVmsmAmZu3/PnrBvTfAttqZljH0IMHH/4mu6XiuGQTBjKO6MobFdyzQh6MHw1mHx12Na7GB1YFodYFiailsmmCFMRwpY21gxCXjCxbCmr/Dvq7F4aiDkb5pNZgn/ak/EdKRiOpIxrc7w0shAuNBlBLwQavo16A33OLPYwGIjJdlJfVUl+BsxAm4Mf2O4yOZvxAh6wLBiNp0LNM0C80MwAIYRflaLNXzNcDKgeYZY5LlNDEItXu98P/SD88yW55khIhUpc5dzIvcxdilsNs0litQ5m98zdv+6+fe7nG/+4D3DMHDYwN9YD0EvRsDDzurYzmuZLe7zQ62rosYem+Xt7rgZuVfkPrv8GswcjulM28P1OoeKUu1gRG4y9/9sTKShooiIiEhn8nq93Hjjjbz55pu4XC4uvPBCLrzwwt2eu2bNGubNm8d3333H0KFDufHGGznkkEM6OWIREQHCBQJbAqYtgSC57Xddm4uQzQVJee13zV0YBqRkp+DpAhsKxEvzUtka5Wiv4rt4UERERET22+23386qVatYtGgR8+bN49577+WNN95odV5jYyOXXnopEydO5MUXX2TcuHFcdtllNDY27uaqIiIiIh1LRSkRERGRLqyxsZHFixczd+5c8vPzOe6447j44ot56qmnWp37+uuv43Q6ueaaaxgyZAhz584lKSlptwUsERERkY6mopSIiIhIF7Z27VoCgQDjxo2LHJswYQIrVqwgFGq5e9OKFSuYMGFCeFciwDAMxo8fz/LlyzszZBERERFAPaVEREREurSysjIyMjJwOHY2v83Ozsbr9VJdXU1mZmaLc4cObdmENysri8LCwpju2dYNr2JlGC1/ldaUo+iUo71TfqJTjqJTjqLr6Tlq63OrKCUiIiLShbnd7hYFKSDy2ufztencH54XTVZWyj5EeuBcvztQjqJTjvZO+YlOOYpOOYpOOdo7FaVEREREujCn09mqqNT82uVytencH54XTUVFx+wkZBjhwXtHXb87UI6iU472TvmJTjmKTjmKrqfnqPn5o1FRSkRERKQLy8vLo6qqikAggM0WHtqVlZXhcrlITU1tdW55eXmLY+Xl5eTmxrYNuWnSoQPsjr5+d6AcRacc7Z3yE51yFJ1yFJ1ytHdqdC4iIiLShY0cORKbzdaiWfnSpUsZPXo0FkvLoV5BQQFff/01ZtPo2DRNli1bRkFBQWeGLCIiIgKoKCUiIiLSpSUkJHDqqadyww03sHLlSt5++20WLlzIeeedB4RnTXk8HgBmzJhBbW0tt956K+vXr+fWW2/F7XZzwgknxPMRREREpIdSUUpERESki5s9ezb5+fmcf/753HjjjVx11VVMnz4dgClTpvD6668DkJyczIMPPsjSpUuZOXMmK1as4KGHHiIxMTGe4YuIiEgPpZ5SIiIiIl1cQkICCxYsYMGCBa3eW7duXYvXY8aM4d///ndnhSYiIiKyRz2uKGUYHXvdjrp+V6f8RKccRaccRaccRaccRdfTc9RTnzsWGk/Fj3IUnXK0d8pPdMpRdMpRdD09R219bsM01QdeREREREREREQ6l3pKiYiIiIiIiIhIp1NRSkREREREREREOp2KUiIiIiIiIiIi0ulUlBIRERERERERkU6nopSIiIiIiIiIiHQ6FaVERERERERERKTTqSglIiIiIiIiIiKdTkUpERERERERERHpdCpK7Sev18ucOXOYOHEiU6ZMYeHChfEOKe5KSkq4+uqrmTRpEkceeSTz58/H6/UCUFRUxAUXXMDYsWM58cQT+fjjj+McbfxdeumlXHfddZHXa9as4cwzz6SgoIDTTz+dVatWxTG6+PH5fNx4440ceuih/OhHP+LOO+/ENE1AOWq2fft2LrvsMsaPH8/UqVN5/PHHI+/19Bz5fD5OOukkPv/888ixaH//fPLJJ5x00kkUFBRw3nnnUVRU1Nlhd6rd5Wj58uWcddZZjBs3juOPP57Fixe3+ExPy5F0Lo2pWtJ4KjYaT+2exlPRaTy1ZxpPRafx1P5TUWo/3X777axatYpFixYxb9487r33Xt544414hxU3pmly9dVX43a7eeqpp7jrrrt47733uPvuuzFNkyuvvJLs7GxeeOEFTjnlFGbNmkVxcXG8w46b1157jQ8++CDyurGxkUsvvZSJEyfy4osvMm7cOC677DIaGxvjGGV83HLLLXzyySc8+uij/PWvf+W5557j2WefVY528X//938kJiby4osvMmfOHO6++27eeuutHp8jr9fL7373OwoLCyPHov39U1xczJVXXsnMmTN5/vnnyczM5IorrogM3Lub3eWorKyMSy65hEmTJvHvf/+bq6++mptvvpn3338f6Hk5ks6nMdVOGk/FRuOpPdN4KjqNp3ZP46noNJ5qJ6bss4aGBnP06NHmZ599Fjl23333mb/85S/jGFV8rV+/3hw+fLhZVlYWObZkyRJzypQp5ieffGKOHTvWbGhoiLx3/vnnm3//+9/jEWrcVVVVmT/+8Y/N008/3bz22mtN0zTNxYsXm1OnTjVDoZBpmqYZCoXM4447znzhhRfiGWqnq6qqMkeNGmV+/vnnkWMPPviged111ylHTaqrq83hw4eb69atixybNWuWeeONN/boHBUWFpo//elPzZNPPtkcPnx45O/naH//3H333S3+7m5sbDTHjRvX4u/37mJPOfrXv/5lzpgxo8W5f/rTn8zf/e53pmn2rBxJ59OYqiWNp9pO46k903gqOo2ndk/jqeg0nmo/mim1H9auXUsgEGDcuHGRYxMmTGDFihWEQqE4RhY/OTk5PPLII2RnZ7c4Xl9fz4oVKxg1ahSJiYmR4xMmTGD58uWdHOWBYcGCBZxyyikMHTo0cmzFihVMmDABwzAAMAyD8ePH97gcLV26lOTkZCZNmhQ5dumllzJ//nzlqInL5SIhIYEXX3wRv9/Pxo0bWbZsGSNHjuzROfriiy+YPHkyzz77bIvj0f7+WbFiBRMnToy8l5CQQH5+frfM2Z5y1Lw86Ifq6+uBnpUj6XwaU7Wk8VTbaTy1ZxpPRafx1O5pPBWdxlPtR0Wp/VBWVkZGRgYOhyNyLDs7G6/XS3V1dfwCi6PU1FSOPPLIyOtQKMSTTz7JYYcdRllZGbm5uS3Oz8rKYseOHZ0dZtx9+umnfPXVV1xxxRUtjitHYUVFRfTt25eXXnqJGTNmcOyxx3LfffcRCoWUoyZOp5Prr7+eZ599loKCAk444QR+/OMfc+aZZ/boHP3iF79gzpw5JCQktDgeLSc9KWd7ylG/fv0YO3Zs5HVFRQWvvfYahx9+ONCzciSdT2OqljSeahuNp/ZO46noNJ7aPY2notN4qv3Y4h1AV+Z2u1sMnoDIa5/PF4+QDjh33HEHa9as4fnnn+fxxx/fbb56Wq68Xi/z5s3j+uuvx+VytXhvT99TPS1HjY2NbNmyhWeeeYb58+dTVlbG9ddfT0JCgnK0iw0bNnDMMcfwq1/9isLCQm6++WYOP/xw5Wg3ouVEOWvJ4/Fw1VVXkZ2dzc9//nNAOZKOpTHV3mk81ZrGU9FpPNU2Gk+1ncZTsdF4qm1UlNoPTqez1TdP8+sf/s+xJ7rjjjtYtGgRd911F8OHD8fpdLb6aafP5+txubr33ns55JBDWvwEtNmevqd6Wo5sNhv19fX89a9/pW/fvkC4KeDTTz/NgAEDlCPCPx1+/vnn+eCDD3C5XIwePZqSkhLuv/9++vfvrxz9QLS/f/b0315qampnhXjAaGho4IorrmDz5s3861//ivwEUDmSjqQx1Z5pPLV7Gk9Fp/FUdBpPxUbjqbbTeKrttHxvP+Tl5VFVVUUgEIgcKysrw+Vy9ehvKoCbb76Zxx57jDvuuIPjjz8eCOervLy8xXnl5eWtpi92d6+99hpvv/0248aNY9y4cSxZsoQlS5Ywbtw45ahJTk4OTqczMoACGDRoENu3b1eOmqxatYoBAwa0GBiNGjWK4uJi5Wg3ouVkT+/n5OR0WowHgvr6ei666CIKCwtZtGgRAwcOjLynHElH0phq9zSe2jONp6LTeCo6jadio/FU22g8FRsVpfbDyJEjsdlsLZqSLV26lNGjR2Ox9NzU3nvvvTzzzDPceeed/OQnP4kcLygoYPXq1Xg8nsixpUuXUlBQEI8w4+af//wnS5Ys4aWXXuKll15i6tSpTJ06lZdeeomCggK+/vrryJagpmmybNmyHpejgoICvF4vmzZtihzbuHEjffv2VY6a5ObmsmXLlhY/adm4cSP9+vVTjnYj2t8/BQUFLF26NPKe2+1mzZo1PSpnoVCIWbNmsXXrVv75z38ybNiwFu8rR9KRNKZqTeOpvdN4KjqNp6LTeCo2Gk9Fp/FU7Hrm/+XbSUJCAqeeeio33HADK1eu5O2332bhwoWcd9558Q4tbjZs2MA//vEPLrnkEiZMmEBZWVnka9KkSfTu3ZvZs2dTWFjIQw89xMqVKznjjDPiHXan6tu3LwMGDIh8JSUlkZSUxIABA5gxYwa1tbXceuutrF+/nltvvRW3280JJ5wQ77A71eDBgzn66KOZPXs2a9eu5aOPPuKhhx7i7LPPVo6aTJ06Fbvdzh//+Ec2bdrEu+++ywMPPMC5556rHO1GtL9/Tj/9dJYtW8ZDDz1EYWEhs2fPpl+/fkyePDnOkXee559/ns8//5xbbrmF1NTUyN/dzdP0lSPpSBpTtaTxVHQaT0Wn8VR0Gk/FRuOp6DSe2gem7JfGxkbzmmuuMceOHWtOmTLFfOyxx+IdUlw9+OCD5vDhw3f7ZZqmuXnzZvOcc84xDznkEPMnP/mJ+b///S/OEcfftddea1577bWR1ytWrDBPPfVUc/To0eYZZ5xhrl69Oo7RxU9tba35hz/8wRw7dqx5+OGHm/fcc48ZCoVM01SOmhUWFpoXXHCBOX78eHPatGnmY489phztYvjw4eZnn30WeR3t75/333/fnD59ujlmzBjz/PPPN7///vvODrnT7ZqjCy+8cLd/d//yl7+MnN8TcySdR2OqnTSeip3GU7un8VR0Gk/tncZT0Wk8tX8M02yajygiIiIiIiIiItJJtHxPREREREREREQ6nYpSIiIiIiIiIiLS6VSUEhERERERERGRTqeilIiIiIiIiIiIdDoVpUREREREREREpNOpKCUiIiIiIiIiIp1ORSkREREREREREel0KkqJiIiIiIiIiEins8U7ABGRfTF16lS2bdu22/eeeOIJJk+e3CH3ve666wD485//3CHXFxEREeksGk+JSLypKCUiXdacOXM48cQTWx1PS0uLQzQiIiIiXY/GUyISTypKiUiXlZKSQk5OTrzDEBEREemyNJ4SkXhSTykR6ZamTp3K448/zsknn8zYsWO59NJLKSsri7y/YcMGLrroIsaPH8+RRx7JvffeSygUirz/8ssvM2PGDAoKCjjrrLNYs2ZN5L36+np++9vfUlBQwNFHH82SJUs69dlEREREOoPGUyLS0VSUEpFu65577uHiiy/m2Wefxe12c9VVVwFQWVnJL37xC3Jzc1m8eDHz5s3jySef5IknngDgo48+Yu7cuZx//vm88sorHHLIIVx22WX4fD4A3nrrLfLz83n11Vc54YQTmDNnDnV1dXF7ThEREZGOovGUiHQkwzRNM95BiIjEaurUqZSVlWGztVyF3KdPH1577TWmTp3KtGnTmDNnDgBFRUVMmzaNJUuW8Nlnn7Fw4ULefvvtyOeffvpp7rvvPj7++GNmzZpFcnJypPmmz+fjrrvu4sILL+Svf/0rmzdv5plnngGgrq6OiRMn8txzz1FQUNCJGRARERHZPxpPiUi8qaeUiHRZV199NdOnT29xbNdB1fjx4yO/79+/P+np6WzYsIENGzaQn5/f4txx48ZRVlZGbW0tmzZt4qyzzoq853A4uPbaa1tcq1lKSgoAXq+3/R5MREREpJNoPCUi8aSilIh0WVlZWQwYMGCP7//wp37BYBCLxYLT6Wx1bnP/g2Aw2OpzP2S1Wlsd06RTERER6Yo0nhKReFJPKRHpttauXRv5/ZYtW6irq2PEiBEMGjSI1atX4/f7I+9//fXXZGZmkp6ezoABA1p8NhgMMnXqVJYuXdqp8YuIiIjEm8ZTItKRVJQSkS6rrq6OsrKyVl+NjY0APPHEE7zzzjusXbuWOXPmcMQRRzBw4EBOPvlkfD4f119/PRs2bODtt9/mnnvu4eyzz8YwDM4991xeeeUV/v3vf7Nlyxbmz5+PaZrk5+fH+YlFRERE2pfGUyIST1q+JyJd1m233cZtt93W6vhvfvMbAE477TTuvPNOiouLOeqoo7jxxhsBSE5O5pFHHuHWW2/l1FNPJTMzk/PPP5/LLrsMgEMPPZR58+Zx3333UVZWxiGHHMIDDzyAy+XqvIcTERER6QQaT4lIPGn3PRHplqZOncqsWbOYOXNmvEMRERER6ZI0nhKRjqbleyIiIiIiIiIi0ulUlBIRERERERERkU6n5XsiIiIiIiIiItLpNFNKREREREREREQ6nYpSIiIiIiIiIiLS6VSUEhERERERERGRTqeilIiIiIiIiIiIdDoVpUREREREREREpNOpKCUiIiIiIiIiIp1ORSkREREREREREel0KkqJiIiIiIiIiEinU1FKREREREREREQ63f8HzWs5zfaLWokAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "##          SINGLE VIDEO PREDICTION TEST         ##\n",
    "def predict_handsign(video_path, model):\n",
    "    # Process the video to extract landmarks\n",
    "    video_data = process_video(video_path)\n",
    "    \n",
    "    # Reshape the data to match the model input shape (add batch dimension for a single video)\n",
    "    video_data = video_data.reshape(1, frames_per_video, num_landmarks, num_coordinates)\n",
    "        # Make the prediction\n",
    "    prediction = model.predict(video_data)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    \n",
    "    return predicted_class, confidence  \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model('best_handsigns_model.keras')\n",
    "    \n",
    "    test_directory = \"Model testing videos\"\n",
    "    for video_file in os.listdir(test_directory):\n",
    "        if video_file.endswith(('.mp4', '.avi', '.mov')):\n",
    "            video_path = os.path.join(test_directory, video_file)\n",
    "            predicted_class, confidence = predict_handsign(video_path, model)\n",
    "            \n",
    "            # Get hand sign name\n",
    "            predicted_handsign = handsign_names.get(predicted_class, f\"HandSign_{predicted_class}\")\n",
    "            \n",
    "            # Apply confidence threshold\n",
    "            if confidence < 0.7:\n",
    "                predicted_handsign = \"Inseguro (\"+predicted_handsign+\")\"\n",
    "                \n",
    "            print(f\"Video: {video_file}\")\n",
    "            print(f\"Predicted Hand Sign: {predicted_handsign}\")\n",
    "            print(f\"Confidence: {confidence:.2f}\")\n",
    "            print(\"--------------------\")\n"
   ],
   "id": "4f9ed1d4df51b1c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:24:30.101245Z",
     "start_time": "2024-10-17T13:24:27.691452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          CONTINUOUS PREDICTION WITH SLIDING WINDOW           ##\n",
    "\n",
    "import collections\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from scipy.interpolate import interp1d  # For smoothing landmarks\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('best_handsigns_model.keras')\n",
    "\n",
    "# Initialize Mediapipe solutions outside the loop for efficiency\n",
    "mp_hands = mp.solutions.hands.Hands(static_image_mode=False, \n",
    "                                    max_num_hands=2, \n",
    "                                    min_detection_confidence=0.4,  # Lowered confidence to allow for fast movement detection\n",
    "                                    min_tracking_confidence=0.4)   # Lowered tracking confidence\n",
    "mp_pose = mp.solutions.pose.Pose(static_image_mode=False, \n",
    "                                 min_detection_confidence=0.4, \n",
    "                                 min_tracking_confidence=0.4)\n",
    "\n",
    "# Open webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Sliding window buffer for frames\n",
    "frame_buffer = collections.deque(maxlen=frames_per_video)\n",
    "\n",
    "# To smooth predictions, keep track of recent predictions\n",
    "prediction_buffer = collections.deque(maxlen=3)\n",
    "\n",
    "# Store the last prediction\n",
    "last_prediction = \"No Prediction\"\n",
    "last_confidence = 0.0\n",
    "\n",
    "# Track missing hands to reset landmarks if missing for too long\n",
    "hand_missing_threshold = 5\n",
    "left_hand_missing_count = 0\n",
    "right_hand_missing_count = 0\n",
    "\n",
    "# Store the last known hand landmarks to compare in future frames\n",
    "last_left_hand_landmarks = None\n",
    "last_right_hand_landmarks = None\n",
    "\n",
    "# Movement delta threshold for fast movements\n",
    "movement_threshold = 0.9  # Adjusted threshold for movement delta\n",
    "\n",
    "# Smoothing factor for missing landmarks\n",
    "smoothing_factor = 0.8  # Weight to smooth landmarks during quick movements\n",
    "\n",
    "# Draw landmarks on the frame\n",
    "def draw_landmarks(frame, landmarks):\n",
    "    \"\"\"Draw landmarks on the frame.\"\"\"\n",
    "    for i, (x, y, z) in enumerate(landmarks):\n",
    "        h, w, _ = frame.shape\n",
    "        x = int(x * w + 325)\n",
    "        y = int(y * h + 250)\n",
    "        \n",
    "        if i < 21:  # Left hand landmarks\n",
    "            color = (0, 255, 0)\n",
    "        elif i < 42:  # Right hand landmarks\n",
    "            color = (0, 0, 255)\n",
    "        else:  # Body landmarks\n",
    "            color = (255, 0, 0)\n",
    "        \n",
    "        cv2.circle(frame, (x, y), 5, color, -1)\n",
    "\n",
    "def smooth_landmarks(new_landmarks, old_landmarks):\n",
    "    \"\"\"Smooth landmarks by interpolating between old and new.\"\"\"\n",
    "    if old_landmarks is None:\n",
    "        return new_landmarks\n",
    "\n",
    "    return old_landmarks * (1 - smoothing_factor) + new_landmarks * smoothing_factor\n",
    "\n",
    "def process_frame(frame):\n",
    "    global last_left_hand_landmarks, last_right_hand_landmarks\n",
    "    global left_hand_missing_count, right_hand_missing_count\n",
    "\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    hands_results = mp_hands.process(image)\n",
    "    pose_results = mp_pose.process(image)\n",
    "\n",
    "    # Initialize a zero-filled array for landmarks (51 landmarks, each with x, y, z)\n",
    "    landmarks = np.zeros((num_landmarks, num_coordinates))\n",
    "\n",
    "    # Detect nose for relative normalization\n",
    "    try:\n",
    "        nose_landmark = pose_results.pose_landmarks.landmark[0]\n",
    "    except:\n",
    "        class nose_landmark:\n",
    "            x = 0\n",
    "            y = 0\n",
    "            z = 0\n",
    "        nose_landmark = nose_landmark()\n",
    "\n",
    "    if hands_results.multi_hand_landmarks:\n",
    "        handedness_labels = [hand.classification[0].label for hand in hands_results.multi_handedness]\n",
    "\n",
    "        for i, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):\n",
    "            if handedness_labels[i] == 'Left':\n",
    "                left_hand = np.array([(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) \n",
    "                                      for lm in hand_landmarks.landmark])\n",
    "\n",
    "                # Smooth the transition between frames\n",
    "                left_hand = smooth_landmarks(left_hand, last_left_hand_landmarks)\n",
    "                \n",
    "                # Update the stored landmarks for the next frame\n",
    "                last_left_hand_landmarks = left_hand\n",
    "                landmarks[:21] = left_hand  # Insert the left hand landmarks into the first 21 slots\n",
    "\n",
    "            elif handedness_labels[i] == 'Right':\n",
    "                right_hand = np.array([(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) \n",
    "                                       for lm in hand_landmarks.landmark])\n",
    "\n",
    "                # Smooth the transition between frames\n",
    "                right_hand = smooth_landmarks(right_hand, last_right_hand_landmarks)\n",
    "                \n",
    "                # Update the stored landmarks for the next frame\n",
    "                last_right_hand_landmarks = right_hand\n",
    "                landmarks[21:42] = right_hand  # Insert the right hand landmarks into slots 21-42\n",
    "\n",
    "        # Reset the missing counts if hands are detected\n",
    "        left_hand_missing_count = 0\n",
    "        right_hand_missing_count = 0\n",
    "    else:\n",
    "        # Increment missing count when hands are not detected\n",
    "        left_hand_missing_count += 1\n",
    "        right_hand_missing_count += 1\n",
    "\n",
    "        # Reuse last known landmarks if available and hands are missing for too long\n",
    "        if last_left_hand_landmarks is not None:\n",
    "            landmarks[:21] = last_left_hand_landmarks\n",
    "        if last_right_hand_landmarks is not None:\n",
    "            landmarks[21:42] = last_right_hand_landmarks\n",
    "\n",
    "        # Reset landmarks if hands are missing for too long\n",
    "        if left_hand_missing_count > hand_missing_threshold:\n",
    "            last_left_hand_landmarks = None\n",
    "        if right_hand_missing_count > hand_missing_threshold:\n",
    "            last_right_hand_landmarks = None\n",
    "\n",
    "    # Fill in body landmarks (9 selected)\n",
    "    selected_body_landmarks = [0, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "    if pose_results.pose_landmarks:\n",
    "        for idx, landmark_idx in enumerate(selected_body_landmarks):\n",
    "            lm = pose_results.pose_landmarks.landmark[landmark_idx]\n",
    "            landmarks[42 + idx] = (lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z)\n",
    "\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "# Make a prediction based on the buffer\n",
    "def predict_handsign(buffer):\n",
    "    \"\"\"Make a prediction based on a buffer of frames.\"\"\"    \n",
    "    video_data = np.array(buffer)\n",
    "    video_data = video_data.reshape(1, frames_per_video, num_landmarks, num_coordinates)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(video_data, verbose=0)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_class]\n",
    "\n",
    "    return predicted_class, confidence\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Process every frame (no skipping)\n",
    "    landmarks = process_frame(frame)\n",
    "\n",
    "    # Add the landmarks to the frame buffer\n",
    "    frame_buffer.append(landmarks)\n",
    "\n",
    "    # Draw the landmarks on the frame\n",
    "    draw_landmarks(frame, landmarks)\n",
    "\n",
    "    # Once the buffer is full, make a prediction using the sliding window\n",
    "    if len(frame_buffer) == frames_per_video:\n",
    "        predicted_class, confidence = predict_handsign(frame_buffer)\n",
    "        predicted_handsign = handsign_names.get(predicted_class, f\"HandSign_{predicted_class}\")\n",
    "\n",
    "        # Update the last prediction\n",
    "        last_prediction = predicted_handsign\n",
    "        last_confidence = confidence\n",
    "\n",
    "        # Store prediction and confidence in the buffer for smoothing\n",
    "        #print((predicted_class, confidence))\n",
    "        prediction_buffer.append((predicted_class, confidence))\n",
    "\n",
    "        # Average the last N predictions to smooth the output\n",
    "        avg_pred_class = np.argmax(np.bincount([p[0] for p in prediction_buffer]))\n",
    "        avg_confidence = np.mean([p[1] for p in prediction_buffer if p[0] == avg_pred_class])\n",
    "\n",
    "        if avg_confidence > 0.8:\n",
    "            last_prediction = handsign_names.get(avg_pred_class, f\"HandSign_{avg_pred_class}\")\n",
    "            last_confidence = avg_confidence\n",
    "        elif 0.45 < avg_confidence < 0.8:\n",
    "            last_prediction = \"deteccion insegura: \"+handsign_names.get(avg_pred_class, f\"HandSign_{avg_pred_class}\")\n",
    "            last_confidence = avg_confidence\n",
    "        else:\n",
    "            last_prediction = \"deteccion nula\"\n",
    "            last_confidence = avg_confidence\n",
    "            \n",
    "    # Display the last prediction on the frame\n",
    "    cv2.putText(frame, f\"Predicted: {last_prediction} Conf: {last_confidence:.2f}\", \n",
    "                (10, 30), cv2.FONT_ITALIC, 0.7, (0, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('Hands Recognition', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "ee106e95cdc75678",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T13:29:32.499093Z",
     "start_time": "2024-10-17T13:29:29.653478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##         V2 CONTINUOUS PREDICTION WITH SLIDING WINDOW           ##\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Parameters for video feed and predictions\n",
    "show_landmarks = True  # Toggle to show hand landmarks\n",
    "show_connections = True  # Toggle to show landmark connections\n",
    "show_prediction_text = True  # Toggle to show prediction and accuracy on screen\n",
    "accuracy_threshold = 0.7  # Threshold for highlighting low accuracy\n",
    "sliding_window_size = 10  # Size of the sliding window for prediction\n",
    "smoothing_buffer_size = 5  # Buffer size for prediction smoothing (larger = smoother)\n",
    "mediapipe_confidence = 0.7  # Confidence threshold for mediapipe detection\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('handsigns_model.h5')\n",
    "\n",
    "# Initialize MediaPipe hands and pose solutions\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "hands = mp_hands.Hands(min_detection_confidence=mediapipe_confidence, min_tracking_confidence=mediapipe_confidence)\n",
    "pose = mp_pose.Pose(min_detection_confidence=mediapipe_confidence, min_tracking_confidence=mediapipe_confidence)\n",
    "\n",
    "# Set up sliding window and smoothing buffer\n",
    "sliding_window = deque(maxlen=sliding_window_size)\n",
    "smoothing_buffer = deque(maxlen=smoothing_buffer_size)\n",
    "\n",
    "# Initialize video capture (webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "last_handedness = {'Left': False, 'Right': False}\n",
    "\n",
    "# Function to smooth predictions\n",
    "def smooth_predictions(predictions):\n",
    "    if len(predictions) > 0:\n",
    "        return np.mean(predictions, axis=0)\n",
    "    return np.zeros(num_handsigns)\n",
    "\n",
    "# Main loop for video feed and prediction\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    #frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Process frame to extract landmarks and results\n",
    "    landmarks, last_handedness = process_frame(frame, hands, pose, last_handedness)\n",
    "    hands_results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    pose_results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Append the landmarks to the sliding window\n",
    "    sliding_window.append(landmarks)\n",
    "    \n",
    "    # Check if the sliding window is full\n",
    "    if len(sliding_window) == sliding_window_size:\n",
    "        # Prepare input for the model (reshape and normalize)\n",
    "        input_data = np.array(sliding_window).reshape(1, sliding_window_size, num_landmarks, num_coordinates)\n",
    "        \n",
    "        # Predict the hand sign\n",
    "        predictions = model.predict(input_data)\n",
    "        prediction = np.argmax(predictions)\n",
    "        confidence = np.max(predictions)\n",
    "        \n",
    "        # Add the prediction to the smoothing buffer\n",
    "        smoothing_buffer.append(predictions)\n",
    "        smoothed_predictions = smooth_predictions(smoothing_buffer)\n",
    "        smoothed_prediction = np.argmax(smoothed_predictions)\n",
    "        smoothed_confidence = np.max(smoothed_predictions)\n",
    "\n",
    "        # Display prediction on screen if enabled\n",
    "        if show_prediction_text:\n",
    "            text = f\"Sign: {handsign_names[smoothed_prediction]}, Accuracy: {smoothed_confidence:.2f}\"\n",
    "            if smoothed_confidence < accuracy_threshold:\n",
    "                text += \" (Low accuracy)\"\n",
    "            cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Draw landmarks if enabled\n",
    "    if show_landmarks and hands_results.multi_hand_landmarks:\n",
    "        for hand_landmarks in hands_results.multi_hand_landmarks:\n",
    "            if show_connections:\n",
    "                mp.solutions.drawing_utils.draw_landmarks(\n",
    "                    frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            else:\n",
    "                mp.solutions.drawing_utils.draw_landmarks(frame, hand_landmarks)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Hand Sign Recognition', frame)\n",
    "\n",
    "    # Break the loop with 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ],
   "id": "41e6691dae6fe336",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 309ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "##          MODEL TESTING          ##\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_and_preprocess_test_data(test_data_path):\n",
    "    # Reuse the process_dataset function\n",
    "    test_data = process_dataset(test_data_path)\n",
    "    \n",
    "    # Reshape the data to match the model input shape\n",
    "    X_test = test_data.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "    y_test = np.repeat(np.arange(num_handsigns), videos_per_handsign)\n",
    "    \n",
    "    return X_test, y_test\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Generate classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_classes))\n",
    "    \n",
    "    return y_pred_classes\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_misclassifications(X_test, y_test, y_pred, num_samples=5):\n",
    "    misclassified = np.where(y_test != y_pred)[0]\n",
    "    np.random.shuffle(misclassified)\n",
    "    \n",
    "    for i in range(min(num_samples, len(misclassified))):\n",
    "        idx = misclassified[i]\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Plot a representation of the hand sign (e.g., first frame landmarks)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(X_test[idx, 0, :, 0], X_test[idx, 0, :, 1])\n",
    "        plt.title(f\"True: {y_test[idx]}, Predicted: {y_pred[idx]}\")\n",
    "        plt.xlabel(\"X coordinate\")\n",
    "        plt.ylabel(\"Y coordinate\")\n",
    "        \n",
    "        # Plot the confidence scores for each class\n",
    "        plt.subplot(1, 2, 2)\n",
    "        confidence_scores = model.predict(X_test[idx:idx+1])[0]\n",
    "        plt.bar(range(num_handsigns), confidence_scores)\n",
    "        plt.title(\"Confidence Scores\")\n",
    "        plt.xlabel(\"Hand Sign Class\")\n",
    "        plt.ylabel(\"Confidence\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model('handsigns_model.h5')\n",
    "    \n",
    "    # Load and preprocess test data\n",
    "    test_data_path = \"Model testing videos\"  # Replace with your test dataset path\n",
    "    X_test, y_test = load_and_preprocess_test_data(test_data_path)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Visualize some misclassifications\n",
    "    visualize_misclassifications(X_test, y_test, y_pred)"
   ],
   "id": "67b4c8b4c4f1ca0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "819a4814bfc8aec8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
