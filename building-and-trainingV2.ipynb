{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T05:43:27.479214Z",
     "start_time": "2024-10-17T05:43:27.467669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          DATA SHAPE DEFINITION           ##\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define the parameters for the data shape\n",
    "videos_per_handsign = 2  # Adjust if necessary\n",
    "frames_per_video = 10\n",
    "num_landmarks = 51\n",
    "num_coordinates = 3\n",
    "\n",
    "num_additional_samples = 2      #how many different samples of frames_per_video frames will be taken from each video (carefull to not add too many if vids are short)\n",
    "\n",
    "data_augmentation = True        #Add noise and transformation to generate, from each video extracted, a num_augmented_versions number of new ones (also keep between 1-4)\n",
    "num_augmented_versions = 2\n",
    "\n",
    "# Define the root directory containing handsign folders\n",
    "root_path = \"ACOTADONomenclatedDataset\"\n",
    "\n",
    "def get_handsign_folders(root_path):\n",
    "    handsign_names = {}\n",
    "    handsign_video_counts = {}  # To store the video count for each handsign\n",
    "    handsign_count = 0\n",
    "    \n",
    "    # Walk through the root directory\n",
    "    for folder in os.listdir(root_path):\n",
    "        folder_path = os.path.join(root_path, folder)\n",
    "        \n",
    "        # Ignore non-directories\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # If the folder starts with \"#\", check its subdirectories\n",
    "        if folder.startswith(\"#\"):\n",
    "            for subfolder in os.listdir(folder_path):\n",
    "                subfolder_path = os.path.join(folder_path, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    handsign_names[handsign_count] = subfolder\n",
    "                    # Count videos in the subfolder\n",
    "                    videos = [f for f in os.listdir(subfolder_path) if f.endswith(('.mp4', '.avi', '.MOV'))]\n",
    "                    handsign_video_counts[subfolder] = len(videos)\n",
    "                    handsign_count += 1\n",
    "        else:\n",
    "            # Directly add the folder as a handsign\n",
    "            handsign_names[handsign_count] = folder\n",
    "            # Count videos in the folder\n",
    "            videos = [f for f in os.listdir(folder_path) if f.endswith(('.mp4', '.avi', '.MOV'))]\n",
    "            handsign_video_counts[folder] = len(videos)\n",
    "            handsign_count += 1\n",
    "    \n",
    "    return handsign_names, handsign_video_counts\n",
    "\n",
    "# Get the handsign names and video counts\n",
    "handsign_names, handsign_video_counts = get_handsign_folders(root_path)\n",
    "num_handsigns = len(handsign_names)\n",
    "\n",
    "# Sort handsigns by the number of available videos in descending order\n",
    "sorted_handsign_video_counts = dict(sorted(handsign_video_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Output the handsign names, number of handsigns, and sorted video counts\n",
    "print(f\"Number of handsigns: {num_handsigns}\")\n",
    "print(\"Handsign names:\")\n",
    "print(json.dumps(handsign_names, indent=4))\n",
    "\n",
    "print(\"\\nVideo counts per handsign (sorted by number of videos):\")\n",
    "print(json.dumps(sorted_handsign_video_counts, indent=4))\n"
   ],
   "id": "823e51359a2141fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of handsigns: 10\n",
      "Handsign names:\n",
      "{\n",
      "    \"0\": \"apellido\",\n",
      "    \"1\": \"argentina\",\n",
      "    \"2\": \"ayuda\",\n",
      "    \"3\": \"C\",\n",
      "    \"4\": \"comprar\",\n",
      "    \"5\": \"cumplea\\u00f1os\",\n",
      "    \"6\": \"hijo\",\n",
      "    \"7\": \"I\",\n",
      "    \"8\": \"mujer\",\n",
      "    \"9\": \"V\"\n",
      "}\n",
      "\n",
      "Video counts per handsign (sorted by number of videos):\n",
      "{\n",
      "    \"C\": 163,\n",
      "    \"cumplea\\u00f1os\": 143,\n",
      "    \"mujer\": 137,\n",
      "    \"apellido\": 136,\n",
      "    \"V\": 100,\n",
      "    \"I\": 97,\n",
      "    \"comprar\": 84,\n",
      "    \"hijo\": 83,\n",
      "    \"argentina\": 81,\n",
      "    \"ayuda\": 74\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T05:43:32.835621Z",
     "start_time": "2024-10-17T05:43:32.823703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "#redefine videos per handsign to accomodate for additional samples to be taken before generating the dummy array (this is done so there's no shaping/dimensions size incompatibility issue)\n",
    "videos_per_handsign = videos_per_handsign * (1+num_additional_samples)\n",
    "\n",
    "# Generate dummy data\n",
    "data = [np.random.rand(videos_per_handsign, frames_per_video, num_landmarks, num_coordinates) for _ in range(num_handsigns)]\n",
    "\n",
    "# Convert the list to a numpy array with shape (num_handsigns, videos_per_handsign, frames_per_video, num_landmarks, num_coordinates)\n",
    "data_array = np.array(data)\n",
    "\n",
    "# Save the data array to a .npy file\n",
    "np.save('handsigns_data.npy', data_array)"
   ],
   "id": "fa59d6b8b575718a",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T05:48:32.647258Z",
     "start_time": "2024-10-17T05:48:32.633404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          PROCESS VIDEO DATASET FUNC DEFINITIONS         ##\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_landmarks(hands_results, pose_results, last_handedness):\n",
    "    landmarks = []\n",
    "\n",
    "    try:\n",
    "        nose_landmark = pose_results.pose_landmarks.landmark[0]\n",
    "    except:\n",
    "        class nose_landmark:\n",
    "            x = 0\n",
    "            y = 0\n",
    "            z = 0\n",
    "        nose_landmark = nose_landmark()\n",
    "\n",
    "    left_hand_landmarks = [(0, 0, 0)] * 21\n",
    "    right_hand_landmarks = [(0, 0, 0)] * 21\n",
    "\n",
    "    if hands_results.multi_hand_landmarks and hands_results.multi_handedness:\n",
    "        for i, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):\n",
    "            label = hands_results.multi_handedness[i].classification[0].label\n",
    "            if label == 'Left':\n",
    "                left_hand_landmarks = [(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) for lm in hand_landmarks.landmark]\n",
    "                last_handedness['Left'] = True\n",
    "            elif label == 'Right':\n",
    "                right_hand_landmarks = [(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) for lm in hand_landmarks.landmark]\n",
    "                last_handedness['Right'] = True\n",
    "\n",
    "    if not hands_results.multi_hand_landmarks or len(hands_results.multi_hand_landmarks) < 2:\n",
    "        if not last_handedness.get('Left'):\n",
    "            left_hand_landmarks = [(0, 0, 0)] * 21\n",
    "        if not last_handedness.get('Right'):\n",
    "            right_hand_landmarks = [(0, 0, 0)] * 21\n",
    "\n",
    "    landmarks.extend(left_hand_landmarks)\n",
    "    landmarks.extend(right_hand_landmarks)\n",
    "\n",
    "    selected_body_landmarks = [0, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "    if pose_results.pose_landmarks:\n",
    "        for idx in selected_body_landmarks:\n",
    "            lm = pose_results.pose_landmarks.landmark[idx]\n",
    "            landmarks.append((lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z))\n",
    "    else:\n",
    "        landmarks.extend([(0, 0, 0)] * 9)\n",
    "\n",
    "    return np.array(landmarks), last_handedness\n",
    "\n",
    "\n",
    "def process_frame(frame, hands, pose, last_handedness):\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    hands_results = hands.process(image)\n",
    "    pose_results = pose.process(image)\n",
    "\n",
    "    landmarks, last_handedness = extract_landmarks(hands_results, pose_results, last_handedness)\n",
    "\n",
    "    return landmarks, last_handedness\n",
    "\n",
    "\n",
    "def process_video_with_samples(video_path, frames_per_video, num_landmarks, num_coordinates, num_additional_samples=0):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames == 0:\n",
    "        print(f\"Warning: Video {video_path} contains zero frames. Filling this video's samples with zeros.\")\n",
    "        return np.zeros((1 + num_additional_samples, frames_per_video, num_landmarks, num_coordinates))\n",
    "\n",
    "    # Original sample selection: evenly spaced frames across the whole video\n",
    "    if total_frames < frames_per_video:\n",
    "        print(f\"Warning: Video {video_path} has fewer frames ({total_frames}) than required ({frames_per_video}). Duplicating frames to match.\")\n",
    "        indices = np.linspace(0, total_frames - 1, frames_per_video, dtype=int)\n",
    "    else:\n",
    "        indices = np.linspace(0, total_frames - 1, frames_per_video, dtype=int)\n",
    "    \n",
    "    frame_sets = [indices]  # Keep track of selected frames\n",
    "    used_frames = set(indices)  # Record frames already used\n",
    "    \n",
    "    for i in range(1, num_additional_samples + 1):\n",
    "        available_frames = list(set(range(total_frames)) - used_frames)\n",
    "        \n",
    "        # If there are fewer available frames than needed, duplicate frames but spread them across the video\n",
    "        if len(available_frames) < frames_per_video:\n",
    "            # Select frames with possible duplication, spread evenly\n",
    "            additional_indices = np.linspace(0, total_frames - 1, frames_per_video, dtype=int)\n",
    "        else:\n",
    "            # Select evenly spaced frames from the remaining available frames\n",
    "            additional_indices = np.linspace(0, len(available_frames) - 1, frames_per_video, dtype=int)\n",
    "            additional_indices = [available_frames[idx] for idx in additional_indices]\n",
    "\n",
    "        used_frames.update(additional_indices)  # Update the set of used frames\n",
    "        frame_sets.append(additional_indices)  # Track the new sample\n",
    "\n",
    "    frames_data = []\n",
    "    last_handedness = {'Left': False, 'Right': False}\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    with mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5) as hands, \\\n",
    "         mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        \n",
    "        frame_count = 0\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            for frame_set in frame_sets:\n",
    "                if frame_count in frame_set:\n",
    "                    landmarks, last_handedness = process_frame(frame, hands, pose, last_handedness)\n",
    "                    frames_data.append(landmarks)\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Ensure the right number of frames is collected\n",
    "    while len(frames_data) < frames_per_video * (1 + num_additional_samples):\n",
    "        if len(frames_data) > 0:\n",
    "            frames_data.append(frames_data[-1])  # Duplicate the last frame only if necessary\n",
    "        else:\n",
    "            frames_data.append(np.zeros((num_landmarks, num_coordinates)))\n",
    "\n",
    "    reshaped_data = np.array(frames_data).reshape((1 + num_additional_samples, frames_per_video, num_landmarks, num_coordinates))\n",
    "\n",
    "    return reshaped_data\n",
    "\n",
    "\n",
    "\n",
    "def process_dataset_with_samples(root_path, handsign_names, frames_per_video, num_landmarks, num_coordinates, videos_per_handsign, num_additional_samples=0):\n",
    "    data = []\n",
    "\n",
    "    for handsign_index in tqdm(range(len(handsign_names)), desc=\"Processing handsigns\"):\n",
    "        handsign_folder = handsign_names[handsign_index]\n",
    "        handsign_path = os.path.join(root_path, handsign_folder)\n",
    "        \n",
    "        if not os.path.exists(handsign_path):\n",
    "            print(f\"Warning: Directory {handsign_path} does not exist. Skipping.\")\n",
    "            data.append(np.zeros((videos_per_handsign, frames_per_video, num_landmarks, num_coordinates)))\n",
    "            continue\n",
    "\n",
    "        videos = [f for f in os.listdir(handsign_path) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        handsign_data = []\n",
    "\n",
    "        # Calculate how many videos to process based on videos_per_handsign and num_additional_samples\n",
    "        max_videos_to_process = videos_per_handsign // (1 + num_additional_samples)\n",
    "        \n",
    "        # Process the required number of videos\n",
    "        for video in tqdm(videos[:max_videos_to_process], desc=f\"Processing videos for handsign {handsign_index}\", leave=False):\n",
    "            video_path = os.path.join(handsign_path, video)\n",
    "            \n",
    "            # Call the updated process_video_with_samples function\n",
    "            video_data = process_video_with_samples(video_path, frames_per_video, num_landmarks, num_coordinates, num_additional_samples)\n",
    "            \n",
    "            # Append all generated samples (original + additional) from the video\n",
    "            for sample in video_data:\n",
    "                handsign_data.append(sample)\n",
    "\n",
    "        handsign_data = np.array(handsign_data)\n",
    "        total_video_samples = handsign_data.shape[0]  # Total samples generated from the videos processed\n",
    "\n",
    "        # Ensure total number of video samples matches the predefined videos_per_handsign\n",
    "        if total_video_samples < videos_per_handsign:\n",
    "            padding_needed = videos_per_handsign - total_video_samples\n",
    "            print(f\"Warning: Handsign {handsign_index} ('{handsign_folder}') has only {total_video_samples} samples. \"\n",
    "                  f\"Padding with {padding_needed} empty samples.\")\n",
    "            handsign_data = np.pad(handsign_data, ((0, padding_needed), (0, 0), (0, 0), (0, 0)), mode='constant')\n",
    "        elif total_video_samples > videos_per_handsign:\n",
    "            handsign_data = handsign_data[:videos_per_handsign]\n",
    "            print(f\"Warning: More samples generated ({total_video_samples}) than expected ({videos_per_handsign}). Trimming excess samples.\")\n",
    "\n",
    "        data.append(handsign_data)\n",
    "\n",
    "    final_data = np.array(data)\n",
    "    print(f\"Final dataset shape: {final_data.shape}\")\n",
    "\n",
    "    return final_data\n",
    "\n",
    "\n"
   ],
   "id": "c6b1d3592b943838",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T05:49:13.415262Z",
     "start_time": "2024-10-17T05:48:36.403455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          PROCESS VIDEOS DATASET FUNC CALLING         ##\n",
    "data_array = process_dataset_with_samples(root_path, handsign_names, frames_per_video, num_landmarks, num_coordinates, videos_per_handsign, num_additional_samples)\n",
    "\n",
    "# Save the data array to a .npy file\n",
    "np.save('handsigns_data.npy', data_array)\n",
    "print(\"Data saved to handsigns_data.npy\")\n",
    "    "
   ],
   "id": "38b563f5e5342b66",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing handsigns:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Processing videos for handsign 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 0:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]\u001B[A\n",
      "Processing videos for handsign 0: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]\u001B[A\n",
      "Processing handsigns:  10%|█         | 1/10 [00:03<00:34,  3.79s/it]           \u001B[A\n",
      "Processing videos for handsign 1:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 1:  50%|█████     | 1/2 [00:01<00:01,  1.84s/it]\u001B[A\n",
      "Processing videos for handsign 1: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]\u001B[A\n",
      "Processing handsigns:  20%|██        | 2/10 [00:07<00:29,  3.73s/it]           \u001B[A\n",
      "Processing videos for handsign 2:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 2:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]\u001B[A\n",
      "Processing videos for handsign 2: 100%|██████████| 2/2 [00:05<00:00,  2.99s/it]\u001B[A\n",
      "Processing handsigns:  30%|███       | 3/10 [00:13<00:32,  4.68s/it]           \u001B[A\n",
      "Processing videos for handsign 3:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 3:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]\u001B[A\n",
      "Processing videos for handsign 3: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]\u001B[A\n",
      "Processing handsigns:  40%|████      | 4/10 [00:17<00:27,  4.59s/it]           \u001B[A\n",
      "Processing videos for handsign 4:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 4:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]\u001B[A\n",
      "Processing videos for handsign 4: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]\u001B[A\n",
      "Processing handsigns:  50%|█████     | 5/10 [00:21<00:21,  4.30s/it]           \u001B[A\n",
      "Processing videos for handsign 5:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 5:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]\u001B[A\n",
      "Processing videos for handsign 5: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]\u001B[A\n",
      "Processing handsigns:  60%|██████    | 6/10 [00:25<00:16,  4.03s/it]           \u001B[A\n",
      "Processing videos for handsign 6:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 6:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]\u001B[A\n",
      "Processing videos for handsign 6: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]\u001B[A\n",
      "Processing handsigns:  70%|███████   | 7/10 [00:28<00:11,  3.77s/it]           \u001B[A\n",
      "Processing videos for handsign 7:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 7:  50%|█████     | 1/2 [00:01<00:01,  1.29s/it]\u001B[A\n",
      "Processing videos for handsign 7: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\u001B[A\n",
      "Processing handsigns:  80%|████████  | 8/10 [00:30<00:06,  3.42s/it]           \u001B[A\n",
      "Processing videos for handsign 8:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 8:  50%|█████     | 1/2 [00:01<00:01,  1.77s/it]\u001B[A\n",
      "Processing videos for handsign 8: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]\u001B[A\n",
      "Processing handsigns:  90%|█████████ | 9/10 [00:34<00:03,  3.45s/it]           \u001B[A\n",
      "Processing videos for handsign 9:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 9:  50%|█████     | 1/2 [00:01<00:01,  1.27s/it]\u001B[A\n",
      "Processing videos for handsign 9: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]\u001B[A\n",
      "Processing handsigns: 100%|██████████| 10/10 [00:37<00:00,  3.70s/it]          \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (10, 6, 10, 51, 3)\n",
      "Data saved to handsigns_data.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T23:20:08.691554Z",
     "start_time": "2024-10-15T23:20:08.087869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##        DATA AUGMENTATION (OPTIONAL)        ##\n",
    "\n",
    "#Augmentation parameters\n",
    "noise_level=0.005 #for the add_noise() function\n",
    "translation_vector=np.random.uniform(-0.05, 0.05, 3) #for the apply_translation() function\n",
    "scale_factor=np.random.uniform(0.6, 1.6) #for the apply_scaling() function\n",
    "angle_degrees=np.random.uniform(-25, 25) #for the apply_rotation()\n",
    "\n",
    "\n",
    "def apply_rotation(landmarks, angle_degrees):\n",
    "    \"\"\"Rotate the landmarks in 3D space by a given angle.\"\"\"\n",
    "    angle_radians = np.radians(angle_degrees)\n",
    "    cos_angle = np.cos(angle_radians)\n",
    "    sin_angle = np.sin(angle_radians)\n",
    "\n",
    "    # Rotation around the Z-axis (you can adjust for other axes if necessary)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_angle, -sin_angle, 0],\n",
    "        [sin_angle, cos_angle, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    return np.dot(landmarks, rotation_matrix)\n",
    "\n",
    "def apply_scaling(landmarks, scale_factor):\n",
    "    \"\"\"Scale the landmarks by a given factor.\"\"\"\n",
    "    return landmarks * scale_factor\n",
    "\n",
    "def apply_translation(landmarks, translation_vector):\n",
    "    \"\"\"Translate the landmarks by a given vector (x, y, z).\"\"\"\n",
    "    return landmarks + translation_vector\n",
    "\n",
    "def add_noise(landmarks, noise_level=0.001):\n",
    "    \"\"\"Add random noise to the landmarks.\"\"\"\n",
    "    noise = np.random.normal(0, noise_level, landmarks.shape)\n",
    "    return landmarks + noise\n",
    "\n",
    "def augment_data(data_array, num_augmented_versions=5):\n",
    "    \"\"\"\n",
    "    Augment the data array by applying transformations.\n",
    "    Creates `num_augmented_versions` augmented copies of each handsign video.\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    for handsign_data in data_array:\n",
    "        augmented_handsign_data = []\n",
    "        for video_data in handsign_data:\n",
    "            augmented_videos = [video_data]  # Start with the original video data\n",
    "\n",
    "            for _ in range(num_augmented_versions):\n",
    "                augmented_video = []\n",
    "                for frame in video_data:\n",
    "                    # Apply a combination of augmentations\n",
    "                    rotated_frame = apply_rotation(frame, angle_degrees)\n",
    "                    scaled_frame = apply_scaling(rotated_frame, scale_factor)\n",
    "                    translated_frame = apply_translation(scaled_frame, translation_vector)\n",
    "                    noisy_frame = add_noise(translated_frame, noise_level)\n",
    "\n",
    "                    augmented_video.append(noisy_frame)\n",
    "                \n",
    "                augmented_videos.append(np.array(augmented_video))\n",
    "\n",
    "            # Flatten the augmented videos for each original video\n",
    "            augmented_handsign_data.extend(augmented_videos)\n",
    "\n",
    "        augmented_data.append(np.array(augmented_handsign_data))\n",
    "    \n",
    "    return np.array(augmented_data)\n",
    "\n",
    "# Load original handsigns data\n",
    "handsigns_data = np.load('handsigns_data.npy')\n",
    "\n",
    "# Apply augmentation\n",
    "if data_augmentation:\n",
    "    \n",
    "    augmented_data = augment_data(handsigns_data, num_augmented_versions)\n",
    "    \n",
    "    # Save the augmented data to a new .npy file\n",
    "    np.save('handsigns_data_augmented.npy', augmented_data)\n",
    "    \n",
    "    # Update the videos per handsign value to match the videos generated by the augmentation\n",
    "    data_array = np.load('handsigns_data_augmented.npy')\n",
    "    videos_per_handsign = data_array.shape[1]\n",
    "    \n",
    "    print(\"Augmented data saved to handsigns_data_augmented.npy, videos_per_handsign augmented by \"+str(num_augmented_versions)+\" per existing video for a total of \"+str(videos_per_handsign)+\" videos per handsign\")\n",
    "else:\n",
    "    print(\"no data augmentation was performed\")"
   ],
   "id": "d0c17cfc27c8ccac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data saved to handsigns_data_augmented.npy, videos_per_handsign augmented by 2 per existing video for a total of 444 videos per handsign\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T23:20:20.561830Z",
     "start_time": "2024-10-15T23:20:20.499213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          MODEL DEFINITION            ##\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Reshape, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Reshape input to (frames_per_video, num_landmarks * num_coordinates)\n",
    "new_input_shape = (frames_per_video, num_landmarks * num_coordinates)\n",
    "\n",
    "model = Sequential([\n",
    "    # Reshape layer\n",
    "    Reshape((frames_per_video, num_landmarks * num_coordinates), input_shape=(frames_per_video, num_landmarks, num_coordinates)),\n",
    "    \n",
    "    # LSTM layers with Dropout and Batch Normalization to reduce overfitting\n",
    "    LSTM(64, return_sequences=True, kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    LSTM(128, return_sequences=False, kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    # Fully connected layer\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    # Output layer for multi-class classification\n",
    "    Dense(num_handsigns, activation='softmax')  # Softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Specify a learning rate\n",
    "learning_rate = 0.0005\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model.summary() # Uncomment if you want to see the model summary\n"
   ],
   "id": "c1f9d72562ce0728",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-15T23:20:25.207249Z",
     "start_time": "2024-10-15T23:20:25.096202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##        DATA PREPROCESSING FOR TRAINING            ##\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# Load the data from the .npy file, making a copy to use for training as to not modify the original extracted data\n",
    "if data_augmentation:\n",
    "    shutil.copy('handsigns_data_augmented.npy', 'handsigns_data_training_copy.npy')\n",
    "    data_array = np.load('handsigns_data_training_copy.npy')\n",
    "    \n",
    "    # Update videos_per_handsign based on augmentation\n",
    "    #videos_per_handsign = data_array.shape[1]  # Dynamically update based on the new augmented shape\n",
    "    print(\"using handsigns_data_augmented.npy. After augmentation videos per handsign updated to: \" + str(data_array.shape[1]))\n",
    "else:\n",
    "    shutil.copy('handsigns_data.npy', 'handsigns_data_training_copy.npy')\n",
    "    data_array = np.load('handsigns_data_training_copy.npy')\n",
    "\n",
    "print('Array used shape: ',data_array.shape)\n",
    "# X remains unchanged\n",
    "X = data_array \n",
    "\n",
    "# Create labels for each handsign (0 to num_handsigns-1)\n",
    "# This creates a label for each hand sign, repeated for each video\n",
    "y = np.repeat(np.arange(num_handsigns), videos_per_handsign)\n",
    "y = y.reshape(num_handsigns, videos_per_handsign)\n",
    "\n",
    "# Initialize lists to hold training and validation data\n",
    "X_train_list = []\n",
    "X_val_list = []\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "\n",
    "# Split videos and labels for each handsign\n",
    "for handsign_index in range(num_handsigns):\n",
    "    # Split the videos within each handsign\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        np.arange(videos_per_handsign), \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Select training and validation data for this handsign\n",
    "    X_train_list.append(data_array[handsign_index, train_indices])\n",
    "    X_val_list.append(data_array[handsign_index, val_indices])\n",
    "    \n",
    "    # Select corresponding labels\n",
    "    y_train_list.append(y[handsign_index, train_indices])\n",
    "    y_val_list.append(y[handsign_index, val_indices])\n",
    "\n",
    "# Concatenate lists to form the final training and validation sets\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "X_val = np.concatenate(X_val_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "y_val = np.concatenate(y_val_list, axis=0)\n",
    "\n",
    "# Reshape X_train and X_val to fit the model's expected input shape\n",
    "X_train = X_train.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "X_val = X_val.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "\n",
    "# Flatten y_train and y_val\n",
    "y_train = y_train.flatten()\n",
    "y_val = y_val.flatten()"
   ],
   "id": "664f881d08e116f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using handsigns_data_augmented.npy. After augmentation videos per handsign updated to: 444\n",
      "Array used shape:  (10, 444, 10, 51, 3)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T23:23:38.360991Z",
     "start_time": "2024-10-15T23:20:31.539834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          MODEL TRAINING          ##\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Callback helpers for model training #\n",
    "# Early stopping to stop training when validation loss stops improving\n",
    "# Model checkpointing to save the best model during training\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)  \n",
    "checkpoint = ModelCheckpoint('best_handsigns_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)  \n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[early_stopping, checkpoint, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "model.save('handsigns_model.h5')\n",
    "\n",
    "# Optionally, save the training history\n",
    "import pickle\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "    \n",
    "\n",
    "    \n",
    "##          TRAINING HISTORY ANALYSIS           ##\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# If you want to save the plot instead of displaying it:\n",
    "# plt.savefig('training_history.png')"
   ],
   "id": "febb1178fa7e41a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.1376 - loss: 21.4254\n",
      "Epoch 1: val_loss improved from inf to 15.36197, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 12ms/step - accuracy: 0.1383 - loss: 21.3914 - val_accuracy: 0.1562 - val_loss: 15.3620 - learning_rate: 5.0000e-04\n",
      "Epoch 2/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.2666 - loss: 14.7854\n",
      "Epoch 2: val_loss improved from 15.36197 to 11.22857, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.2667 - loss: 14.7569 - val_accuracy: 0.3101 - val_loss: 11.2286 - learning_rate: 5.0000e-04\n",
      "Epoch 3/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.3024 - loss: 11.0122\n",
      "Epoch 3: val_loss improved from 11.22857 to 8.44295, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.3030 - loss: 10.9922 - val_accuracy: 0.4607 - val_loss: 8.4429 - learning_rate: 5.0000e-04\n",
      "Epoch 4/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.3743 - loss: 8.4065\n",
      "Epoch 4: val_loss improved from 8.44295 to 6.50504, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.3750 - loss: 8.3934 - val_accuracy: 0.6225 - val_loss: 6.5050 - learning_rate: 5.0000e-04\n",
      "Epoch 5/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.4393 - loss: 6.6214\n",
      "Epoch 5: val_loss improved from 6.50504 to 5.13806, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.4394 - loss: 6.6151 - val_accuracy: 0.6584 - val_loss: 5.1381 - learning_rate: 5.0000e-04\n",
      "Epoch 6/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.4755 - loss: 5.3840\n",
      "Epoch 6: val_loss improved from 5.13806 to 4.12601, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.4753 - loss: 5.3753 - val_accuracy: 0.7213 - val_loss: 4.1260 - learning_rate: 5.0000e-04\n",
      "Epoch 7/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.5104 - loss: 4.4091\n",
      "Epoch 7: val_loss improved from 4.12601 to 3.35757, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.5105 - loss: 4.4072 - val_accuracy: 0.7213 - val_loss: 3.3576 - learning_rate: 5.0000e-04\n",
      "Epoch 8/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.5773 - loss: 3.6159\n",
      "Epoch 8: val_loss improved from 3.35757 to 2.84983, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.5775 - loss: 3.6084 - val_accuracy: 0.7404 - val_loss: 2.8498 - learning_rate: 5.0000e-04\n",
      "Epoch 9/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.6030 - loss: 3.0497\n",
      "Epoch 9: val_loss improved from 2.84983 to 2.33144, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.6033 - loss: 3.0467 - val_accuracy: 0.7697 - val_loss: 2.3314 - learning_rate: 5.0000e-04\n",
      "Epoch 10/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.6484 - loss: 2.6279\n",
      "Epoch 10: val_loss improved from 2.33144 to 2.09604, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.6481 - loss: 2.6269 - val_accuracy: 0.7461 - val_loss: 2.0960 - learning_rate: 5.0000e-04\n",
      "Epoch 11/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.6571 - loss: 2.2774\n",
      "Epoch 11: val_loss improved from 2.09604 to 1.86488, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 12ms/step - accuracy: 0.6572 - loss: 2.2749 - val_accuracy: 0.7461 - val_loss: 1.8649 - learning_rate: 5.0000e-04\n",
      "Epoch 12/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.6722 - loss: 2.0752\n",
      "Epoch 12: val_loss improved from 1.86488 to 1.61691, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.6724 - loss: 2.0730 - val_accuracy: 0.7506 - val_loss: 1.6169 - learning_rate: 5.0000e-04\n",
      "Epoch 13/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.6985 - loss: 1.8462\n",
      "Epoch 13: val_loss improved from 1.61691 to 1.57165, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.6986 - loss: 1.8436 - val_accuracy: 0.7337 - val_loss: 1.5716 - learning_rate: 5.0000e-04\n",
      "Epoch 14/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7018 - loss: 1.6765\n",
      "Epoch 14: val_loss improved from 1.57165 to 1.31304, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 13ms/step - accuracy: 0.7022 - loss: 1.6751 - val_accuracy: 0.7910 - val_loss: 1.3130 - learning_rate: 5.0000e-04\n",
      "Epoch 15/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7219 - loss: 1.5401\n",
      "Epoch 15: val_loss improved from 1.31304 to 1.26104, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.7216 - loss: 1.5399 - val_accuracy: 0.7888 - val_loss: 1.2610 - learning_rate: 5.0000e-04\n",
      "Epoch 16/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.7354 - loss: 1.4583\n",
      "Epoch 16: val_loss did not improve from 1.26104\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.7351 - loss: 1.4579 - val_accuracy: 0.7202 - val_loss: 1.3262 - learning_rate: 5.0000e-04\n",
      "Epoch 17/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.7190 - loss: 1.3834\n",
      "Epoch 17: val_loss improved from 1.26104 to 1.21986, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.7196 - loss: 1.3825 - val_accuracy: 0.7607 - val_loss: 1.2199 - learning_rate: 5.0000e-04\n",
      "Epoch 18/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.7296 - loss: 1.3168\n",
      "Epoch 18: val_loss improved from 1.21986 to 1.02742, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.7299 - loss: 1.3162 - val_accuracy: 0.8157 - val_loss: 1.0274 - learning_rate: 5.0000e-04\n",
      "Epoch 19/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7693 - loss: 1.1839\n",
      "Epoch 19: val_loss improved from 1.02742 to 0.93224, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.7687 - loss: 1.1860 - val_accuracy: 0.8494 - val_loss: 0.9322 - learning_rate: 5.0000e-04\n",
      "Epoch 20/500\n",
      "\u001B[1m105/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7558 - loss: 1.1949\n",
      "Epoch 20: val_loss did not improve from 0.93224\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.7556 - loss: 1.1943 - val_accuracy: 0.8090 - val_loss: 0.9405 - learning_rate: 5.0000e-04\n",
      "Epoch 21/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.7492 - loss: 1.1715\n",
      "Epoch 21: val_loss did not improve from 0.93224\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.7491 - loss: 1.1719 - val_accuracy: 0.8169 - val_loss: 0.9498 - learning_rate: 5.0000e-04\n",
      "Epoch 22/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7483 - loss: 1.1632\n",
      "Epoch 22: val_loss did not improve from 0.93224\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.7484 - loss: 1.1633 - val_accuracy: 0.7978 - val_loss: 0.9588 - learning_rate: 5.0000e-04\n",
      "Epoch 23/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7656 - loss: 1.1268\n",
      "Epoch 23: val_loss did not improve from 0.93224\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.7658 - loss: 1.1260 - val_accuracy: 0.7640 - val_loss: 0.9978 - learning_rate: 5.0000e-04\n",
      "Epoch 24/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7603 - loss: 1.1500\n",
      "Epoch 24: val_loss did not improve from 0.93224\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.7606 - loss: 1.1487 - val_accuracy: 0.7685 - val_loss: 1.0679 - learning_rate: 5.0000e-04\n",
      "Epoch 25/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.7855 - loss: 1.0514\n",
      "Epoch 25: val_loss improved from 0.93224 to 0.72360, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.7858 - loss: 1.0498 - val_accuracy: 0.8697 - val_loss: 0.7236 - learning_rate: 2.5000e-04\n",
      "Epoch 26/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8011 - loss: 0.9727\n",
      "Epoch 26: val_loss did not improve from 0.72360\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8016 - loss: 0.9714 - val_accuracy: 0.8528 - val_loss: 0.7639 - learning_rate: 2.5000e-04\n",
      "Epoch 27/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8116 - loss: 0.9582\n",
      "Epoch 27: val_loss improved from 0.72360 to 0.68889, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8118 - loss: 0.9572 - val_accuracy: 0.8719 - val_loss: 0.6889 - learning_rate: 2.5000e-04\n",
      "Epoch 28/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8159 - loss: 0.9139\n",
      "Epoch 28: val_loss improved from 0.68889 to 0.64834, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8159 - loss: 0.9137 - val_accuracy: 0.8753 - val_loss: 0.6483 - learning_rate: 2.5000e-04\n",
      "Epoch 29/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8298 - loss: 0.8564\n",
      "Epoch 29: val_loss did not improve from 0.64834\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8296 - loss: 0.8575 - val_accuracy: 0.8551 - val_loss: 0.7020 - learning_rate: 2.5000e-04\n",
      "Epoch 30/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8154 - loss: 0.8683\n",
      "Epoch 30: val_loss did not improve from 0.64834\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8154 - loss: 0.8685 - val_accuracy: 0.8281 - val_loss: 0.7562 - learning_rate: 2.5000e-04\n",
      "Epoch 31/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8107 - loss: 0.8615\n",
      "Epoch 31: val_loss did not improve from 0.64834\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8108 - loss: 0.8615 - val_accuracy: 0.8528 - val_loss: 0.6617 - learning_rate: 2.5000e-04\n",
      "Epoch 32/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8059 - loss: 0.8841\n",
      "Epoch 32: val_loss did not improve from 0.64834\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8062 - loss: 0.8839 - val_accuracy: 0.8551 - val_loss: 0.7049 - learning_rate: 2.5000e-04\n",
      "Epoch 33/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8251 - loss: 0.8157\n",
      "Epoch 33: val_loss did not improve from 0.64834\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8251 - loss: 0.8163 - val_accuracy: 0.8708 - val_loss: 0.6486 - learning_rate: 2.5000e-04\n",
      "Epoch 34/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8478 - loss: 0.7645\n",
      "Epoch 34: val_loss improved from 0.64834 to 0.57933, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8477 - loss: 0.7651 - val_accuracy: 0.8921 - val_loss: 0.5793 - learning_rate: 1.2500e-04\n",
      "Epoch 35/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8469 - loss: 0.7614\n",
      "Epoch 35: val_loss did not improve from 0.57933\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8470 - loss: 0.7616 - val_accuracy: 0.8888 - val_loss: 0.5872 - learning_rate: 1.2500e-04\n",
      "Epoch 36/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8473 - loss: 0.7474\n",
      "Epoch 36: val_loss improved from 0.57933 to 0.57048, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8473 - loss: 0.7474 - val_accuracy: 0.8933 - val_loss: 0.5705 - learning_rate: 1.2500e-04\n",
      "Epoch 37/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8533 - loss: 0.7382\n",
      "Epoch 37: val_loss improved from 0.57048 to 0.54844, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8531 - loss: 0.7386 - val_accuracy: 0.8910 - val_loss: 0.5484 - learning_rate: 1.2500e-04\n",
      "Epoch 38/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8634 - loss: 0.7372\n",
      "Epoch 38: val_loss did not improve from 0.54844\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8634 - loss: 0.7372 - val_accuracy: 0.8933 - val_loss: 0.5683 - learning_rate: 1.2500e-04\n",
      "Epoch 39/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8485 - loss: 0.7349\n",
      "Epoch 39: val_loss improved from 0.54844 to 0.53068, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8485 - loss: 0.7348 - val_accuracy: 0.8933 - val_loss: 0.5307 - learning_rate: 1.2500e-04\n",
      "Epoch 40/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8587 - loss: 0.7339\n",
      "Epoch 40: val_loss improved from 0.53068 to 0.53055, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8586 - loss: 0.7335 - val_accuracy: 0.8978 - val_loss: 0.5305 - learning_rate: 1.2500e-04\n",
      "Epoch 41/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8592 - loss: 0.7092\n",
      "Epoch 41: val_loss did not improve from 0.53055\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8590 - loss: 0.7098 - val_accuracy: 0.9011 - val_loss: 0.5384 - learning_rate: 1.2500e-04\n",
      "Epoch 42/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8625 - loss: 0.6972\n",
      "Epoch 42: val_loss did not improve from 0.53055\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8624 - loss: 0.6977 - val_accuracy: 0.8685 - val_loss: 0.5834 - learning_rate: 1.2500e-04\n",
      "Epoch 43/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8440 - loss: 0.7189\n",
      "Epoch 43: val_loss did not improve from 0.53055\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8442 - loss: 0.7186 - val_accuracy: 0.8888 - val_loss: 0.5452 - learning_rate: 1.2500e-04\n",
      "Epoch 44/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8557 - loss: 0.6873\n",
      "Epoch 44: val_loss improved from 0.53055 to 0.51590, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8558 - loss: 0.6872 - val_accuracy: 0.8989 - val_loss: 0.5159 - learning_rate: 1.2500e-04\n",
      "Epoch 45/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8601 - loss: 0.7094\n",
      "Epoch 45: val_loss improved from 0.51590 to 0.51402, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8599 - loss: 0.7095 - val_accuracy: 0.8910 - val_loss: 0.5140 - learning_rate: 1.2500e-04\n",
      "Epoch 46/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8562 - loss: 0.6720\n",
      "Epoch 46: val_loss improved from 0.51402 to 0.50486, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8562 - loss: 0.6723 - val_accuracy: 0.9034 - val_loss: 0.5049 - learning_rate: 1.2500e-04\n",
      "Epoch 47/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8614 - loss: 0.6626\n",
      "Epoch 47: val_loss did not improve from 0.50486\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8612 - loss: 0.6633 - val_accuracy: 0.8854 - val_loss: 0.5300 - learning_rate: 1.2500e-04\n",
      "Epoch 48/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8665 - loss: 0.6544\n",
      "Epoch 48: val_loss did not improve from 0.50486\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8665 - loss: 0.6546 - val_accuracy: 0.8798 - val_loss: 0.5250 - learning_rate: 1.2500e-04\n",
      "Epoch 49/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8566 - loss: 0.6818\n",
      "Epoch 49: val_loss improved from 0.50486 to 0.49588, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.8570 - loss: 0.6809 - val_accuracy: 0.8966 - val_loss: 0.4959 - learning_rate: 1.2500e-04\n",
      "Epoch 50/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8700 - loss: 0.6673\n",
      "Epoch 50: val_loss did not improve from 0.49588\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8698 - loss: 0.6675 - val_accuracy: 0.8854 - val_loss: 0.5119 - learning_rate: 1.2500e-04\n",
      "Epoch 51/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8662 - loss: 0.6491\n",
      "Epoch 51: val_loss did not improve from 0.49588\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8661 - loss: 0.6496 - val_accuracy: 0.8899 - val_loss: 0.5373 - learning_rate: 1.2500e-04\n",
      "Epoch 52/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8721 - loss: 0.6530\n",
      "Epoch 52: val_loss did not improve from 0.49588\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8722 - loss: 0.6530 - val_accuracy: 0.8820 - val_loss: 0.5286 - learning_rate: 1.2500e-04\n",
      "Epoch 53/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8756 - loss: 0.6454\n",
      "Epoch 53: val_loss did not improve from 0.49588\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8752 - loss: 0.6464 - val_accuracy: 0.8888 - val_loss: 0.5120 - learning_rate: 1.2500e-04\n",
      "Epoch 54/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8704 - loss: 0.6220\n",
      "Epoch 54: val_loss improved from 0.49588 to 0.46577, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8704 - loss: 0.6222 - val_accuracy: 0.9011 - val_loss: 0.4658 - learning_rate: 1.2500e-04\n",
      "Epoch 55/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8595 - loss: 0.6368\n",
      "Epoch 55: val_loss improved from 0.46577 to 0.45530, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8598 - loss: 0.6367 - val_accuracy: 0.9112 - val_loss: 0.4553 - learning_rate: 1.2500e-04\n",
      "Epoch 56/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8802 - loss: 0.6106\n",
      "Epoch 56: val_loss did not improve from 0.45530\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8798 - loss: 0.6115 - val_accuracy: 0.8933 - val_loss: 0.5145 - learning_rate: 1.2500e-04\n",
      "Epoch 57/500\n",
      "\u001B[1m105/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8644 - loss: 0.6447\n",
      "Epoch 57: val_loss did not improve from 0.45530\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8644 - loss: 0.6452 - val_accuracy: 0.8978 - val_loss: 0.4964 - learning_rate: 1.2500e-04\n",
      "Epoch 58/500\n",
      "\u001B[1m105/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8636 - loss: 0.6387\n",
      "Epoch 58: val_loss did not improve from 0.45530\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8639 - loss: 0.6386 - val_accuracy: 0.8944 - val_loss: 0.5100 - learning_rate: 1.2500e-04\n",
      "Epoch 59/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8651 - loss: 0.6302\n",
      "Epoch 59: val_loss did not improve from 0.45530\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8652 - loss: 0.6298 - val_accuracy: 0.8843 - val_loss: 0.5070 - learning_rate: 1.2500e-04\n",
      "Epoch 60/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8738 - loss: 0.5932\n",
      "Epoch 60: val_loss did not improve from 0.45530\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8736 - loss: 0.5944 - val_accuracy: 0.9034 - val_loss: 0.4580 - learning_rate: 1.2500e-04\n",
      "Epoch 61/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8763 - loss: 0.6133\n",
      "Epoch 61: val_loss improved from 0.45530 to 0.45233, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8763 - loss: 0.6133 - val_accuracy: 0.9090 - val_loss: 0.4523 - learning_rate: 6.2500e-05\n",
      "Epoch 62/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8901 - loss: 0.5760\n",
      "Epoch 62: val_loss did not improve from 0.45233\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8900 - loss: 0.5761 - val_accuracy: 0.9045 - val_loss: 0.4558 - learning_rate: 6.2500e-05\n",
      "Epoch 63/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8884 - loss: 0.5912\n",
      "Epoch 63: val_loss improved from 0.45233 to 0.45121, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8884 - loss: 0.5911 - val_accuracy: 0.9124 - val_loss: 0.4512 - learning_rate: 6.2500e-05\n",
      "Epoch 64/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8758 - loss: 0.5819\n",
      "Epoch 64: val_loss improved from 0.45121 to 0.43462, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8759 - loss: 0.5820 - val_accuracy: 0.9090 - val_loss: 0.4346 - learning_rate: 6.2500e-05\n",
      "Epoch 65/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8910 - loss: 0.5540\n",
      "Epoch 65: val_loss did not improve from 0.43462\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8909 - loss: 0.5543 - val_accuracy: 0.9067 - val_loss: 0.4472 - learning_rate: 6.2500e-05\n",
      "Epoch 66/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8830 - loss: 0.5553\n",
      "Epoch 66: val_loss improved from 0.43462 to 0.43251, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8828 - loss: 0.5564 - val_accuracy: 0.9135 - val_loss: 0.4325 - learning_rate: 6.2500e-05\n",
      "Epoch 67/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8714 - loss: 0.5904\n",
      "Epoch 67: val_loss improved from 0.43251 to 0.41369, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8720 - loss: 0.5898 - val_accuracy: 0.9157 - val_loss: 0.4137 - learning_rate: 6.2500e-05\n",
      "Epoch 68/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8717 - loss: 0.5730\n",
      "Epoch 68: val_loss did not improve from 0.41369\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8717 - loss: 0.5731 - val_accuracy: 0.9079 - val_loss: 0.4487 - learning_rate: 6.2500e-05\n",
      "Epoch 69/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8825 - loss: 0.5695\n",
      "Epoch 69: val_loss did not improve from 0.41369\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8826 - loss: 0.5694 - val_accuracy: 0.9124 - val_loss: 0.4223 - learning_rate: 6.2500e-05\n",
      "Epoch 70/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8835 - loss: 0.5691\n",
      "Epoch 70: val_loss did not improve from 0.41369\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8836 - loss: 0.5691 - val_accuracy: 0.9112 - val_loss: 0.4196 - learning_rate: 6.2500e-05\n",
      "Epoch 71/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8837 - loss: 0.5838\n",
      "Epoch 71: val_loss did not improve from 0.41369\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8837 - loss: 0.5836 - val_accuracy: 0.9135 - val_loss: 0.4173 - learning_rate: 6.2500e-05\n",
      "Epoch 72/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9007 - loss: 0.5377\n",
      "Epoch 72: val_loss did not improve from 0.41369\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9004 - loss: 0.5383 - val_accuracy: 0.9112 - val_loss: 0.4354 - learning_rate: 6.2500e-05\n",
      "Epoch 73/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8903 - loss: 0.5465\n",
      "Epoch 73: val_loss improved from 0.41369 to 0.40736, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8903 - loss: 0.5468 - val_accuracy: 0.9180 - val_loss: 0.4074 - learning_rate: 3.1250e-05\n",
      "Epoch 74/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8925 - loss: 0.5549\n",
      "Epoch 74: val_loss did not improve from 0.40736\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8925 - loss: 0.5548 - val_accuracy: 0.9157 - val_loss: 0.4128 - learning_rate: 3.1250e-05\n",
      "Epoch 75/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8898 - loss: 0.5611\n",
      "Epoch 75: val_loss did not improve from 0.40736\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8899 - loss: 0.5609 - val_accuracy: 0.9146 - val_loss: 0.4098 - learning_rate: 3.1250e-05\n",
      "Epoch 76/500\n",
      "\u001B[1m105/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8880 - loss: 0.5417\n",
      "Epoch 76: val_loss improved from 0.40736 to 0.40164, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8883 - loss: 0.5418 - val_accuracy: 0.9180 - val_loss: 0.4016 - learning_rate: 3.1250e-05\n",
      "Epoch 77/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8939 - loss: 0.5333\n",
      "Epoch 77: val_loss did not improve from 0.40164\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8937 - loss: 0.5339 - val_accuracy: 0.9180 - val_loss: 0.4104 - learning_rate: 3.1250e-05\n",
      "Epoch 78/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8833 - loss: 0.5656\n",
      "Epoch 78: val_loss improved from 0.40164 to 0.39464, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8836 - loss: 0.5651 - val_accuracy: 0.9270 - val_loss: 0.3946 - learning_rate: 3.1250e-05\n",
      "Epoch 79/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8958 - loss: 0.5425\n",
      "Epoch 79: val_loss did not improve from 0.39464\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8958 - loss: 0.5427 - val_accuracy: 0.9225 - val_loss: 0.4079 - learning_rate: 3.1250e-05\n",
      "Epoch 80/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8989 - loss: 0.5207\n",
      "Epoch 80: val_loss did not improve from 0.39464\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8986 - loss: 0.5212 - val_accuracy: 0.9169 - val_loss: 0.4056 - learning_rate: 3.1250e-05\n",
      "Epoch 81/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8757 - loss: 0.5617\n",
      "Epoch 81: val_loss did not improve from 0.39464\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8759 - loss: 0.5611 - val_accuracy: 0.9191 - val_loss: 0.3957 - learning_rate: 3.1250e-05\n",
      "Epoch 82/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8940 - loss: 0.5203\n",
      "Epoch 82: val_loss did not improve from 0.39464\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8941 - loss: 0.5205 - val_accuracy: 0.9247 - val_loss: 0.4007 - learning_rate: 3.1250e-05\n",
      "Epoch 83/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9002 - loss: 0.5036\n",
      "Epoch 83: val_loss did not improve from 0.39464\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9001 - loss: 0.5037 - val_accuracy: 0.9146 - val_loss: 0.4065 - learning_rate: 3.1250e-05\n",
      "Epoch 84/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9069 - loss: 0.5028\n",
      "Epoch 84: val_loss improved from 0.39464 to 0.38883, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9065 - loss: 0.5035 - val_accuracy: 0.9292 - val_loss: 0.3888 - learning_rate: 1.5625e-05\n",
      "Epoch 85/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8886 - loss: 0.5357\n",
      "Epoch 85: val_loss improved from 0.38883 to 0.38547, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8886 - loss: 0.5357 - val_accuracy: 0.9270 - val_loss: 0.3855 - learning_rate: 1.5625e-05\n",
      "Epoch 86/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9089 - loss: 0.4976\n",
      "Epoch 86: val_loss did not improve from 0.38547\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9088 - loss: 0.4977 - val_accuracy: 0.9213 - val_loss: 0.3864 - learning_rate: 1.5625e-05\n",
      "Epoch 87/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9015 - loss: 0.4917\n",
      "Epoch 87: val_loss did not improve from 0.38547\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9014 - loss: 0.4926 - val_accuracy: 0.9225 - val_loss: 0.3917 - learning_rate: 1.5625e-05\n",
      "Epoch 88/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8959 - loss: 0.5098\n",
      "Epoch 88: val_loss did not improve from 0.38547\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8962 - loss: 0.5095 - val_accuracy: 0.9236 - val_loss: 0.3863 - learning_rate: 1.5625e-05\n",
      "Epoch 89/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8915 - loss: 0.5092\n",
      "Epoch 89: val_loss did not improve from 0.38547\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8914 - loss: 0.5097 - val_accuracy: 0.9258 - val_loss: 0.3884 - learning_rate: 1.5625e-05\n",
      "Epoch 90/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9056 - loss: 0.5058\n",
      "Epoch 90: val_loss improved from 0.38547 to 0.37886, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9056 - loss: 0.5058 - val_accuracy: 0.9225 - val_loss: 0.3789 - learning_rate: 1.5625e-05\n",
      "Epoch 91/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8900 - loss: 0.5359\n",
      "Epoch 91: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8900 - loss: 0.5358 - val_accuracy: 0.9247 - val_loss: 0.3843 - learning_rate: 1.5625e-05\n",
      "Epoch 92/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8939 - loss: 0.5172\n",
      "Epoch 92: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8941 - loss: 0.5167 - val_accuracy: 0.9169 - val_loss: 0.3809 - learning_rate: 1.5625e-05\n",
      "Epoch 93/500\n",
      "\u001B[1m105/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9092 - loss: 0.4901\n",
      "Epoch 93: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9087 - loss: 0.4909 - val_accuracy: 0.9270 - val_loss: 0.3832 - learning_rate: 1.5625e-05\n",
      "Epoch 94/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8966 - loss: 0.5216\n",
      "Epoch 94: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8966 - loss: 0.5216 - val_accuracy: 0.9225 - val_loss: 0.3844 - learning_rate: 1.5625e-05\n",
      "Epoch 95/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9029 - loss: 0.5242\n",
      "Epoch 95: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9029 - loss: 0.5240 - val_accuracy: 0.9258 - val_loss: 0.3837 - learning_rate: 1.5625e-05\n",
      "Epoch 96/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8935 - loss: 0.5286\n",
      "Epoch 96: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8937 - loss: 0.5281 - val_accuracy: 0.9225 - val_loss: 0.3851 - learning_rate: 7.8125e-06\n",
      "Epoch 97/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8929 - loss: 0.4968\n",
      "Epoch 97: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8930 - loss: 0.4968 - val_accuracy: 0.9258 - val_loss: 0.3831 - learning_rate: 7.8125e-06\n",
      "Epoch 98/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9035 - loss: 0.5006\n",
      "Epoch 98: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9033 - loss: 0.5010 - val_accuracy: 0.9247 - val_loss: 0.3792 - learning_rate: 7.8125e-06\n",
      "Epoch 99/500\n",
      "\u001B[1m105/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9030 - loss: 0.5090\n",
      "Epoch 99: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9030 - loss: 0.5089 - val_accuracy: 0.9236 - val_loss: 0.3824 - learning_rate: 7.8125e-06\n",
      "Epoch 100/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8999 - loss: 0.5116\n",
      "Epoch 100: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8998 - loss: 0.5116 - val_accuracy: 0.9258 - val_loss: 0.3795 - learning_rate: 7.8125e-06\n",
      "Epoch 101/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9059 - loss: 0.4770\n",
      "Epoch 101: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9058 - loss: 0.4773 - val_accuracy: 0.9247 - val_loss: 0.3802 - learning_rate: 3.9063e-06\n",
      "Epoch 102/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9052 - loss: 0.5031\n",
      "Epoch 102: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9052 - loss: 0.5036 - val_accuracy: 0.9236 - val_loss: 0.3802 - learning_rate: 3.9063e-06\n",
      "Epoch 103/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9044 - loss: 0.4989\n",
      "Epoch 103: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9042 - loss: 0.4991 - val_accuracy: 0.9225 - val_loss: 0.3803 - learning_rate: 3.9063e-06\n",
      "Epoch 104/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9132 - loss: 0.4616\n",
      "Epoch 104: val_loss did not improve from 0.37886\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9130 - loss: 0.4626 - val_accuracy: 0.9247 - val_loss: 0.3792 - learning_rate: 3.9063e-06\n",
      "Epoch 105/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8945 - loss: 0.4925\n",
      "Epoch 105: val_loss improved from 0.37886 to 0.37862, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8944 - loss: 0.4928 - val_accuracy: 0.9247 - val_loss: 0.3786 - learning_rate: 3.9063e-06\n",
      "Epoch 106/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9055 - loss: 0.4691\n",
      "Epoch 106: val_loss improved from 0.37862 to 0.37721, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9054 - loss: 0.4696 - val_accuracy: 0.9247 - val_loss: 0.3772 - learning_rate: 3.9063e-06\n",
      "Epoch 107/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9053 - loss: 0.4726\n",
      "Epoch 107: val_loss improved from 0.37721 to 0.37721, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9050 - loss: 0.4737 - val_accuracy: 0.9281 - val_loss: 0.3772 - learning_rate: 3.9063e-06\n",
      "Epoch 108/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8935 - loss: 0.5077\n",
      "Epoch 108: val_loss did not improve from 0.37721\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8936 - loss: 0.5073 - val_accuracy: 0.9247 - val_loss: 0.3774 - learning_rate: 3.9063e-06\n",
      "Epoch 109/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9034 - loss: 0.4869\n",
      "Epoch 109: val_loss did not improve from 0.37721\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9033 - loss: 0.4870 - val_accuracy: 0.9247 - val_loss: 0.3779 - learning_rate: 3.9063e-06\n",
      "Epoch 110/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8997 - loss: 0.5286\n",
      "Epoch 110: val_loss did not improve from 0.37721\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8997 - loss: 0.5284 - val_accuracy: 0.9270 - val_loss: 0.3788 - learning_rate: 3.9063e-06\n",
      "Epoch 111/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8997 - loss: 0.4982\n",
      "Epoch 111: val_loss improved from 0.37721 to 0.37636, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8996 - loss: 0.4987 - val_accuracy: 0.9258 - val_loss: 0.3764 - learning_rate: 3.9063e-06\n",
      "Epoch 112/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8952 - loss: 0.4888\n",
      "Epoch 112: val_loss did not improve from 0.37636\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8954 - loss: 0.4891 - val_accuracy: 0.9281 - val_loss: 0.3766 - learning_rate: 3.9063e-06\n",
      "Epoch 113/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8971 - loss: 0.5013\n",
      "Epoch 113: val_loss improved from 0.37636 to 0.37542, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8970 - loss: 0.5017 - val_accuracy: 0.9270 - val_loss: 0.3754 - learning_rate: 3.9063e-06\n",
      "Epoch 114/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9095 - loss: 0.4598\n",
      "Epoch 114: val_loss did not improve from 0.37542\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9091 - loss: 0.4613 - val_accuracy: 0.9247 - val_loss: 0.3768 - learning_rate: 3.9063e-06\n",
      "Epoch 115/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9047 - loss: 0.5043\n",
      "Epoch 115: val_loss did not improve from 0.37542\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9048 - loss: 0.5038 - val_accuracy: 0.9236 - val_loss: 0.3768 - learning_rate: 3.9063e-06\n",
      "Epoch 116/500\n",
      "\u001B[1m105/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9000 - loss: 0.5030\n",
      "Epoch 116: val_loss improved from 0.37542 to 0.37461, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9000 - loss: 0.5025 - val_accuracy: 0.9292 - val_loss: 0.3746 - learning_rate: 3.9063e-06\n",
      "Epoch 117/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9045 - loss: 0.5038\n",
      "Epoch 117: val_loss did not improve from 0.37461\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9045 - loss: 0.5038 - val_accuracy: 0.9236 - val_loss: 0.3755 - learning_rate: 3.9063e-06\n",
      "Epoch 118/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8954 - loss: 0.5121\n",
      "Epoch 118: val_loss did not improve from 0.37461\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8954 - loss: 0.5122 - val_accuracy: 0.9247 - val_loss: 0.3771 - learning_rate: 3.9063e-06\n",
      "Epoch 119/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9059 - loss: 0.4915\n",
      "Epoch 119: val_loss improved from 0.37461 to 0.37417, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9056 - loss: 0.4922 - val_accuracy: 0.9258 - val_loss: 0.3742 - learning_rate: 3.9063e-06\n",
      "Epoch 120/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8922 - loss: 0.5176\n",
      "Epoch 120: val_loss did not improve from 0.37417\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8927 - loss: 0.5171 - val_accuracy: 0.9270 - val_loss: 0.3749 - learning_rate: 3.9063e-06\n",
      "Epoch 121/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9077 - loss: 0.4641\n",
      "Epoch 121: val_loss did not improve from 0.37417\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9076 - loss: 0.4643 - val_accuracy: 0.9270 - val_loss: 0.3747 - learning_rate: 3.9063e-06\n",
      "Epoch 122/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9033 - loss: 0.4831\n",
      "Epoch 122: val_loss did not improve from 0.37417\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9033 - loss: 0.4832 - val_accuracy: 0.9258 - val_loss: 0.3759 - learning_rate: 3.9063e-06\n",
      "Epoch 123/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9080 - loss: 0.4853\n",
      "Epoch 123: val_loss did not improve from 0.37417\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9079 - loss: 0.4854 - val_accuracy: 0.9236 - val_loss: 0.3751 - learning_rate: 3.9063e-06\n",
      "Epoch 124/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9046 - loss: 0.4907\n",
      "Epoch 124: val_loss did not improve from 0.37417\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9045 - loss: 0.4910 - val_accuracy: 0.9247 - val_loss: 0.3746 - learning_rate: 3.9063e-06\n",
      "Epoch 125/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8932 - loss: 0.4897\n",
      "Epoch 125: val_loss did not improve from 0.37417\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8932 - loss: 0.4902 - val_accuracy: 0.9236 - val_loss: 0.3752 - learning_rate: 1.9531e-06\n",
      "Epoch 126/500\n",
      "\u001B[1m105/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9031 - loss: 0.4933\n",
      "Epoch 126: val_loss did not improve from 0.37417\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9030 - loss: 0.4931 - val_accuracy: 0.9236 - val_loss: 0.3768 - learning_rate: 1.9531e-06\n",
      "Epoch 127/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9049 - loss: 0.4821\n",
      "Epoch 127: val_loss did not improve from 0.37417\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9048 - loss: 0.4820 - val_accuracy: 0.9247 - val_loss: 0.3758 - learning_rate: 1.9531e-06\n",
      "Epoch 128/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9007 - loss: 0.4929\n",
      "Epoch 128: val_loss improved from 0.37417 to 0.37365, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9009 - loss: 0.4924 - val_accuracy: 0.9270 - val_loss: 0.3737 - learning_rate: 1.9531e-06\n",
      "Epoch 129/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9045 - loss: 0.4991\n",
      "Epoch 129: val_loss did not improve from 0.37365\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9044 - loss: 0.4992 - val_accuracy: 0.9258 - val_loss: 0.3747 - learning_rate: 1.9531e-06\n",
      "Epoch 130/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9076 - loss: 0.4751\n",
      "Epoch 130: val_loss did not improve from 0.37365\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9076 - loss: 0.4753 - val_accuracy: 0.9270 - val_loss: 0.3756 - learning_rate: 1.9531e-06\n",
      "Epoch 131/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9013 - loss: 0.4944\n",
      "Epoch 131: val_loss did not improve from 0.37365\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9014 - loss: 0.4945 - val_accuracy: 0.9281 - val_loss: 0.3747 - learning_rate: 1.9531e-06\n",
      "Epoch 132/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9024 - loss: 0.4879\n",
      "Epoch 132: val_loss did not improve from 0.37365\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9021 - loss: 0.4891 - val_accuracy: 0.9292 - val_loss: 0.3747 - learning_rate: 1.9531e-06\n",
      "Epoch 133/500\n",
      "\u001B[1m104/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9025 - loss: 0.4881\n",
      "Epoch 133: val_loss did not improve from 0.37365\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9025 - loss: 0.4885 - val_accuracy: 0.9258 - val_loss: 0.3747 - learning_rate: 1.9531e-06\n",
      "Epoch 134/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9044 - loss: 0.5002\n",
      "Epoch 134: val_loss did not improve from 0.37365\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9043 - loss: 0.5003 - val_accuracy: 0.9258 - val_loss: 0.3742 - learning_rate: 1.0000e-06\n",
      "Epoch 135/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9036 - loss: 0.5015\n",
      "Epoch 135: val_loss did not improve from 0.37365\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9035 - loss: 0.5016 - val_accuracy: 0.9281 - val_loss: 0.3747 - learning_rate: 1.0000e-06\n",
      "Epoch 136/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9004 - loss: 0.5016\n",
      "Epoch 136: val_loss did not improve from 0.37365\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9004 - loss: 0.5018 - val_accuracy: 0.9247 - val_loss: 0.3749 - learning_rate: 1.0000e-06\n",
      "Epoch 137/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8990 - loss: 0.4933\n",
      "Epoch 137: val_loss did not improve from 0.37365\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8993 - loss: 0.4929 - val_accuracy: 0.9270 - val_loss: 0.3743 - learning_rate: 1.0000e-06\n",
      "Epoch 138/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9087 - loss: 0.4577\n",
      "Epoch 138: val_loss improved from 0.37365 to 0.37353, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9083 - loss: 0.4591 - val_accuracy: 0.9270 - val_loss: 0.3735 - learning_rate: 1.0000e-06\n",
      "Epoch 139/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8958 - loss: 0.5037\n",
      "Epoch 139: val_loss did not improve from 0.37353\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8961 - loss: 0.5030 - val_accuracy: 0.9258 - val_loss: 0.3747 - learning_rate: 1.0000e-06\n",
      "Epoch 140/500\n",
      "\u001B[1m106/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8931 - loss: 0.5161\n",
      "Epoch 140: val_loss did not improve from 0.37353\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8935 - loss: 0.5150 - val_accuracy: 0.9258 - val_loss: 0.3749 - learning_rate: 1.0000e-06\n",
      "Epoch 141/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9085 - loss: 0.4759\n",
      "Epoch 141: val_loss did not improve from 0.37353\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9084 - loss: 0.4764 - val_accuracy: 0.9258 - val_loss: 0.3738 - learning_rate: 1.0000e-06\n",
      "Epoch 142/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8979 - loss: 0.5067\n",
      "Epoch 142: val_loss improved from 0.37353 to 0.37333, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.8978 - loss: 0.5066 - val_accuracy: 0.9281 - val_loss: 0.3733 - learning_rate: 1.0000e-06\n",
      "Epoch 143/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8997 - loss: 0.5004\n",
      "Epoch 143: val_loss improved from 0.37333 to 0.37263, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.9000 - loss: 0.5000 - val_accuracy: 0.9270 - val_loss: 0.3726 - learning_rate: 1.0000e-06\n",
      "Epoch 144/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9087 - loss: 0.4723\n",
      "Epoch 144: val_loss improved from 0.37263 to 0.37256, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9084 - loss: 0.4729 - val_accuracy: 0.9270 - val_loss: 0.3726 - learning_rate: 1.0000e-06\n",
      "Epoch 145/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8997 - loss: 0.5019\n",
      "Epoch 145: val_loss improved from 0.37256 to 0.37179, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8997 - loss: 0.5019 - val_accuracy: 0.9281 - val_loss: 0.3718 - learning_rate: 1.0000e-06\n",
      "Epoch 146/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8934 - loss: 0.5242\n",
      "Epoch 146: val_loss did not improve from 0.37179\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8936 - loss: 0.5235 - val_accuracy: 0.9281 - val_loss: 0.3718 - learning_rate: 1.0000e-06\n",
      "Epoch 147/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9015 - loss: 0.5041\n",
      "Epoch 147: val_loss improved from 0.37179 to 0.37121, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9015 - loss: 0.5039 - val_accuracy: 0.9315 - val_loss: 0.3712 - learning_rate: 1.0000e-06\n",
      "Epoch 148/500\n",
      "\u001B[1m107/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9160 - loss: 0.4513\n",
      "Epoch 148: val_loss improved from 0.37121 to 0.37096, saving model to best_handsigns_model.keras\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9158 - loss: 0.4524 - val_accuracy: 0.9315 - val_loss: 0.3710 - learning_rate: 1.0000e-06\n",
      "Epoch 149/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9029 - loss: 0.5089\n",
      "Epoch 149: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.9030 - loss: 0.5087 - val_accuracy: 0.9315 - val_loss: 0.3713 - learning_rate: 1.0000e-06\n",
      "Epoch 150/500\n",
      "\u001B[1m105/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9118 - loss: 0.4766\n",
      "Epoch 150: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9114 - loss: 0.4768 - val_accuracy: 0.9292 - val_loss: 0.3712 - learning_rate: 1.0000e-06\n",
      "Epoch 151/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9055 - loss: 0.4876\n",
      "Epoch 151: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9055 - loss: 0.4876 - val_accuracy: 0.9270 - val_loss: 0.3721 - learning_rate: 1.0000e-06\n",
      "Epoch 152/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9146 - loss: 0.4910\n",
      "Epoch 152: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9146 - loss: 0.4909 - val_accuracy: 0.9247 - val_loss: 0.3723 - learning_rate: 1.0000e-06\n",
      "Epoch 153/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9096 - loss: 0.4840\n",
      "Epoch 153: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9096 - loss: 0.4839 - val_accuracy: 0.9258 - val_loss: 0.3722 - learning_rate: 1.0000e-06\n",
      "Epoch 154/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9084 - loss: 0.4780\n",
      "Epoch 154: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9083 - loss: 0.4782 - val_accuracy: 0.9258 - val_loss: 0.3725 - learning_rate: 1.0000e-06\n",
      "Epoch 155/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9139 - loss: 0.4866\n",
      "Epoch 155: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9137 - loss: 0.4867 - val_accuracy: 0.9258 - val_loss: 0.3726 - learning_rate: 1.0000e-06\n",
      "Epoch 156/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8989 - loss: 0.4972\n",
      "Epoch 156: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8989 - loss: 0.4972 - val_accuracy: 0.9258 - val_loss: 0.3722 - learning_rate: 1.0000e-06\n",
      "Epoch 157/500\n",
      "\u001B[1m110/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9023 - loss: 0.4956\n",
      "Epoch 157: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9024 - loss: 0.4956 - val_accuracy: 0.9258 - val_loss: 0.3734 - learning_rate: 1.0000e-06\n",
      "Epoch 158/500\n",
      "\u001B[1m108/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9059 - loss: 0.4759\n",
      "Epoch 158: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9060 - loss: 0.4762 - val_accuracy: 0.9281 - val_loss: 0.3726 - learning_rate: 1.0000e-06\n",
      "Epoch 159/500\n",
      "\u001B[1m109/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8919 - loss: 0.5082\n",
      "Epoch 159: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8921 - loss: 0.5077 - val_accuracy: 0.9281 - val_loss: 0.3730 - learning_rate: 1.0000e-06\n",
      "Epoch 160/500\n",
      "\u001B[1m105/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8972 - loss: 0.5082\n",
      "Epoch 160: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8977 - loss: 0.5070 - val_accuracy: 0.9258 - val_loss: 0.3738 - learning_rate: 1.0000e-06\n",
      "Epoch 161/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9103 - loss: 0.4580\n",
      "Epoch 161: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9103 - loss: 0.4581 - val_accuracy: 0.9247 - val_loss: 0.3740 - learning_rate: 1.0000e-06\n",
      "Epoch 162/500\n",
      "\u001B[1m104/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9011 - loss: 0.4846\n",
      "Epoch 162: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9016 - loss: 0.4840 - val_accuracy: 0.9236 - val_loss: 0.3740 - learning_rate: 1.0000e-06\n",
      "Epoch 163/500\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8999 - loss: 0.4877\n",
      "Epoch 163: val_loss did not improve from 0.37096\n",
      "\u001B[1m111/111\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8998 - loss: 0.4878 - val_accuracy: 0.9258 - val_loss: 0.3728 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "##          SINGLE VIDEO PREDICTION TEST         ##\n",
    "def predict_handsign(video_path, model):\n",
    "    # Process the video to extract landmarks\n",
    "    video_data = process_video(video_path)\n",
    "    \n",
    "    # Reshape the data to match the model input shape (add batch dimension for a single video)\n",
    "    video_data = video_data.reshape(1, frames_per_video, num_landmarks, num_coordinates)\n",
    "        # Make the prediction\n",
    "    prediction = model.predict(video_data)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    \n",
    "    return predicted_class, confidence  \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model('best_handsigns_model.keras')\n",
    "    \n",
    "    test_directory = \"Model testing videos\"\n",
    "    for video_file in os.listdir(test_directory):\n",
    "        if video_file.endswith(('.mp4', '.avi', '.mov')):\n",
    "            video_path = os.path.join(test_directory, video_file)\n",
    "            predicted_class, confidence = predict_handsign(video_path, model)\n",
    "            \n",
    "            # Get hand sign name\n",
    "            predicted_handsign = handsign_names.get(predicted_class, f\"HandSign_{predicted_class}\")\n",
    "            \n",
    "            # Apply confidence threshold\n",
    "            if confidence < 0.7:\n",
    "                predicted_handsign = \"Inseguro (\"+predicted_handsign+\")\"\n",
    "                \n",
    "            print(f\"Video: {video_file}\")\n",
    "            print(f\"Predicted Hand Sign: {predicted_handsign}\")\n",
    "            print(f\"Confidence: {confidence:.2f}\")\n",
    "            print(\"--------------------\")\n"
   ],
   "id": "4f9ed1d4df51b1c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T23:27:22.549590Z",
     "start_time": "2024-10-15T23:24:09.278745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          CONTINUOUS PREDICTION WITH SLIDING WINDOW           ##\n",
    "\n",
    "import collections\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from scipy.interpolate import interp1d  # For smoothing landmarks\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('best_handsigns_model.keras')\n",
    "\n",
    "# Initialize Mediapipe solutions outside the loop for efficiency\n",
    "mp_hands = mp.solutions.hands.Hands(static_image_mode=False, \n",
    "                                    max_num_hands=2, \n",
    "                                    min_detection_confidence=0.4,  # Lowered confidence to allow for fast movement detection\n",
    "                                    min_tracking_confidence=0.4)   # Lowered tracking confidence\n",
    "mp_pose = mp.solutions.pose.Pose(static_image_mode=False, \n",
    "                                 min_detection_confidence=0.4, \n",
    "                                 min_tracking_confidence=0.4)\n",
    "\n",
    "# Open webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Sliding window buffer for frames\n",
    "frame_buffer = collections.deque(maxlen=frames_per_video)\n",
    "\n",
    "# To smooth predictions, keep track of recent predictions\n",
    "prediction_buffer = collections.deque(maxlen=3)\n",
    "\n",
    "# Store the last prediction\n",
    "last_prediction = \"No Prediction\"\n",
    "last_confidence = 0.0\n",
    "\n",
    "# Track missing hands to reset landmarks if missing for too long\n",
    "hand_missing_threshold = 5\n",
    "left_hand_missing_count = 0\n",
    "right_hand_missing_count = 0\n",
    "\n",
    "# Store the last known hand landmarks to compare in future frames\n",
    "last_left_hand_landmarks = None\n",
    "last_right_hand_landmarks = None\n",
    "\n",
    "# Movement delta threshold for fast movements\n",
    "movement_threshold = 0.9  # Adjusted threshold for movement delta\n",
    "\n",
    "# Smoothing factor for missing landmarks\n",
    "smoothing_factor = 0.8  # Weight to smooth landmarks during quick movements\n",
    "\n",
    "# Draw landmarks on the frame\n",
    "def draw_landmarks(frame, landmarks):\n",
    "    \"\"\"Draw landmarks on the frame.\"\"\"\n",
    "    for i, (x, y, z) in enumerate(landmarks):\n",
    "        h, w, _ = frame.shape\n",
    "        x = int(x * w + 325)\n",
    "        y = int(y * h + 250)\n",
    "        \n",
    "        if i < 21:  # Left hand landmarks\n",
    "            color = (0, 255, 0)\n",
    "        elif i < 42:  # Right hand landmarks\n",
    "            color = (0, 0, 255)\n",
    "        else:  # Body landmarks\n",
    "            color = (255, 0, 0)\n",
    "        \n",
    "        cv2.circle(frame, (x, y), 5, color, -1)\n",
    "\n",
    "def smooth_landmarks(new_landmarks, old_landmarks):\n",
    "    \"\"\"Smooth landmarks by interpolating between old and new.\"\"\"\n",
    "    if old_landmarks is None:\n",
    "        return new_landmarks\n",
    "\n",
    "    return old_landmarks * (1 - smoothing_factor) + new_landmarks * smoothing_factor\n",
    "\n",
    "def process_frame(frame):\n",
    "    global last_left_hand_landmarks, last_right_hand_landmarks\n",
    "    global left_hand_missing_count, right_hand_missing_count\n",
    "\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    hands_results = mp_hands.process(image)\n",
    "    pose_results = mp_pose.process(image)\n",
    "\n",
    "    # Initialize a zero-filled array for landmarks (51 landmarks, each with x, y, z)\n",
    "    landmarks = np.zeros((num_landmarks, num_coordinates))\n",
    "\n",
    "    # Detect nose for relative normalization\n",
    "    try:\n",
    "        nose_landmark = pose_results.pose_landmarks.landmark[0]\n",
    "    except:\n",
    "        class nose_landmark:\n",
    "            x = 0\n",
    "            y = 0\n",
    "            z = 0\n",
    "        nose_landmark = nose_landmark()\n",
    "\n",
    "    if hands_results.multi_hand_landmarks:\n",
    "        handedness_labels = [hand.classification[0].label for hand in hands_results.multi_handedness]\n",
    "\n",
    "        for i, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):\n",
    "            if handedness_labels[i] == 'Left':\n",
    "                left_hand = np.array([(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) \n",
    "                                      for lm in hand_landmarks.landmark])\n",
    "\n",
    "                # Smooth the transition between frames\n",
    "                left_hand = smooth_landmarks(left_hand, last_left_hand_landmarks)\n",
    "                \n",
    "                # Update the stored landmarks for the next frame\n",
    "                last_left_hand_landmarks = left_hand\n",
    "                landmarks[:21] = left_hand  # Insert the left hand landmarks into the first 21 slots\n",
    "\n",
    "            elif handedness_labels[i] == 'Right':\n",
    "                right_hand = np.array([(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) \n",
    "                                       for lm in hand_landmarks.landmark])\n",
    "\n",
    "                # Smooth the transition between frames\n",
    "                right_hand = smooth_landmarks(right_hand, last_right_hand_landmarks)\n",
    "                \n",
    "                # Update the stored landmarks for the next frame\n",
    "                last_right_hand_landmarks = right_hand\n",
    "                landmarks[21:42] = right_hand  # Insert the right hand landmarks into slots 21-42\n",
    "\n",
    "        # Reset the missing counts if hands are detected\n",
    "        left_hand_missing_count = 0\n",
    "        right_hand_missing_count = 0\n",
    "    else:\n",
    "        # Increment missing count when hands are not detected\n",
    "        left_hand_missing_count += 1\n",
    "        right_hand_missing_count += 1\n",
    "\n",
    "        # Reuse last known landmarks if available and hands are missing for too long\n",
    "        if last_left_hand_landmarks is not None:\n",
    "            landmarks[:21] = last_left_hand_landmarks\n",
    "        if last_right_hand_landmarks is not None:\n",
    "            landmarks[21:42] = last_right_hand_landmarks\n",
    "\n",
    "        # Reset landmarks if hands are missing for too long\n",
    "        if left_hand_missing_count > hand_missing_threshold:\n",
    "            last_left_hand_landmarks = None\n",
    "        if right_hand_missing_count > hand_missing_threshold:\n",
    "            last_right_hand_landmarks = None\n",
    "\n",
    "    # Fill in body landmarks (9 selected)\n",
    "    selected_body_landmarks = [0, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "    if pose_results.pose_landmarks:\n",
    "        for idx, landmark_idx in enumerate(selected_body_landmarks):\n",
    "            lm = pose_results.pose_landmarks.landmark[landmark_idx]\n",
    "            landmarks[42 + idx] = (lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z)\n",
    "\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "# Make a prediction based on the buffer\n",
    "def predict_handsign(buffer):\n",
    "    \"\"\"Make a prediction based on a buffer of frames.\"\"\"    \n",
    "    video_data = np.array(buffer)\n",
    "    video_data = video_data.reshape(1, frames_per_video, num_landmarks, num_coordinates)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(video_data, verbose=0)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_class]\n",
    "\n",
    "    return predicted_class, confidence\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Process every frame (no skipping)\n",
    "    landmarks = process_frame(frame)\n",
    "\n",
    "    # Add the landmarks to the frame buffer\n",
    "    frame_buffer.append(landmarks)\n",
    "\n",
    "    # Draw the landmarks on the frame\n",
    "    draw_landmarks(frame, landmarks)\n",
    "\n",
    "    # Once the buffer is full, make a prediction using the sliding window\n",
    "    if len(frame_buffer) == frames_per_video:\n",
    "        predicted_class, confidence = predict_handsign(frame_buffer)\n",
    "        predicted_handsign = handsign_names.get(predicted_class, f\"HandSign_{predicted_class}\")\n",
    "\n",
    "        # Update the last prediction\n",
    "        last_prediction = predicted_handsign\n",
    "        last_confidence = confidence\n",
    "\n",
    "        # Store prediction and confidence in the buffer for smoothing\n",
    "        print((predicted_class, confidence))\n",
    "        prediction_buffer.append((predicted_class, confidence))\n",
    "\n",
    "        # Average the last N predictions to smooth the output\n",
    "        avg_pred_class = np.argmax(np.bincount([p[0] for p in prediction_buffer]))\n",
    "        avg_confidence = np.mean([p[1] for p in prediction_buffer if p[0] == avg_pred_class])\n",
    "\n",
    "        if avg_confidence > 0.8:\n",
    "            last_prediction = handsign_names.get(avg_pred_class, f\"HandSign_{avg_pred_class}\")\n",
    "            last_confidence = avg_confidence\n",
    "        elif 0.45 < avg_confidence < 0.8:\n",
    "            last_prediction = \"deteccion insegura: \"+handsign_names.get(avg_pred_class, f\"HandSign_{avg_pred_class}\")\n",
    "            last_confidence = avg_confidence\n",
    "        else:\n",
    "            last_prediction = \"deteccion nula\"\n",
    "            last_confidence = avg_confidence\n",
    "            \n",
    "    # Display the last prediction on the frame\n",
    "    cv2.putText(frame, f\"Predicted: {last_prediction} Conf: {last_confidence:.2f}\", \n",
    "                (10, 30), cv2.FONT_ITALIC, 0.7, (0, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('Hands Recognition', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "ee106e95cdc75678",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.42694715)\n",
      "(1, 0.4615326)\n",
      "(1, 0.47306275)\n",
      "(1, 0.4829299)\n",
      "(1, 0.48602715)\n",
      "(1, 0.48806855)\n",
      "(1, 0.49425682)\n",
      "(1, 0.49575508)\n",
      "(1, 0.49981558)\n",
      "(1, 0.5037491)\n",
      "(1, 0.5078445)\n",
      "(1, 0.5244928)\n",
      "(1, 0.56312144)\n",
      "(1, 0.6253616)\n",
      "(1, 0.7011692)\n",
      "(1, 0.7587216)\n",
      "(1, 0.8030141)\n",
      "(1, 0.83399636)\n",
      "(1, 0.84932846)\n",
      "(1, 0.8275894)\n",
      "(1, 0.7758922)\n",
      "(1, 0.63943166)\n",
      "(2, 0.52957815)\n",
      "(2, 0.79841805)\n",
      "(2, 0.92617625)\n",
      "(2, 0.97404206)\n",
      "(2, 0.99120516)\n",
      "(2, 0.99700075)\n",
      "(2, 0.9986638)\n",
      "(2, 0.9978241)\n",
      "(2, 0.9982451)\n",
      "(2, 0.9926086)\n",
      "(2, 0.98597544)\n",
      "(2, 0.9780723)\n",
      "(2, 0.972305)\n",
      "(2, 0.96937853)\n",
      "(2, 0.96785855)\n",
      "(2, 0.96307623)\n",
      "(2, 0.95745295)\n",
      "(2, 0.94697464)\n",
      "(2, 0.9479973)\n",
      "(2, 0.96238095)\n",
      "(2, 0.97734696)\n",
      "(2, 0.98377496)\n",
      "(2, 0.9882876)\n",
      "(2, 0.98972017)\n",
      "(2, 0.98911345)\n",
      "(2, 0.9868454)\n",
      "(2, 0.97369057)\n",
      "(2, 0.96042705)\n",
      "(2, 0.9539734)\n",
      "(2, 0.95592695)\n",
      "(2, 0.9607468)\n",
      "(2, 0.96227574)\n",
      "(2, 0.9691676)\n",
      "(2, 0.9712631)\n",
      "(2, 0.9742571)\n",
      "(2, 0.97574663)\n",
      "(2, 0.9754174)\n",
      "(2, 0.9706034)\n",
      "(2, 0.96169114)\n",
      "(2, 0.9522116)\n",
      "(2, 0.938189)\n",
      "(2, 0.9239316)\n",
      "(2, 0.9111758)\n",
      "(2, 0.9125178)\n",
      "(2, 0.9159137)\n",
      "(2, 0.9097664)\n",
      "(2, 0.9000495)\n",
      "(2, 0.88912773)\n",
      "(2, 0.8722187)\n",
      "(2, 0.86683244)\n",
      "(2, 0.8752319)\n",
      "(2, 0.90740806)\n",
      "(2, 0.9201887)\n",
      "(2, 0.9351452)\n",
      "(2, 0.94987303)\n",
      "(2, 0.9628229)\n",
      "(2, 0.9791155)\n",
      "(2, 0.9865155)\n",
      "(2, 0.9887305)\n",
      "(2, 0.98835653)\n",
      "(2, 0.98825836)\n",
      "(2, 0.98910683)\n",
      "(2, 0.99076086)\n",
      "(2, 0.9929697)\n",
      "(2, 0.99474055)\n",
      "(2, 0.9962042)\n",
      "(2, 0.99711347)\n",
      "(2, 0.99780613)\n",
      "(2, 0.9983084)\n",
      "(2, 0.99863845)\n",
      "(2, 0.9989242)\n",
      "(2, 0.99904567)\n",
      "(2, 0.9989536)\n",
      "(2, 0.998733)\n",
      "(2, 0.998495)\n",
      "(2, 0.9982218)\n",
      "(2, 0.99778336)\n",
      "(2, 0.9973367)\n",
      "(2, 0.9967674)\n",
      "(2, 0.99636453)\n",
      "(2, 0.9958982)\n",
      "(2, 0.99523664)\n",
      "(2, 0.9946203)\n",
      "(2, 0.9940503)\n",
      "(2, 0.9934835)\n",
      "(2, 0.9931647)\n",
      "(2, 0.99324244)\n",
      "(2, 0.9933164)\n",
      "(2, 0.99239504)\n",
      "(2, 0.9916011)\n",
      "(2, 0.9891158)\n",
      "(2, 0.9833682)\n",
      "(2, 0.9698104)\n",
      "(2, 0.9363362)\n",
      "(2, 0.8544452)\n",
      "(2, 0.6899372)\n",
      "(2, 0.48861068)\n",
      "(3, 0.5204746)\n",
      "(3, 0.5599736)\n",
      "(3, 0.6093143)\n",
      "(3, 0.67703044)\n",
      "(3, 0.622967)\n",
      "(3, 0.58923733)\n",
      "(3, 0.56485)\n",
      "(3, 0.54125416)\n",
      "(3, 0.5115075)\n",
      "(3, 0.4857299)\n",
      "(3, 0.48756737)\n",
      "(3, 0.5273907)\n",
      "(3, 0.6176491)\n",
      "(3, 0.70266736)\n",
      "(3, 0.73892426)\n",
      "(3, 0.6997753)\n",
      "(3, 0.5548887)\n",
      "(4, 0.40068388)\n",
      "(4, 0.7400989)\n",
      "(4, 0.9133789)\n",
      "(4, 0.91168076)\n",
      "(4, 0.8968867)\n",
      "(4, 0.8820671)\n",
      "(4, 0.8691845)\n",
      "(4, 0.87331533)\n",
      "(4, 0.883137)\n",
      "(4, 0.8841252)\n",
      "(4, 0.90991706)\n",
      "(4, 0.932899)\n",
      "(4, 0.9392561)\n",
      "(4, 0.94207734)\n",
      "(4, 0.9324571)\n",
      "(4, 0.8754206)\n",
      "(4, 0.69003886)\n",
      "(1, 0.61651874)\n",
      "(1, 0.8242706)\n",
      "(1, 0.869407)\n",
      "(1, 0.81803316)\n",
      "(1, 0.71346086)\n",
      "(1, 0.7644269)\n",
      "(1, 0.7348037)\n",
      "(1, 0.73381925)\n",
      "(1, 0.73897487)\n",
      "(1, 0.7485491)\n",
      "(1, 0.75830966)\n",
      "(1, 0.74270874)\n",
      "(1, 0.70453715)\n",
      "(1, 0.6688844)\n",
      "(1, 0.635395)\n",
      "(1, 0.61409414)\n",
      "(1, 0.60979444)\n",
      "(1, 0.6312729)\n",
      "(1, 0.6745362)\n",
      "(1, 0.72286683)\n",
      "(1, 0.76953244)\n",
      "(1, 0.8574136)\n",
      "(1, 0.87489337)\n",
      "(1, 0.8949959)\n",
      "(1, 0.91640526)\n",
      "(1, 0.93549144)\n",
      "(1, 0.95474803)\n",
      "(1, 0.9718992)\n",
      "(1, 0.9818626)\n",
      "(1, 0.9875251)\n",
      "(1, 0.99143255)\n",
      "(1, 0.9940211)\n",
      "(1, 0.99556595)\n",
      "(1, 0.99638027)\n",
      "(1, 0.9970143)\n",
      "(1, 0.9973991)\n",
      "(1, 0.9976163)\n",
      "(1, 0.9973794)\n",
      "(1, 0.99662507)\n",
      "(1, 0.9949266)\n",
      "(1, 0.9917241)\n",
      "(1, 0.98417044)\n",
      "(1, 0.9612323)\n",
      "(1, 0.9164289)\n",
      "(1, 0.797292)\n",
      "(1, 0.6150338)\n",
      "(2, 0.4735852)\n",
      "(2, 0.59608555)\n",
      "(2, 0.50263053)\n",
      "(3, 0.3982142)\n",
      "(2, 0.41388455)\n",
      "(2, 0.43568558)\n",
      "(2, 0.44885725)\n",
      "(2, 0.48630875)\n",
      "(2, 0.5384693)\n",
      "(2, 0.6166817)\n",
      "(2, 0.68264234)\n",
      "(2, 0.75207543)\n",
      "(2, 0.79735756)\n",
      "(2, 0.8405969)\n",
      "(2, 0.8467359)\n",
      "(2, 0.83271074)\n",
      "(2, 0.83659244)\n",
      "(2, 0.8399196)\n",
      "(2, 0.8448479)\n",
      "(2, 0.84189564)\n",
      "(2, 0.84413624)\n",
      "(2, 0.83420986)\n",
      "(2, 0.8145257)\n",
      "(2, 0.79594064)\n",
      "(2, 0.7490376)\n",
      "(2, 0.71922296)\n",
      "(2, 0.6979468)\n",
      "(2, 0.68274945)\n",
      "(2, 0.6824805)\n",
      "(2, 0.67277056)\n",
      "(2, 0.6629622)\n",
      "(2, 0.6540556)\n",
      "(2, 0.6426234)\n",
      "(2, 0.61246943)\n",
      "(2, 0.54744023)\n",
      "(3, 0.52523524)\n",
      "(3, 0.6991849)\n",
      "(3, 0.8494776)\n",
      "(3, 0.92170495)\n",
      "(3, 0.93993616)\n",
      "(3, 0.92295647)\n",
      "(3, 0.85323614)\n",
      "(3, 0.7878294)\n",
      "(3, 0.70876867)\n",
      "(3, 0.63979936)\n",
      "(3, 0.7491129)\n",
      "(3, 0.833656)\n",
      "(3, 0.8902489)\n",
      "(3, 0.91743094)\n",
      "(3, 0.92649204)\n",
      "(3, 0.89465386)\n",
      "(3, 0.7627651)\n",
      "(2, 0.45397016)\n",
      "(2, 0.5940848)\n",
      "(2, 0.68550736)\n",
      "(2, 0.71167964)\n",
      "(2, 0.650848)\n",
      "(2, 0.6178077)\n",
      "(2, 0.60528517)\n",
      "(2, 0.6387369)\n",
      "(2, 0.67156786)\n",
      "(2, 0.71643466)\n",
      "(2, 0.7338176)\n",
      "(2, 0.7044404)\n",
      "(2, 0.66029406)\n",
      "(2, 0.61634374)\n",
      "(2, 0.6005405)\n",
      "(2, 0.6115369)\n",
      "(2, 0.6259458)\n",
      "(2, 0.6480083)\n",
      "(2, 0.6765656)\n",
      "(2, 0.69876444)\n",
      "(2, 0.6555138)\n",
      "(2, 0.60154325)\n",
      "(2, 0.54734397)\n",
      "(2, 0.49214375)\n",
      "(3, 0.47411567)\n",
      "(3, 0.4864114)\n",
      "(2, 0.48872608)\n",
      "(2, 0.5433063)\n",
      "(2, 0.6045468)\n",
      "(2, 0.6699344)\n",
      "(2, 0.74569786)\n",
      "(2, 0.8189621)\n",
      "(2, 0.8839289)\n",
      "(2, 0.9224668)\n",
      "(2, 0.94643915)\n",
      "(2, 0.9616398)\n",
      "(2, 0.9710758)\n",
      "(2, 0.96571267)\n",
      "(2, 0.95757043)\n",
      "(2, 0.94702166)\n",
      "(2, 0.9312315)\n",
      "(2, 0.94548464)\n",
      "(2, 0.95633334)\n",
      "(2, 0.9671811)\n",
      "(2, 0.96675116)\n",
      "(2, 0.9639204)\n",
      "(2, 0.9729873)\n",
      "(2, 0.94868505)\n",
      "(2, 0.93130213)\n",
      "(2, 0.9077175)\n",
      "(2, 0.89756733)\n",
      "(2, 0.880971)\n",
      "(2, 0.86600167)\n",
      "(2, 0.8902505)\n",
      "(2, 0.89218664)\n",
      "(2, 0.86363643)\n",
      "(2, 0.775417)\n",
      "(2, 0.5723105)\n",
      "(3, 0.31879896)\n",
      "(3, 0.29947516)\n",
      "(4, 0.5655442)\n",
      "(4, 0.79473025)\n",
      "(4, 0.8796193)\n",
      "(4, 0.91839147)\n",
      "(4, 0.92829764)\n",
      "(4, 0.9349991)\n",
      "(4, 0.93832767)\n",
      "(4, 0.9386769)\n",
      "(4, 0.9403313)\n",
      "(4, 0.9352678)\n",
      "(4, 0.92627996)\n",
      "(4, 0.9107244)\n",
      "(4, 0.8827859)\n",
      "(4, 0.8228615)\n",
      "(4, 0.6740076)\n",
      "(1, 0.5010979)\n",
      "(1, 0.66419)\n",
      "(1, 0.7359563)\n",
      "(1, 0.7635056)\n",
      "(1, 0.8141665)\n",
      "(1, 0.86030954)\n",
      "(1, 0.90743935)\n",
      "(1, 0.89254457)\n",
      "(1, 0.92300034)\n",
      "(1, 0.9596447)\n",
      "(1, 0.9796138)\n",
      "(1, 0.9828205)\n",
      "(1, 0.9878633)\n",
      "(1, 0.99131)\n",
      "(1, 0.99528414)\n",
      "(1, 0.9960532)\n",
      "(1, 0.9973363)\n",
      "(1, 0.9970847)\n",
      "(1, 0.9972078)\n",
      "(1, 0.9966652)\n",
      "(1, 0.9967884)\n",
      "(1, 0.9971439)\n",
      "(1, 0.9974825)\n",
      "(1, 0.9977634)\n",
      "(1, 0.99799097)\n",
      "(1, 0.99821377)\n",
      "(1, 0.9985239)\n",
      "(1, 0.9979943)\n",
      "(1, 0.99725753)\n",
      "(1, 0.99506736)\n",
      "(1, 0.9908099)\n",
      "(1, 0.98807985)\n",
      "(1, 0.9732178)\n",
      "(1, 0.88179386)\n",
      "(1, 0.71136516)\n",
      "(7, 0.60673803)\n",
      "(7, 0.63624215)\n",
      "(7, 0.6157895)\n",
      "(7, 0.5290592)\n",
      "(7, 0.4150802)\n",
      "(1, 0.35791975)\n",
      "(1, 0.55011475)\n",
      "(1, 0.69933075)\n",
      "(1, 0.84499675)\n",
      "(1, 0.9384052)\n",
      "(1, 0.9716861)\n",
      "(1, 0.98416257)\n",
      "(1, 0.986067)\n",
      "(1, 0.98064923)\n",
      "(1, 0.97553784)\n",
      "(1, 0.97035307)\n",
      "(1, 0.9647992)\n",
      "(1, 0.9599982)\n",
      "(1, 0.96003056)\n",
      "(1, 0.9608055)\n",
      "(1, 0.96117526)\n",
      "(1, 0.95368135)\n",
      "(1, 0.9318196)\n",
      "(1, 0.88244724)\n",
      "(1, 0.798989)\n",
      "(1, 0.7013488)\n",
      "(1, 0.6085992)\n",
      "(1, 0.50319916)\n",
      "(4, 0.45958892)\n",
      "(4, 0.51963913)\n",
      "(4, 0.44571832)\n",
      "(2, 0.4481568)\n",
      "(2, 0.4133401)\n",
      "(4, 0.37147272)\n",
      "(4, 0.52087116)\n",
      "(4, 0.65057117)\n",
      "(4, 0.74579567)\n",
      "(4, 0.6288865)\n",
      "(8, 0.38064924)\n",
      "(8, 0.6008405)\n",
      "(8, 0.5757318)\n",
      "(9, 0.53888786)\n",
      "(9, 0.44252563)\n",
      "(8, 0.6450116)\n",
      "(9, 0.5764126)\n",
      "(7, 0.51971394)\n",
      "(7, 0.6400251)\n",
      "(7, 0.54941916)\n",
      "(9, 0.53781503)\n",
      "(9, 0.6811957)\n",
      "(9, 0.7376427)\n",
      "(9, 0.7473326)\n",
      "(9, 0.809686)\n",
      "(9, 0.83201176)\n",
      "(9, 0.8419711)\n",
      "(9, 0.8456175)\n",
      "(9, 0.85630983)\n",
      "(9, 0.87312347)\n",
      "(9, 0.8983421)\n",
      "(9, 0.90295935)\n",
      "(9, 0.7860426)\n",
      "(9, 0.54810745)\n",
      "(5, 0.4574305)\n",
      "(9, 0.5072325)\n",
      "(9, 0.49038512)\n",
      "(5, 0.5061341)\n",
      "(5, 0.5728627)\n",
      "(5, 0.59832865)\n",
      "(9, 0.55985796)\n",
      "(9, 0.7509285)\n",
      "(9, 0.8937803)\n",
      "(9, 0.8480322)\n",
      "(8, 0.7920063)\n",
      "(8, 0.9493628)\n",
      "(8, 0.9154872)\n",
      "(8, 0.5655894)\n",
      "(6, 0.576066)\n",
      "(6, 0.6484211)\n",
      "(6, 0.57093745)\n",
      "(2, 0.38584024)\n",
      "(6, 0.4627328)\n",
      "(6, 0.6088493)\n",
      "(6, 0.71116215)\n",
      "(6, 0.82549554)\n",
      "(6, 0.90208185)\n",
      "(6, 0.92019755)\n",
      "(6, 0.89862716)\n",
      "(6, 0.82645905)\n",
      "(6, 0.66169447)\n",
      "(2, 0.52325404)\n",
      "(2, 0.8527291)\n",
      "(2, 0.95052195)\n",
      "(2, 0.96968484)\n",
      "(2, 0.96908027)\n",
      "(2, 0.9602096)\n",
      "(2, 0.94445586)\n",
      "(2, 0.9165002)\n",
      "(2, 0.77165747)\n",
      "(2, 0.9306469)\n",
      "(2, 0.91533154)\n",
      "(2, 0.94765425)\n",
      "(2, 0.8783193)\n",
      "(2, 0.80871725)\n",
      "(2, 0.794106)\n",
      "(2, 0.7561228)\n",
      "(2, 0.71061224)\n",
      "(2, 0.7003027)\n",
      "(2, 0.68925637)\n",
      "(2, 0.66258276)\n",
      "(2, 0.60752976)\n",
      "(2, 0.5406211)\n",
      "(3, 0.49360043)\n",
      "(3, 0.5189078)\n",
      "(3, 0.52220416)\n",
      "(3, 0.516688)\n",
      "(3, 0.5264631)\n",
      "(3, 0.51078635)\n",
      "(3, 0.49981415)\n",
      "(3, 0.48465806)\n",
      "(2, 0.5106866)\n",
      "(2, 0.5484326)\n",
      "(2, 0.5962064)\n",
      "(2, 0.66373503)\n",
      "(2, 0.7465806)\n",
      "(2, 0.84024614)\n",
      "(2, 0.9175715)\n",
      "(2, 0.96405315)\n",
      "(2, 0.9864818)\n",
      "(2, 0.9948084)\n",
      "(2, 0.9977187)\n",
      "(2, 0.998728)\n",
      "(2, 0.99920315)\n",
      "(2, 0.99944717)\n",
      "(2, 0.9996126)\n",
      "(2, 0.99969447)\n",
      "(2, 0.99972385)\n",
      "(2, 0.9997305)\n",
      "(2, 0.99969757)\n",
      "(2, 0.99962616)\n",
      "(2, 0.9996014)\n",
      "(2, 0.99959165)\n",
      "(2, 0.99956506)\n",
      "(2, 0.9994904)\n",
      "(2, 0.99941003)\n",
      "(2, 0.99939775)\n",
      "(2, 0.99941087)\n",
      "(2, 0.9994342)\n",
      "(2, 0.99943036)\n",
      "(2, 0.99942493)\n",
      "(2, 0.99941015)\n",
      "(2, 0.99940825)\n",
      "(2, 0.9994043)\n",
      "(2, 0.9994288)\n",
      "(2, 0.9994469)\n",
      "(2, 0.99943596)\n",
      "(2, 0.99938285)\n",
      "(2, 0.99918765)\n",
      "(2, 0.9984268)\n",
      "(2, 0.9953957)\n",
      "(2, 0.9839622)\n",
      "(2, 0.97095245)\n",
      "(2, 0.95716625)\n",
      "(2, 0.94561815)\n",
      "(2, 0.9533191)\n",
      "(2, 0.95465696)\n",
      "(2, 0.954534)\n",
      "(2, 0.9645098)\n",
      "(2, 0.9784061)\n",
      "(2, 0.9890826)\n",
      "(2, 0.9944939)\n",
      "(2, 0.9969887)\n",
      "(2, 0.9979886)\n",
      "(2, 0.9983204)\n",
      "(2, 0.9981177)\n",
      "(2, 0.99802005)\n",
      "(2, 0.99823594)\n",
      "(2, 0.99845695)\n",
      "(2, 0.99864966)\n",
      "(2, 0.9988167)\n",
      "(2, 0.998949)\n",
      "(2, 0.999054)\n",
      "(2, 0.9990533)\n",
      "(2, 0.9990207)\n",
      "(2, 0.9989666)\n",
      "(2, 0.9988894)\n",
      "(2, 0.99876875)\n",
      "(2, 0.99861467)\n",
      "(2, 0.99829715)\n",
      "(2, 0.9977775)\n",
      "(2, 0.9972584)\n",
      "(2, 0.99665207)\n",
      "(2, 0.99583745)\n",
      "(2, 0.9950589)\n",
      "(2, 0.9940801)\n",
      "(2, 0.9936243)\n",
      "(2, 0.99312395)\n",
      "(2, 0.99270695)\n",
      "(2, 0.9932795)\n",
      "(2, 0.99446106)\n",
      "(2, 0.9954763)\n",
      "(2, 0.9962864)\n",
      "(2, 0.99689627)\n",
      "(2, 0.9970994)\n",
      "(2, 0.99723804)\n",
      "(2, 0.9970387)\n",
      "(2, 0.99704117)\n",
      "(2, 0.99687934)\n",
      "(2, 0.996597)\n",
      "(2, 0.9957799)\n",
      "(2, 0.99392587)\n",
      "(2, 0.98975337)\n",
      "(2, 0.9795562)\n",
      "(2, 0.9614152)\n",
      "(2, 0.9437858)\n",
      "(2, 0.95149887)\n",
      "(2, 0.96932954)\n",
      "(2, 0.97402793)\n",
      "(2, 0.96985614)\n",
      "(2, 0.9441815)\n",
      "(2, 0.8671675)\n",
      "(2, 0.63164157)\n",
      "(8, 0.57725924)\n",
      "(8, 0.71124727)\n",
      "(8, 0.7456323)\n",
      "(8, 0.716254)\n",
      "(8, 0.71353626)\n",
      "(8, 0.7253988)\n",
      "(8, 0.7668019)\n",
      "(8, 0.80019206)\n",
      "(8, 0.8142155)\n",
      "(8, 0.7780693)\n",
      "(8, 0.62995595)\n",
      "(2, 0.5852388)\n",
      "(2, 0.8190319)\n",
      "(2, 0.8900227)\n",
      "(2, 0.8080989)\n",
      "(2, 0.6065719)\n",
      "(2, 0.3546477)\n",
      "(2, 0.36367407)\n",
      "(2, 0.41922355)\n",
      "(2, 0.51483554)\n",
      "(2, 0.6567952)\n",
      "(2, 0.85043836)\n",
      "(2, 0.94973195)\n",
      "(2, 0.9831209)\n",
      "(2, 0.99049497)\n",
      "(2, 0.98921317)\n",
      "(2, 0.9844065)\n",
      "(2, 0.9695776)\n",
      "(2, 0.93473613)\n",
      "(2, 0.89321625)\n",
      "(2, 0.84119916)\n",
      "(2, 0.7849534)\n",
      "(2, 0.7698631)\n",
      "(2, 0.76768994)\n",
      "(2, 0.7841569)\n",
      "(2, 0.8078932)\n",
      "(2, 0.83062696)\n",
      "(2, 0.8617332)\n",
      "(2, 0.8878966)\n",
      "(2, 0.89004713)\n",
      "(2, 0.89844435)\n",
      "(2, 0.914711)\n",
      "(2, 0.93621856)\n",
      "(2, 0.96043044)\n",
      "(2, 0.9773811)\n",
      "(2, 0.9870766)\n",
      "(2, 0.98987716)\n",
      "(2, 0.9863821)\n",
      "(2, 0.9456785)\n",
      "(2, 0.5590577)\n",
      "(4, 0.5149366)\n",
      "(4, 0.57968825)\n",
      "(4, 0.61233324)\n",
      "(4, 0.6231156)\n",
      "(4, 0.5984039)\n",
      "(4, 0.57661825)\n",
      "(4, 0.55722845)\n",
      "(4, 0.5404981)\n",
      "(4, 0.5230368)\n",
      "(4, 0.5008253)\n",
      "(4, 0.460082)\n",
      "(2, 0.45471585)\n",
      "(2, 0.6711597)\n",
      "(2, 0.8720703)\n",
      "(2, 0.9691486)\n",
      "(2, 0.99128634)\n",
      "(2, 0.9964965)\n",
      "(2, 0.99778533)\n",
      "(2, 0.9973838)\n",
      "(2, 0.9934382)\n",
      "(2, 0.9895517)\n",
      "(2, 0.98977274)\n",
      "(2, 0.98869276)\n",
      "(2, 0.98638356)\n",
      "(2, 0.9803668)\n",
      "(2, 0.9707546)\n",
      "(2, 0.9500978)\n",
      "(2, 0.9029056)\n",
      "(2, 0.69919413)\n",
      "(9, 0.27423197)\n",
      "(9, 0.7159511)\n",
      "(9, 0.9113636)\n",
      "(9, 0.96768415)\n",
      "(9, 0.97228855)\n",
      "(9, 0.97656894)\n",
      "(9, 0.9832565)\n",
      "(9, 0.98335046)\n",
      "(9, 0.9837891)\n",
      "(9, 0.9835422)\n",
      "(9, 0.97962326)\n",
      "(9, 0.97161406)\n",
      "(9, 0.9730409)\n",
      "(9, 0.9792595)\n",
      "(9, 0.9803861)\n",
      "(9, 0.97917855)\n",
      "(9, 0.9775254)\n",
      "(9, 0.96756715)\n",
      "(9, 0.94286877)\n",
      "(9, 0.8726124)\n",
      "(9, 0.7359454)\n",
      "(9, 0.54662776)\n",
      "(3, 0.33183193)\n",
      "(3, 0.3414622)\n",
      "(1, 0.3833296)\n",
      "(2, 0.40153825)\n",
      "(2, 0.6451644)\n",
      "(2, 0.74747044)\n",
      "(2, 0.8066374)\n",
      "(2, 0.8410217)\n",
      "(2, 0.87128407)\n",
      "(2, 0.86960256)\n",
      "(2, 0.878086)\n",
      "(2, 0.83575964)\n",
      "(2, 0.78066975)\n",
      "(2, 0.76424426)\n",
      "(2, 0.77213573)\n",
      "(2, 0.8014859)\n",
      "(2, 0.84954286)\n",
      "(2, 0.91282374)\n",
      "(2, 0.9470191)\n",
      "(2, 0.9654596)\n",
      "(2, 0.9769548)\n",
      "(2, 0.9836556)\n",
      "(2, 0.9825972)\n",
      "(2, 0.98464555)\n",
      "(2, 0.9836679)\n",
      "(2, 0.9836871)\n",
      "(2, 0.9889712)\n",
      "(2, 0.994111)\n",
      "(2, 0.9974825)\n",
      "(2, 0.99867946)\n",
      "(2, 0.99917346)\n",
      "(2, 0.9993305)\n",
      "(2, 0.99939656)\n",
      "(2, 0.99924845)\n",
      "(2, 0.99895006)\n",
      "(2, 0.9982919)\n",
      "(2, 0.99741215)\n",
      "(2, 0.99668723)\n",
      "(2, 0.9964849)\n",
      "(2, 0.99536055)\n",
      "(2, 0.9930957)\n",
      "(2, 0.98940736)\n",
      "(2, 0.98163134)\n",
      "(2, 0.9761406)\n",
      "(2, 0.9748241)\n",
      "(2, 0.9777834)\n",
      "(2, 0.9804537)\n",
      "(2, 0.9833175)\n",
      "(2, 0.98698646)\n",
      "(2, 0.99027866)\n",
      "(2, 0.9920232)\n",
      "(2, 0.9931873)\n",
      "(2, 0.99308926)\n",
      "(2, 0.9930293)\n",
      "(2, 0.99318486)\n",
      "(2, 0.99231297)\n",
      "(2, 0.9912999)\n",
      "(2, 0.9899418)\n",
      "(2, 0.988929)\n",
      "(2, 0.9881747)\n",
      "(2, 0.9870242)\n",
      "(2, 0.98525256)\n",
      "(2, 0.98206526)\n",
      "(2, 0.9760158)\n",
      "(2, 0.96601325)\n",
      "(2, 0.93122554)\n",
      "(2, 0.82409465)\n",
      "(2, 0.5550109)\n",
      "(1, 0.21211924)\n",
      "(7, 0.23846444)\n",
      "(7, 0.27133623)\n",
      "(7, 0.26984552)\n",
      "(5, 0.3434642)\n",
      "(5, 0.41735983)\n",
      "(5, 0.53292966)\n",
      "(5, 0.5369546)\n",
      "(5, 0.4933849)\n",
      "(5, 0.47501403)\n",
      "(5, 0.579952)\n",
      "(5, 0.44909444)\n",
      "(7, 0.33621362)\n",
      "(7, 0.41009456)\n",
      "(7, 0.36438468)\n",
      "(3, 0.35009462)\n",
      "(7, 0.35978615)\n",
      "(7, 0.37794292)\n",
      "(7, 0.38499662)\n",
      "(7, 0.3848999)\n",
      "(1, 0.41149744)\n",
      "(1, 0.5342584)\n",
      "(1, 0.54482335)\n",
      "(4, 0.36767507)\n",
      "(4, 0.42151338)\n",
      "(4, 0.3919599)\n",
      "(2, 0.29607922)\n",
      "(2, 0.51574403)\n",
      "(2, 0.67137736)\n",
      "(2, 0.62821937)\n",
      "(1, 0.45601642)\n",
      "(1, 0.72503644)\n",
      "(1, 0.8384435)\n",
      "(1, 0.85912526)\n",
      "(1, 0.86829835)\n",
      "(1, 0.8441409)\n",
      "(1, 0.8032223)\n",
      "(1, 0.7306962)\n",
      "(1, 0.61859614)\n",
      "(1, 0.50475717)\n",
      "(1, 0.43919644)\n",
      "(4, 0.4267336)\n",
      "(4, 0.40144855)\n",
      "(1, 0.4888039)\n",
      "(1, 0.61028355)\n",
      "(1, 0.64376014)\n",
      "(1, 0.6628725)\n",
      "(1, 0.72714853)\n",
      "(1, 0.77908885)\n",
      "(1, 0.81333846)\n",
      "(1, 0.8662244)\n",
      "(1, 0.89743847)\n",
      "(1, 0.88421744)\n",
      "(1, 0.72983736)\n",
      "(2, 0.6022927)\n",
      "(2, 0.866181)\n",
      "(2, 0.9585414)\n",
      "(2, 0.96634513)\n",
      "(2, 0.96268535)\n",
      "(2, 0.9483739)\n",
      "(2, 0.92641324)\n",
      "(2, 0.8762244)\n",
      "(2, 0.8455061)\n",
      "(2, 0.8158054)\n",
      "(2, 0.8852062)\n",
      "(2, 0.951688)\n",
      "(2, 0.9762298)\n",
      "(2, 0.98820555)\n",
      "(2, 0.9926454)\n",
      "(2, 0.9956001)\n",
      "(2, 0.9969342)\n",
      "(2, 0.9948325)\n",
      "(2, 0.9885488)\n",
      "(2, 0.9678349)\n",
      "(2, 0.88328964)\n",
      "(2, 0.83317745)\n",
      "(2, 0.5917575)\n",
      "(1, 0.6210477)\n",
      "(1, 0.74295443)\n",
      "(1, 0.8011278)\n",
      "(1, 0.8260238)\n",
      "(1, 0.8618876)\n",
      "(1, 0.89021236)\n",
      "(1, 0.91757417)\n",
      "(1, 0.9297519)\n",
      "(1, 0.9313168)\n",
      "(1, 0.92083067)\n",
      "(1, 0.90095836)\n",
      "(1, 0.8921832)\n",
      "(1, 0.89205205)\n",
      "(1, 0.8911178)\n",
      "(1, 0.8897839)\n",
      "(1, 0.83694893)\n",
      "(1, 0.70579374)\n",
      "(1, 0.49712896)\n",
      "(2, 0.61800086)\n",
      "(2, 0.6274037)\n",
      "(2, 0.5818628)\n",
      "(2, 0.7111891)\n",
      "(2, 0.7797014)\n",
      "(2, 0.8210379)\n",
      "(2, 0.8181028)\n",
      "(2, 0.763573)\n",
      "(2, 0.6612789)\n",
      "(2, 0.5275207)\n",
      "(2, 0.39360994)\n",
      "(2, 0.34879827)\n",
      "(2, 0.38516638)\n",
      "(1, 0.49813864)\n",
      "(1, 0.63258624)\n",
      "(1, 0.74084294)\n",
      "(1, 0.78003997)\n",
      "(1, 0.7998018)\n",
      "(1, 0.80656374)\n",
      "(1, 0.8102143)\n",
      "(1, 0.813609)\n",
      "(1, 0.8146533)\n",
      "(1, 0.81002885)\n",
      "(1, 0.794024)\n",
      "(1, 0.75457305)\n",
      "(1, 0.70486027)\n",
      "(1, 0.66007)\n",
      "(1, 0.6063245)\n",
      "(1, 0.5478752)\n",
      "(1, 0.48384926)\n",
      "(2, 0.45296746)\n",
      "(2, 0.48287928)\n",
      "(2, 0.49387097)\n",
      "(2, 0.5454693)\n",
      "(2, 0.63464844)\n",
      "(2, 0.7146067)\n",
      "(2, 0.742525)\n",
      "(2, 0.75297076)\n",
      "(2, 0.74602103)\n",
      "(2, 0.71824145)\n",
      "(2, 0.71128106)\n",
      "(2, 0.6816367)\n",
      "(2, 0.6372445)\n",
      "(2, 0.6194841)\n",
      "(2, 0.6194945)\n",
      "(2, 0.6712176)\n",
      "(2, 0.68664503)\n",
      "(2, 0.70166516)\n",
      "(2, 0.72899836)\n",
      "(2, 0.8019667)\n",
      "(2, 0.8487389)\n",
      "(2, 0.8740075)\n",
      "(2, 0.8964381)\n",
      "(2, 0.92334086)\n",
      "(2, 0.92114544)\n",
      "(2, 0.912425)\n",
      "(2, 0.90485805)\n",
      "(2, 0.8685922)\n",
      "(2, 0.7471869)\n",
      "(2, 0.5131423)\n",
      "(1, 0.5539965)\n",
      "(1, 0.63051194)\n",
      "(1, 0.65548027)\n",
      "(1, 0.6346257)\n",
      "(1, 0.5216363)\n",
      "(2, 0.5386462)\n",
      "(2, 0.63189185)\n",
      "(2, 0.6709766)\n",
      "(2, 0.6605988)\n",
      "(2, 0.61353624)\n",
      "(2, 0.5596642)\n",
      "(2, 0.45961645)\n",
      "(1, 0.42894158)\n",
      "(1, 0.5713977)\n",
      "(1, 0.61341774)\n",
      "(1, 0.617325)\n",
      "(1, 0.59143853)\n",
      "(1, 0.5355212)\n",
      "(1, 0.44551778)\n",
      "(1, 0.3602806)\n",
      "(1, 0.2812674)\n",
      "(4, 0.31219587)\n",
      "(4, 0.373335)\n",
      "(4, 0.3799929)\n",
      "(4, 0.31505302)\n",
      "(2, 0.21506324)\n",
      "(2, 0.31913516)\n",
      "(2, 0.40059966)\n",
      "(2, 0.4519656)\n",
      "(2, 0.6104422)\n",
      "(2, 0.75131124)\n",
      "(2, 0.84528434)\n",
      "(2, 0.8859999)\n",
      "(2, 0.89478207)\n",
      "(2, 0.9111468)\n",
      "(2, 0.9167596)\n",
      "(2, 0.88572484)\n",
      "(2, 0.8395526)\n",
      "(2, 0.72911614)\n",
      "(2, 0.3868841)\n",
      "(1, 0.6202707)\n",
      "(1, 0.860745)\n",
      "(1, 0.97974485)\n",
      "(1, 0.9964851)\n",
      "(1, 0.99909794)\n",
      "(1, 0.9994879)\n",
      "(1, 0.99964774)\n",
      "(1, 0.9996656)\n",
      "(1, 0.99967873)\n",
      "(1, 0.99971014)\n",
      "(1, 0.9997367)\n",
      "(1, 0.99974686)\n",
      "(1, 0.99974746)\n",
      "(1, 0.9997358)\n",
      "(1, 0.99972206)\n",
      "(1, 0.99973327)\n",
      "(1, 0.9997652)\n",
      "(1, 0.99978644)\n",
      "(1, 0.9998037)\n",
      "(1, 0.9998153)\n",
      "(1, 0.999808)\n",
      "(1, 0.9997936)\n",
      "(1, 0.9997123)\n",
      "(1, 0.99954295)\n",
      "(1, 0.99813)\n",
      "(1, 0.6866508)\n",
      "(9, 0.90474117)\n",
      "(9, 0.9350839)\n",
      "(9, 0.950641)\n",
      "(9, 0.9641253)\n",
      "(9, 0.96491265)\n",
      "(9, 0.94848007)\n",
      "(9, 0.923084)\n",
      "(9, 0.8825085)\n",
      "(9, 0.75059897)\n",
      "(2, 0.24894021)\n",
      "(2, 0.5003618)\n",
      "(2, 0.82967865)\n",
      "(2, 0.9399957)\n",
      "(2, 0.93630195)\n",
      "(2, 0.94598967)\n",
      "(2, 0.95814943)\n",
      "(2, 0.9680618)\n",
      "(2, 0.9763485)\n",
      "(2, 0.98368907)\n",
      "(2, 0.989164)\n",
      "(2, 0.992923)\n",
      "(2, 0.9937482)\n",
      "(2, 0.99430805)\n",
      "(2, 0.9882493)\n",
      "(2, 0.9895427)\n",
      "(2, 0.98949814)\n",
      "(2, 0.98636174)\n",
      "(2, 0.97607726)\n",
      "(2, 0.92899805)\n",
      "(2, 0.8007344)\n",
      "(2, 0.5506829)\n",
      "(2, 0.43107414)\n",
      "(2, 0.3396089)\n",
      "(2, 0.36196125)\n",
      "(2, 0.60948825)\n",
      "(2, 0.8950835)\n",
      "(2, 0.9886828)\n",
      "(2, 0.9924349)\n",
      "(2, 0.9669785)\n",
      "(2, 0.696211)\n",
      "(3, 0.95706743)\n",
      "(3, 0.98828214)\n",
      "(3, 0.9930415)\n",
      "(3, 0.99674124)\n",
      "(3, 0.99819607)\n",
      "(3, 0.99882215)\n",
      "(3, 0.99910116)\n",
      "(3, 0.9992415)\n",
      "(3, 0.9991949)\n",
      "(3, 0.9989723)\n",
      "(3, 0.99854004)\n",
      "(3, 0.9980014)\n",
      "(3, 0.9974517)\n",
      "(3, 0.99639267)\n",
      "(3, 0.9943482)\n",
      "(3, 0.9936215)\n",
      "(3, 0.9910034)\n",
      "(3, 0.988761)\n",
      "(3, 0.9884089)\n",
      "(3, 0.98768884)\n",
      "(3, 0.98470324)\n",
      "(3, 0.9817409)\n",
      "(3, 0.98218876)\n",
      "(3, 0.9852787)\n",
      "(3, 0.9870373)\n",
      "(3, 0.9847046)\n",
      "(3, 0.9840608)\n",
      "(3, 0.98465997)\n",
      "(3, 0.9874089)\n",
      "(3, 0.9896624)\n",
      "(3, 0.9916715)\n",
      "(3, 0.9935783)\n",
      "(3, 0.99488986)\n",
      "(3, 0.99503183)\n",
      "(3, 0.9929609)\n",
      "(3, 0.98961604)\n",
      "(3, 0.9866632)\n",
      "(3, 0.9779612)\n",
      "(3, 0.9659539)\n",
      "(3, 0.91259134)\n",
      "(3, 0.54751444)\n",
      "(9, 0.8046715)\n",
      "(9, 0.84311616)\n",
      "(9, 0.77357906)\n",
      "(9, 0.7191618)\n",
      "(9, 0.69329005)\n",
      "(9, 0.69893557)\n",
      "(9, 0.72495717)\n",
      "(9, 0.7494265)\n",
      "(9, 0.74774104)\n",
      "(9, 0.7410722)\n",
      "(9, 0.74389446)\n",
      "(9, 0.75509536)\n",
      "(9, 0.7718779)\n",
      "(9, 0.7758866)\n",
      "(9, 0.78059936)\n",
      "(9, 0.7822005)\n",
      "(9, 0.7706394)\n",
      "(9, 0.77044916)\n",
      "(9, 0.77569884)\n",
      "(9, 0.78607374)\n",
      "(9, 0.7826926)\n",
      "(9, 0.7641948)\n",
      "(9, 0.75644404)\n",
      "(9, 0.7543114)\n",
      "(9, 0.7501391)\n",
      "(9, 0.7574876)\n",
      "(9, 0.7649383)\n",
      "(9, 0.76974195)\n",
      "(9, 0.77956635)\n",
      "(9, 0.78343076)\n",
      "(9, 0.7860346)\n",
      "(9, 0.7895876)\n",
      "(9, 0.7979512)\n",
      "(9, 0.80542177)\n",
      "(9, 0.8113343)\n",
      "(9, 0.78972566)\n",
      "(9, 0.7732404)\n",
      "(9, 0.7530972)\n",
      "(9, 0.7416693)\n",
      "(9, 0.7418647)\n",
      "(9, 0.7545021)\n",
      "(9, 0.78658336)\n",
      "(9, 0.8343432)\n",
      "(9, 0.8843029)\n",
      "(9, 0.92216486)\n",
      "(9, 0.95087814)\n",
      "(9, 0.9653719)\n",
      "(9, 0.9662221)\n",
      "(9, 0.97031087)\n",
      "(9, 0.9711179)\n",
      "(9, 0.97273594)\n",
      "(9, 0.97693664)\n",
      "(9, 0.9790218)\n",
      "(9, 0.9839951)\n",
      "(9, 0.9846383)\n",
      "(9, 0.9834631)\n",
      "(9, 0.98171383)\n",
      "(9, 0.98385555)\n",
      "(9, 0.98587775)\n",
      "(9, 0.9869654)\n",
      "(9, 0.98514843)\n",
      "(9, 0.98275983)\n",
      "(9, 0.98065144)\n",
      "(9, 0.9809794)\n",
      "(9, 0.9797738)\n",
      "(9, 0.980162)\n",
      "(9, 0.9788351)\n",
      "(9, 0.9753983)\n",
      "(9, 0.97044927)\n",
      "(9, 0.96488714)\n",
      "(9, 0.9601086)\n",
      "(9, 0.9535297)\n",
      "(9, 0.9434655)\n",
      "(9, 0.92752445)\n",
      "(9, 0.90532553)\n",
      "(9, 0.87502533)\n",
      "(9, 0.8554683)\n",
      "(9, 0.859924)\n",
      "(9, 0.8867709)\n",
      "(9, 0.9152184)\n",
      "(9, 0.9411197)\n",
      "(9, 0.95984274)\n",
      "(9, 0.97150326)\n",
      "(9, 0.9725186)\n",
      "(9, 0.9666732)\n",
      "(9, 0.9377502)\n",
      "(9, 0.85517985)\n",
      "(9, 0.69322586)\n",
      "(9, 0.49521732)\n",
      "(1, 0.34703007)\n",
      "(1, 0.46470085)\n",
      "(4, 0.41570288)\n",
      "(4, 0.5924842)\n",
      "(4, 0.7302312)\n",
      "(4, 0.82111424)\n",
      "(4, 0.87685823)\n",
      "(4, 0.91014963)\n",
      "(4, 0.9168576)\n",
      "(4, 0.9058835)\n",
      "(4, 0.8759545)\n",
      "(4, 0.8197475)\n",
      "(4, 0.7862814)\n",
      "(4, 0.7718246)\n",
      "(4, 0.7890133)\n",
      "(4, 0.8080091)\n",
      "(4, 0.8052589)\n",
      "(4, 0.80816585)\n",
      "(4, 0.83190507)\n",
      "(4, 0.8417593)\n",
      "(4, 0.8589942)\n",
      "(4, 0.8771526)\n",
      "(4, 0.87656564)\n",
      "(4, 0.86015856)\n",
      "(4, 0.85104877)\n",
      "(4, 0.85012925)\n",
      "(4, 0.8495669)\n",
      "(4, 0.86652434)\n",
      "(4, 0.8839862)\n",
      "(4, 0.89397156)\n",
      "(4, 0.9029817)\n",
      "(4, 0.89004743)\n",
      "(4, 0.84903985)\n",
      "(4, 0.7265314)\n",
      "(4, 0.44417217)\n",
      "(2, 0.53427386)\n",
      "(2, 0.7196188)\n",
      "(2, 0.8708706)\n",
      "(2, 0.898088)\n",
      "(2, 0.9064763)\n",
      "(2, 0.9195228)\n",
      "(2, 0.9633176)\n",
      "(2, 0.9851677)\n",
      "(2, 0.99414825)\n",
      "(2, 0.9974571)\n",
      "(2, 0.99780756)\n",
      "(2, 0.9976376)\n",
      "(2, 0.9976164)\n",
      "(2, 0.99762326)\n",
      "(2, 0.9965873)\n",
      "(2, 0.99403715)\n",
      "(2, 0.9869594)\n",
      "(2, 0.95490766)\n",
      "(2, 0.7723296)\n",
      "(4, 0.5010092)\n",
      "(4, 0.76057297)\n",
      "(4, 0.7980777)\n",
      "(4, 0.8314822)\n",
      "(4, 0.8409776)\n",
      "(4, 0.8452054)\n",
      "(4, 0.8268759)\n",
      "(4, 0.8047904)\n",
      "(4, 0.7268493)\n",
      "(4, 0.55949813)\n",
      "(2, 0.45970425)\n",
      "(2, 0.66909826)\n",
      "(2, 0.81358886)\n",
      "(2, 0.8899899)\n",
      "(2, 0.92073613)\n",
      "(2, 0.9268061)\n",
      "(2, 0.77988076)\n",
      "(4, 0.3543273)\n",
      "(6, 0.47402853)\n",
      "(6, 0.80330956)\n",
      "(6, 0.92873615)\n",
      "(6, 0.9651439)\n",
      "(6, 0.9765645)\n",
      "(6, 0.9700261)\n",
      "(6, 0.95834625)\n",
      "(6, 0.942777)\n",
      "(6, 0.9043583)\n",
      "(6, 0.7663866)\n",
      "(2, 0.55222434)\n",
      "(2, 0.8416717)\n",
      "(6, 0.8278766)\n",
      "(6, 0.9510806)\n",
      "(6, 0.9813535)\n",
      "(6, 0.9799257)\n",
      "(6, 0.96061546)\n",
      "(6, 0.9210919)\n",
      "(6, 0.80489224)\n",
      "(6, 0.58302444)\n",
      "(4, 0.43105465)\n",
      "(4, 0.6613111)\n",
      "(4, 0.4878322)\n",
      "(3, 0.2793351)\n",
      "(3, 0.38902715)\n",
      "(3, 0.36260152)\n",
      "(2, 0.61176705)\n",
      "(2, 0.90944767)\n",
      "(2, 0.96021247)\n",
      "(2, 0.93038625)\n",
      "(2, 0.91482556)\n",
      "(2, 0.7161776)\n",
      "(6, 0.5119442)\n",
      "(6, 0.8463432)\n",
      "(6, 0.93959033)\n",
      "(6, 0.9605487)\n",
      "(6, 0.96205103)\n",
      "(6, 0.9342842)\n",
      "(6, 0.82603806)\n",
      "(3, 0.46052244)\n",
      "(3, 0.8304996)\n",
      "(3, 0.7997742)\n",
      "(2, 0.59856117)\n",
      "(2, 0.95028806)\n",
      "(2, 0.99151057)\n",
      "(2, 0.93684965)\n",
      "(2, 0.971609)\n",
      "(2, 0.99361765)\n",
      "(2, 0.98812276)\n",
      "(2, 0.9701334)\n",
      "(2, 0.91483533)\n",
      "(2, 0.7441488)\n",
      "(3, 0.4604864)\n",
      "(3, 0.731297)\n",
      "(3, 0.75686044)\n",
      "(3, 0.61564237)\n",
      "(3, 0.4292001)\n",
      "(6, 0.46901715)\n",
      "(6, 0.4675797)\n",
      "(6, 0.37521657)\n",
      "(4, 0.7653543)\n",
      "(4, 0.79352635)\n",
      "(4, 0.8326315)\n",
      "(4, 0.8118785)\n",
      "(4, 0.79468673)\n",
      "(4, 0.77687716)\n",
      "(4, 0.7850126)\n",
      "(4, 0.7877944)\n",
      "(4, 0.8198011)\n",
      "(4, 0.8475213)\n",
      "(4, 0.8946377)\n",
      "(4, 0.9184832)\n",
      "(4, 0.9339706)\n",
      "(4, 0.9376759)\n",
      "(4, 0.94422007)\n",
      "(4, 0.9459247)\n",
      "(4, 0.9492368)\n",
      "(4, 0.94679636)\n",
      "(4, 0.9425205)\n",
      "(4, 0.935397)\n",
      "(4, 0.92095286)\n",
      "(4, 0.8708529)\n",
      "(4, 0.70316005)\n",
      "(4, 0.2899245)\n",
      "(3, 0.52260697)\n",
      "(3, 0.72587276)\n",
      "(3, 0.7779061)\n",
      "(5, 0.50216424)\n",
      "(5, 0.9868199)\n",
      "(5, 0.99893385)\n",
      "(5, 0.99948066)\n",
      "(5, 0.9995216)\n",
      "(5, 0.9995285)\n",
      "(5, 0.99952257)\n",
      "(5, 0.999495)\n",
      "(5, 0.99949384)\n",
      "(5, 0.99949443)\n",
      "(5, 0.999506)\n",
      "(5, 0.9995109)\n",
      "(5, 0.9995122)\n",
      "(5, 0.9995208)\n",
      "(5, 0.9995436)\n",
      "(5, 0.9995504)\n",
      "(5, 0.99955434)\n",
      "(5, 0.9995511)\n",
      "(5, 0.9995433)\n",
      "(5, 0.99953973)\n",
      "(5, 0.99948114)\n",
      "(5, 0.9993228)\n",
      "(5, 0.99884546)\n",
      "(5, 0.9970458)\n",
      "(5, 0.98478806)\n",
      "(5, 0.90779)\n",
      "(5, 0.65915877)\n",
      "(3, 0.8422366)\n",
      "(3, 0.9591807)\n",
      "(3, 0.9706179)\n",
      "(3, 0.95240533)\n",
      "(3, 0.9340595)\n",
      "(3, 0.9238278)\n",
      "(3, 0.9220471)\n",
      "(3, 0.8049475)\n",
      "(2, 0.4189451)\n",
      "(3, 0.3858271)\n",
      "(3, 0.4126891)\n",
      "(3, 0.36744112)\n",
      "(3, 0.26899686)\n",
      "(4, 0.17607751)\n",
      "(9, 0.19897243)\n",
      "(2, 0.207076)\n",
      "(9, 0.23613837)\n",
      "(9, 0.36523584)\n",
      "(9, 0.4057923)\n",
      "(9, 0.45509097)\n",
      "(9, 0.48269725)\n",
      "(9, 0.54281443)\n",
      "(9, 0.68177694)\n",
      "(9, 0.85555995)\n",
      "(9, 0.93472904)\n",
      "(9, 0.9430445)\n",
      "(9, 0.9192875)\n",
      "(9, 0.8786847)\n",
      "(9, 0.8340415)\n",
      "(9, 0.8285094)\n",
      "(9, 0.82973456)\n",
      "(9, 0.8195861)\n",
      "(9, 0.7737411)\n",
      "(9, 0.74543834)\n",
      "(9, 0.74488056)\n",
      "(9, 0.76527923)\n",
      "(9, 0.80101806)\n",
      "(9, 0.7857559)\n",
      "(9, 0.7209705)\n",
      "(9, 0.7117656)\n",
      "(9, 0.6578961)\n",
      "(9, 0.5458805)\n",
      "(9, 0.4966647)\n",
      "(1, 0.98999095)\n",
      "(1, 0.99980897)\n",
      "(1, 0.9999273)\n",
      "(1, 0.9998809)\n",
      "(1, 0.9996815)\n",
      "(1, 0.996488)\n",
      "(1, 0.92801315)\n",
      "(1, 0.27649236)\n",
      "(2, 0.36101583)\n",
      "(2, 0.49785224)\n",
      "(2, 0.5712886)\n",
      "(2, 0.47250527)\n",
      "(2, 0.38176945)\n",
      "(4, 0.4073618)\n",
      "(4, 0.41320196)\n",
      "(4, 0.31245628)\n",
      "(9, 0.36759335)\n",
      "(9, 0.7412527)\n",
      "(9, 0.77607393)\n",
      "(9, 0.72848964)\n",
      "(9, 0.71676713)\n",
      "(9, 0.71265674)\n",
      "(9, 0.7120927)\n",
      "(9, 0.7130257)\n",
      "(9, 0.71400464)\n",
      "(9, 0.71524864)\n",
      "(9, 0.71901345)\n",
      "(9, 0.7239861)\n",
      "(9, 0.73096037)\n",
      "(9, 0.7387818)\n",
      "(9, 0.7448279)\n",
      "(9, 0.74691546)\n",
      "(9, 0.74056506)\n",
      "(9, 0.72824126)\n",
      "(9, 0.708759)\n",
      "(9, 0.70401955)\n",
      "(9, 0.67501026)\n",
      "(9, 0.6357348)\n",
      "(9, 0.6330118)\n",
      "(9, 0.628147)\n",
      "(9, 0.6785882)\n",
      "(9, 0.7468644)\n",
      "(9, 0.82086235)\n",
      "(9, 0.82955295)\n",
      "(9, 0.8297048)\n",
      "(9, 0.50999004)\n",
      "(4, 0.889746)\n",
      "(4, 0.96649754)\n",
      "(4, 0.9553127)\n",
      "(4, 0.7260155)\n",
      "(4, 0.72630256)\n",
      "(4, 0.67146575)\n",
      "(4, 0.7432243)\n",
      "(4, 0.8224814)\n",
      "(4, 0.8430152)\n",
      "(4, 0.7864824)\n",
      "(4, 0.6736511)\n",
      "(4, 0.6648218)\n",
      "(4, 0.63536173)\n",
      "(4, 0.6664412)\n",
      "(4, 0.6104071)\n",
      "(4, 0.55804574)\n",
      "(4, 0.6123672)\n",
      "(4, 0.71607465)\n",
      "(4, 0.77403355)\n",
      "(4, 0.8631476)\n",
      "(4, 0.875559)\n",
      "(4, 0.87387484)\n",
      "(4, 0.83409506)\n",
      "(4, 0.7248447)\n",
      "(4, 0.550729)\n",
      "(4, 0.3914292)\n",
      "(5, 0.44215584)\n",
      "(5, 0.4951569)\n",
      "(5, 0.5350641)\n",
      "(5, 0.53820753)\n",
      "(5, 0.6019116)\n",
      "(5, 0.6848714)\n",
      "(5, 0.7141454)\n",
      "(5, 0.68458134)\n",
      "(5, 0.5174121)\n",
      "(4, 0.58483845)\n",
      "(4, 0.7220666)\n",
      "(4, 0.7917713)\n",
      "(4, 0.7810046)\n",
      "(4, 0.7097523)\n",
      "(4, 0.6384968)\n",
      "(4, 0.65743655)\n",
      "(4, 0.66625166)\n",
      "(4, 0.71672267)\n",
      "(4, 0.68331915)\n",
      "(4, 0.61490816)\n",
      "(4, 0.52293724)\n",
      "(4, 0.4124135)\n",
      "(5, 0.48639977)\n",
      "(5, 0.5334335)\n",
      "(5, 0.50030375)\n",
      "(5, 0.4481872)\n",
      "(5, 0.48948348)\n",
      "(5, 0.5636059)\n",
      "(5, 0.5741821)\n",
      "(5, 0.53911513)\n",
      "(4, 0.45755213)\n",
      "(4, 0.5315989)\n",
      "(4, 0.5224129)\n",
      "(4, 0.46841922)\n",
      "(4, 0.39228162)\n",
      "(4, 0.33613414)\n",
      "(9, 0.35876817)\n",
      "(9, 0.3741767)\n",
      "(4, 0.41606197)\n",
      "(4, 0.5095631)\n",
      "(4, 0.65064526)\n",
      "(4, 0.7322637)\n",
      "(4, 0.7265835)\n",
      "(4, 0.82437295)\n",
      "(4, 0.8999196)\n",
      "(4, 0.9484481)\n",
      "(4, 0.96218944)\n",
      "(4, 0.95063835)\n",
      "(4, 0.87316674)\n",
      "(6, 0.5150593)\n",
      "(6, 0.8499648)\n",
      "(6, 0.9272004)\n",
      "(6, 0.93422854)\n",
      "(6, 0.89350307)\n",
      "(6, 0.816486)\n",
      "(6, 0.6337242)\n",
      "(6, 0.41475603)\n",
      "(3, 0.5015826)\n",
      "(4, 0.404914)\n",
      "(4, 0.7042131)\n",
      "(4, 0.69818777)\n",
      "(4, 0.6761054)\n",
      "(4, 0.65491873)\n",
      "(4, 0.6213142)\n",
      "(4, 0.5044541)\n",
      "(4, 0.3728418)\n",
      "(5, 0.35418123)\n",
      "(5, 0.5114922)\n",
      "(5, 0.60252386)\n",
      "(5, 0.6338894)\n",
      "(5, 0.5670381)\n",
      "(5, 0.5378937)\n",
      "(5, 0.57079446)\n",
      "(5, 0.6143979)\n",
      "(5, 0.6773148)\n",
      "(5, 0.6949525)\n",
      "(5, 0.68355596)\n",
      "(5, 0.64533466)\n",
      "(5, 0.5941766)\n",
      "(5, 0.5267722)\n",
      "(5, 0.48392493)\n",
      "(5, 0.4934397)\n",
      "(5, 0.49830905)\n",
      "(5, 0.43049264)\n",
      "(0, 0.5551674)\n",
      "(0, 0.8044788)\n",
      "(0, 0.8731399)\n",
      "(0, 0.85288566)\n",
      "(0, 0.8320201)\n",
      "(0, 0.8453391)\n",
      "(0, 0.8586582)\n",
      "(0, 0.805721)\n",
      "(0, 0.5775562)\n",
      "(5, 0.5365511)\n",
      "(5, 0.74010456)\n",
      "(5, 0.8048768)\n",
      "(5, 0.81545216)\n",
      "(5, 0.8124527)\n",
      "(5, 0.8066008)\n",
      "(5, 0.7980572)\n",
      "(5, 0.78332955)\n",
      "(5, 0.7705165)\n",
      "(5, 0.7683796)\n",
      "(5, 0.77164674)\n",
      "(5, 0.77442527)\n",
      "(5, 0.7773133)\n",
      "(5, 0.78464544)\n",
      "(5, 0.7839691)\n",
      "(5, 0.7834543)\n",
      "(5, 0.78247786)\n",
      "(5, 0.7838492)\n",
      "(5, 0.79273266)\n",
      "(5, 0.80171645)\n",
      "(5, 0.8164245)\n",
      "(5, 0.8323591)\n",
      "(5, 0.8323585)\n",
      "(5, 0.8157805)\n",
      "(5, 0.7884999)\n",
      "(5, 0.75337005)\n",
      "(5, 0.71682554)\n",
      "(5, 0.69441855)\n",
      "(5, 0.69000584)\n",
      "(5, 0.6947338)\n",
      "(5, 0.59088874)\n",
      "(2, 0.7677924)\n",
      "(2, 0.9763283)\n",
      "(2, 0.9964535)\n",
      "(2, 0.99890625)\n",
      "(2, 0.9995828)\n",
      "(2, 0.99968517)\n",
      "(2, 0.9996971)\n",
      "(2, 0.9997173)\n",
      "(2, 0.99973875)\n",
      "(2, 0.9996295)\n",
      "(2, 0.99937254)\n",
      "(2, 0.99893636)\n",
      "(2, 0.9979329)\n",
      "(2, 0.9958658)\n",
      "(2, 0.9910746)\n",
      "(2, 0.9883272)\n",
      "(2, 0.9948264)\n",
      "(2, 0.99845254)\n",
      "(2, 0.99968624)\n",
      "(2, 0.99989974)\n",
      "(2, 0.99995196)\n",
      "(2, 0.99996173)\n",
      "(2, 0.9999653)\n",
      "(2, 0.9999652)\n",
      "(2, 0.999956)\n",
      "(2, 0.99992836)\n",
      "(2, 0.9997514)\n",
      "(2, 0.9964474)\n",
      "(2, 0.9966814)\n",
      "(2, 0.9969887)\n",
      "(2, 0.9960496)\n",
      "(2, 0.9929086)\n",
      "(2, 0.9887239)\n",
      "(2, 0.9797794)\n",
      "(2, 0.96549124)\n",
      "(2, 0.9626667)\n",
      "(2, 0.95276207)\n",
      "(2, 0.9396395)\n",
      "(2, 0.88583463)\n",
      "(2, 0.7363169)\n",
      "(2, 0.57647294)\n",
      "(2, 0.4634765)\n",
      "(6, 0.51747453)\n",
      "(6, 0.59136444)\n",
      "(6, 0.58863866)\n",
      "(6, 0.4933966)\n",
      "(2, 0.54794157)\n",
      "(2, 0.6021581)\n",
      "(2, 0.6571742)\n",
      "(2, 0.6763408)\n",
      "(2, 0.6932562)\n",
      "(2, 0.7024985)\n",
      "(2, 0.7511092)\n",
      "(2, 0.7976119)\n",
      "(2, 0.8542712)\n",
      "(2, 0.9161329)\n",
      "(2, 0.94745946)\n",
      "(2, 0.9503879)\n",
      "(2, 0.8725718)\n",
      "(2, 0.40272164)\n",
      "(4, 0.35047942)\n",
      "(4, 0.48889968)\n",
      "(4, 0.5593109)\n",
      "(4, 0.41483888)\n",
      "(6, 0.66667783)\n",
      "(6, 0.7951269)\n",
      "(6, 0.72655827)\n",
      "(6, 0.66824096)\n",
      "(2, 0.6262488)\n",
      "(2, 0.94408053)\n",
      "(2, 0.9878749)\n",
      "(2, 0.9894187)\n",
      "(2, 0.9759296)\n",
      "(2, 0.66959316)\n",
      "(2, 0.6020446)\n",
      "(2, 0.797674)\n",
      "(2, 0.95126516)\n",
      "(2, 0.96724665)\n",
      "(2, 0.96940136)\n",
      "(2, 0.95238835)\n",
      "(2, 0.7866829)\n",
      "(6, 0.35329124)\n",
      "(6, 0.5553191)\n",
      "(6, 0.6399357)\n",
      "(6, 0.65715206)\n",
      "(6, 0.60091364)\n",
      "(6, 0.5708719)\n",
      "(6, 0.4989607)\n",
      "(6, 0.4329105)\n",
      "(3, 0.4370979)\n",
      "(6, 0.41861248)\n",
      "(6, 0.44366693)\n",
      "(6, 0.4733376)\n",
      "(6, 0.47769722)\n",
      "(6, 0.45255467)\n",
      "(6, 0.44659403)\n",
      "(3, 0.47197446)\n",
      "(3, 0.56614465)\n",
      "(3, 0.6451209)\n",
      "(3, 0.7174675)\n",
      "(3, 0.79109377)\n",
      "(3, 0.77905846)\n",
      "(3, 0.7191656)\n",
      "(3, 0.6569671)\n",
      "(3, 0.5722447)\n",
      "(3, 0.5472525)\n",
      "(3, 0.52672434)\n",
      "(3, 0.5489616)\n",
      "(3, 0.58132726)\n",
      "(3, 0.65875983)\n",
      "(3, 0.70026153)\n",
      "(3, 0.7019353)\n",
      "(3, 0.69376796)\n",
      "(3, 0.6324331)\n",
      "(3, 0.570491)\n",
      "(3, 0.4826219)\n",
      "(6, 0.4572492)\n",
      "(6, 0.491994)\n",
      "(6, 0.533405)\n",
      "(6, 0.5251583)\n",
      "(6, 0.50216)\n",
      "(6, 0.5055842)\n",
      "(6, 0.55068463)\n",
      "(6, 0.5791502)\n",
      "(6, 0.61788976)\n",
      "(6, 0.5812617)\n",
      "(6, 0.56940436)\n",
      "(6, 0.6068003)\n",
      "(6, 0.6475753)\n",
      "(6, 0.6815774)\n",
      "(6, 0.71646965)\n",
      "(6, 0.72425824)\n",
      "(6, 0.727503)\n",
      "(6, 0.7378206)\n",
      "(6, 0.74735594)\n",
      "(6, 0.76534694)\n",
      "(6, 0.80073243)\n",
      "(6, 0.843375)\n",
      "(6, 0.8807101)\n",
      "(6, 0.9127496)\n",
      "(6, 0.9191415)\n",
      "(6, 0.93135095)\n",
      "(6, 0.9521044)\n",
      "(6, 0.9479994)\n",
      "(6, 0.9457966)\n",
      "(6, 0.9308953)\n",
      "(6, 0.9144144)\n",
      "(6, 0.9056272)\n",
      "(6, 0.8088797)\n",
      "(6, 0.8172422)\n",
      "(6, 0.7917102)\n",
      "(6, 0.82108784)\n",
      "(6, 0.84531015)\n",
      "(6, 0.852841)\n",
      "(6, 0.8539041)\n",
      "(6, 0.8748459)\n",
      "(6, 0.88011664)\n",
      "(6, 0.89221174)\n",
      "(6, 0.90608174)\n",
      "(6, 0.92747205)\n",
      "(6, 0.94312096)\n",
      "(6, 0.9316955)\n",
      "(6, 0.87444454)\n",
      "(6, 0.62882423)\n",
      "(3, 0.6914675)\n",
      "(3, 0.7491326)\n",
      "(3, 0.70647633)\n",
      "(3, 0.680554)\n",
      "(3, 0.703191)\n",
      "(3, 0.595002)\n",
      "(3, 0.51788723)\n",
      "(3, 0.4789004)\n",
      "(6, 0.4673517)\n",
      "(6, 0.49777606)\n",
      "(6, 0.5637518)\n",
      "(6, 0.53073114)\n",
      "(6, 0.45305353)\n",
      "(3, 0.5792322)\n",
      "(3, 0.63217795)\n",
      "(3, 0.65743595)\n",
      "(3, 0.5799852)\n",
      "(3, 0.5056949)\n",
      "(6, 0.55643797)\n",
      "(6, 0.7003083)\n",
      "(6, 0.79382634)\n",
      "(6, 0.82730323)\n",
      "(6, 0.864274)\n",
      "(6, 0.8880968)\n",
      "(6, 0.9144725)\n",
      "(6, 0.9000491)\n",
      "(6, 0.8805978)\n",
      "(6, 0.85673803)\n",
      "(6, 0.82590103)\n",
      "(6, 0.8118982)\n",
      "(6, 0.8054197)\n",
      "(6, 0.8508566)\n",
      "(6, 0.9099643)\n",
      "(6, 0.9456072)\n",
      "(6, 0.9662075)\n",
      "(6, 0.97757757)\n",
      "(6, 0.9850301)\n",
      "(6, 0.98712486)\n",
      "(6, 0.98776907)\n",
      "(6, 0.9890865)\n",
      "(6, 0.98980623)\n",
      "(6, 0.9897943)\n",
      "(6, 0.9903667)\n",
      "(6, 0.99048597)\n",
      "(6, 0.9889127)\n",
      "(6, 0.9854248)\n",
      "(6, 0.9757211)\n",
      "(6, 0.9627317)\n",
      "(6, 0.9643627)\n",
      "(6, 0.96657884)\n",
      "(6, 0.9643914)\n",
      "(6, 0.9692091)\n",
      "(6, 0.9788488)\n",
      "(6, 0.98132265)\n",
      "(6, 0.98386186)\n",
      "(6, 0.98615545)\n",
      "(6, 0.9877095)\n",
      "(6, 0.9878399)\n",
      "(6, 0.98527724)\n",
      "(6, 0.981356)\n",
      "(6, 0.9727163)\n",
      "(6, 0.9417587)\n",
      "(6, 0.81237686)\n",
      "(6, 0.32882228)\n",
      "(4, 0.63944167)\n",
      "(4, 0.70796824)\n",
      "(4, 0.74900454)\n",
      "(4, 0.7665848)\n",
      "(4, 0.66802746)\n",
      "(4, 0.44094637)\n",
      "(6, 0.6625037)\n",
      "(6, 0.81078565)\n",
      "(6, 0.84884346)\n",
      "(6, 0.8816482)\n",
      "(6, 0.8984764)\n",
      "(6, 0.8978296)\n",
      "(6, 0.9264561)\n",
      "(6, 0.9472397)\n",
      "(6, 0.9542102)\n",
      "(6, 0.9594222)\n",
      "(6, 0.96357375)\n",
      "(6, 0.97458243)\n",
      "(6, 0.98511475)\n",
      "(6, 0.9879144)\n",
      "(6, 0.99161583)\n",
      "(6, 0.9923356)\n",
      "(6, 0.9912293)\n",
      "(6, 0.99188375)\n",
      "(6, 0.9910885)\n",
      "(6, 0.99236506)\n",
      "(6, 0.9920546)\n",
      "(6, 0.9912633)\n",
      "(6, 0.9918251)\n",
      "(6, 0.99222285)\n",
      "(6, 0.9927592)\n",
      "(6, 0.9930824)\n",
      "(6, 0.99316424)\n",
      "(6, 0.9932255)\n",
      "(6, 0.99331445)\n",
      "(6, 0.993356)\n",
      "(6, 0.9933646)\n",
      "(6, 0.9929304)\n",
      "(6, 0.9868367)\n",
      "(6, 0.9928053)\n",
      "(6, 0.9884487)\n",
      "(6, 0.9935947)\n",
      "(6, 0.9946431)\n",
      "(6, 0.9936168)\n",
      "(6, 0.9937425)\n",
      "(6, 0.99318004)\n",
      "(6, 0.992078)\n",
      "(6, 0.9898992)\n",
      "(6, 0.98473597)\n",
      "(6, 0.9613187)\n",
      "(6, 0.7593444)\n",
      "(6, 0.8624045)\n",
      "(6, 0.9291556)\n",
      "(6, 0.96251047)\n",
      "(6, 0.97699535)\n",
      "(6, 0.9808334)\n",
      "(6, 0.98309004)\n",
      "(6, 0.985092)\n",
      "(6, 0.9871481)\n",
      "(6, 0.9881315)\n",
      "(6, 0.9887839)\n",
      "(6, 0.98955005)\n",
      "(6, 0.99004644)\n",
      "(6, 0.98964816)\n",
      "(6, 0.98826784)\n",
      "(6, 0.9857987)\n",
      "(6, 0.9801026)\n",
      "(6, 0.96322256)\n",
      "(6, 0.87757903)\n",
      "(6, 0.5019503)\n",
      "(4, 0.632456)\n",
      "(4, 0.59976584)\n",
      "(4, 0.5920935)\n",
      "(4, 0.6242155)\n",
      "(4, 0.64855164)\n",
      "(4, 0.66569597)\n",
      "(4, 0.7214445)\n",
      "(4, 0.79607487)\n",
      "(4, 0.78769386)\n",
      "(4, 0.7548186)\n",
      "(4, 0.6828827)\n",
      "(4, 0.53494626)\n",
      "(4, 0.43310696)\n",
      "(6, 0.80956334)\n",
      "(6, 0.6548514)\n",
      "(6, 0.6087188)\n",
      "(4, 0.47962508)\n",
      "(4, 0.76854366)\n",
      "(4, 0.6620236)\n",
      "(6, 0.47687805)\n",
      "(6, 0.810267)\n",
      "(6, 0.90854883)\n",
      "(6, 0.9467244)\n",
      "(6, 0.96218216)\n",
      "(6, 0.9707583)\n",
      "(6, 0.9766084)\n",
      "(6, 0.977707)\n",
      "(6, 0.9779668)\n",
      "(6, 0.9733078)\n",
      "(6, 0.97169805)\n",
      "(6, 0.9742697)\n",
      "(6, 0.97658986)\n",
      "(6, 0.9742056)\n",
      "(6, 0.9728784)\n",
      "(6, 0.97342694)\n",
      "(6, 0.9734321)\n",
      "(6, 0.9715784)\n",
      "(6, 0.97022015)\n",
      "(6, 0.9663517)\n",
      "(6, 0.9579165)\n",
      "(6, 0.94845873)\n",
      "(6, 0.9275448)\n",
      "(6, 0.8623197)\n",
      "(6, 0.8122842)\n",
      "(6, 0.7438647)\n",
      "(6, 0.7501357)\n",
      "(6, 0.8559588)\n",
      "(6, 0.9051634)\n",
      "(6, 0.9397477)\n",
      "(6, 0.9554113)\n",
      "(6, 0.96394587)\n",
      "(6, 0.9604735)\n",
      "(6, 0.9591739)\n",
      "(6, 0.9629217)\n",
      "(6, 0.96337456)\n",
      "(6, 0.95806235)\n",
      "(6, 0.95315105)\n",
      "(6, 0.94448227)\n",
      "(6, 0.9342245)\n",
      "(6, 0.91419566)\n",
      "(6, 0.9374985)\n",
      "(6, 0.95478475)\n",
      "(6, 0.9646883)\n",
      "(6, 0.9685098)\n",
      "(6, 0.9708453)\n",
      "(6, 0.9658617)\n",
      "(6, 0.9598388)\n",
      "(6, 0.9423849)\n",
      "(6, 0.8696883)\n",
      "(6, 0.7064228)\n",
      "(4, 0.6234838)\n",
      "(4, 0.8304285)\n",
      "(4, 0.8210308)\n",
      "(4, 0.7493388)\n",
      "(4, 0.64548707)\n",
      "(4, 0.8505911)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T23:29:08.569984Z",
     "start_time": "2024-10-15T23:29:07.811875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##         V2 CONTINUOUS PREDICTION WITH SLIDING WINDOW           ##\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Parameters for video feed and predictions\n",
    "show_landmarks = True  # Toggle to show hand landmarks\n",
    "show_connections = True  # Toggle to show landmark connections\n",
    "show_prediction_text = True  # Toggle to show prediction and accuracy on screen\n",
    "accuracy_threshold = 0.7  # Threshold for highlighting low accuracy\n",
    "sliding_window_size = 10  # Size of the sliding window for prediction\n",
    "smoothing_buffer_size = 5  # Buffer size for prediction smoothing (larger = smoother)\n",
    "mediapipe_confidence = 0.7  # Confidence threshold for mediapipe detection\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('handsigns_model.h5')\n",
    "\n",
    "# Initialize MediaPipe hands and pose solutions\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "hands = mp_hands.Hands(min_detection_confidence=mediapipe_confidence, min_tracking_confidence=mediapipe_confidence)\n",
    "pose = mp_pose.Pose(min_detection_confidence=mediapipe_confidence, min_tracking_confidence=mediapipe_confidence)\n",
    "\n",
    "# Set up sliding window and smoothing buffer\n",
    "sliding_window = deque(maxlen=sliding_window_size)\n",
    "smoothing_buffer = deque(maxlen=smoothing_buffer_size)\n",
    "\n",
    "# Initialize video capture (webcam)\n",
    "cap = cv2.VideoCapture(1)\n",
    "last_handedness = {'Left': False, 'Right': False}\n",
    "\n",
    "# Function to smooth predictions\n",
    "def smooth_predictions(predictions):\n",
    "    if len(predictions) > 0:\n",
    "        return np.mean(predictions, axis=0)\n",
    "    return np.zeros(num_handsigns)\n",
    "\n",
    "# Main loop for video feed and prediction\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    #frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Process frame to extract landmarks and results\n",
    "    landmarks, last_handedness = process_frame(frame, hands, pose, last_handedness)\n",
    "    hands_results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    pose_results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Append the landmarks to the sliding window\n",
    "    sliding_window.append(landmarks)\n",
    "    \n",
    "    # Check if the sliding window is full\n",
    "    if len(sliding_window) == sliding_window_size:\n",
    "        # Prepare input for the model (reshape and normalize)\n",
    "        input_data = np.array(sliding_window).reshape(1, sliding_window_size, num_landmarks, num_coordinates)\n",
    "        \n",
    "        # Predict the hand sign\n",
    "        predictions = model.predict(input_data)\n",
    "        prediction = np.argmax(predictions)\n",
    "        confidence = np.max(predictions)\n",
    "        \n",
    "        # Add the prediction to the smoothing buffer\n",
    "        smoothing_buffer.append(predictions)\n",
    "        smoothed_predictions = smooth_predictions(smoothing_buffer)\n",
    "        smoothed_prediction = np.argmax(smoothed_predictions)\n",
    "        smoothed_confidence = np.max(smoothed_predictions)\n",
    "\n",
    "        # Display prediction on screen if enabled\n",
    "        if show_prediction_text:\n",
    "            text = f\"Sign: {handsign_names[smoothed_prediction]}, Accuracy: {smoothed_confidence:.2f}\"\n",
    "            if smoothed_confidence < accuracy_threshold:\n",
    "                text += \" (Low accuracy)\"\n",
    "            cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Draw landmarks if enabled\n",
    "    if show_landmarks and hands_results.multi_hand_landmarks:\n",
    "        for hand_landmarks in hands_results.multi_hand_landmarks:\n",
    "            if show_connections:\n",
    "                mp.solutions.drawing_utils.draw_landmarks(\n",
    "                    frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            else:\n",
    "                mp.solutions.drawing_utils.draw_landmarks(frame, hand_landmarks)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Hand Sign Recognition', frame)\n",
    "\n",
    "    # Break the loop with 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ],
   "id": "41e6691dae6fe336",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "process_frame() takes 1 positional argument but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 49\u001B[0m\n\u001B[0;32m     45\u001B[0m frame \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mrotate(frame, cv2\u001B[38;5;241m.\u001B[39mROTATE_90_CLOCKWISE)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m#frame = cv2.flip(frame, 1)\u001B[39;00m\n\u001B[0;32m     47\u001B[0m \n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Process frame to extract landmarks and results\u001B[39;00m\n\u001B[1;32m---> 49\u001B[0m landmarks, last_handedness \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhands\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlast_handedness\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m hands_results \u001B[38;5;241m=\u001B[39m hands\u001B[38;5;241m.\u001B[39mprocess(cv2\u001B[38;5;241m.\u001B[39mcvtColor(frame, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2RGB))\n\u001B[0;32m     51\u001B[0m pose_results \u001B[38;5;241m=\u001B[39m pose\u001B[38;5;241m.\u001B[39mprocess(cv2\u001B[38;5;241m.\u001B[39mcvtColor(frame, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2RGB))\n",
      "\u001B[1;31mTypeError\u001B[0m: process_frame() takes 1 positional argument but 4 were given"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "##          MODEL TESTING          ##\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_and_preprocess_test_data(test_data_path):\n",
    "    # Reuse the process_dataset function\n",
    "    test_data = process_dataset(test_data_path)\n",
    "    \n",
    "    # Reshape the data to match the model input shape\n",
    "    X_test = test_data.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "    y_test = np.repeat(np.arange(num_handsigns), videos_per_handsign)\n",
    "    \n",
    "    return X_test, y_test\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Generate classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_classes))\n",
    "    \n",
    "    return y_pred_classes\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_misclassifications(X_test, y_test, y_pred, num_samples=5):\n",
    "    misclassified = np.where(y_test != y_pred)[0]\n",
    "    np.random.shuffle(misclassified)\n",
    "    \n",
    "    for i in range(min(num_samples, len(misclassified))):\n",
    "        idx = misclassified[i]\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Plot a representation of the hand sign (e.g., first frame landmarks)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(X_test[idx, 0, :, 0], X_test[idx, 0, :, 1])\n",
    "        plt.title(f\"True: {y_test[idx]}, Predicted: {y_pred[idx]}\")\n",
    "        plt.xlabel(\"X coordinate\")\n",
    "        plt.ylabel(\"Y coordinate\")\n",
    "        \n",
    "        # Plot the confidence scores for each class\n",
    "        plt.subplot(1, 2, 2)\n",
    "        confidence_scores = model.predict(X_test[idx:idx+1])[0]\n",
    "        plt.bar(range(num_handsigns), confidence_scores)\n",
    "        plt.title(\"Confidence Scores\")\n",
    "        plt.xlabel(\"Hand Sign Class\")\n",
    "        plt.ylabel(\"Confidence\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model('handsigns_model.h5')\n",
    "    \n",
    "    # Load and preprocess test data\n",
    "    test_data_path = \"Model testing videos\"  # Replace with your test dataset path\n",
    "    X_test, y_test = load_and_preprocess_test_data(test_data_path)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Visualize some misclassifications\n",
    "    visualize_misclassifications(X_test, y_test, y_pred)"
   ],
   "id": "67b4c8b4c4f1ca0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "819a4814bfc8aec8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
