{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T02:10:05.527253Z",
     "start_time": "2024-10-11T02:10:05.521970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          DATA SHAPE DEFINITION           ##\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define the parameters for the data shape\n",
    "videos_per_handsign = 136  # Adjust if necessary\n",
    "frames_per_video = 8\n",
    "num_landmarks = 51\n",
    "num_coordinates = 3\n",
    "\n",
    "data_augmentation = True\n",
    "num_augmented_versions = 4  # How many videos will be created from augmenting each video from the dataset\n",
    "\n",
    "# Define the root directory containing handsign folders\n",
    "root_path = \"ACOTADONomenclatedDataset\"\n",
    "\n",
    "def get_handsign_folders(root_path):\n",
    "    handsign_names = {}\n",
    "    handsign_count = 0\n",
    "    \n",
    "    # Walk through the root directory\n",
    "    for folder in os.listdir(root_path):\n",
    "        folder_path = os.path.join(root_path, folder)\n",
    "        \n",
    "        # Ignore non-directories\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # If the folder starts with \"#\", check its subdirectories\n",
    "        if folder.startswith(\"#\"):\n",
    "            for subfolder in os.listdir(folder_path):\n",
    "                subfolder_path = os.path.join(folder_path, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    handsign_names[handsign_count] = subfolder\n",
    "                    handsign_count += 1\n",
    "        else:\n",
    "            # Directly add the folder as a handsign\n",
    "            handsign_names[handsign_count] = folder\n",
    "            handsign_count += 1\n",
    "    \n",
    "    return handsign_names\n",
    "\n",
    "# Get the handsign names automatically\n",
    "handsign_names = get_handsign_folders(root_path)\n",
    "num_handsigns = len(handsign_names)\n",
    "\n",
    "# Output the handsign names and number of handsigns\n",
    "print(f\"Number of handsigns: {num_handsigns}\")\n",
    "print(\"Handsign names:\")\n",
    "print(json.dumps(handsign_names, indent=4))"
   ],
   "id": "823e51359a2141fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of handsigns: 4\n",
      "Handsign names:\n",
      "{\n",
      "    \"0\": \"apellido\",\n",
      "    \"1\": \"C\",\n",
      "    \"2\": \"cumplea\\u00f1os\",\n",
      "    \"3\": \"mujer\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T02:10:11.188453Z",
     "start_time": "2024-10-11T02:10:11.178348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# Generate dummy data\n",
    "data = [np.random.rand(videos_per_handsign, frames_per_video, num_landmarks, num_coordinates) for _ in range(num_handsigns)]\n",
    "\n",
    "# Convert the list to a numpy array with shape (num_handsigns, videos_per_handsign, frames_per_video, num_landmarks, num_coordinates)\n",
    "data_array = np.array(data)\n",
    "\n",
    "# Save the data array to a .npy file\n",
    "np.save('handsigns_data.npy', data_array)"
   ],
   "id": "fa59d6b8b575718a",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T02:10:14.826963Z",
     "start_time": "2024-10-11T02:10:14.815042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          PROCESS VIDEO DATASET FUNC DEFINITIONS         ##\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "def extract_landmarks(hands_results, pose_results, last_handedness):\n",
    "    landmarks = []\n",
    "\n",
    "    try:\n",
    "        nose_landmark = pose_results.pose_landmarks.landmark[0]  # all landmarks are relative to the nose\n",
    "    except:\n",
    "        class nose_landmark:\n",
    "            x = 0\n",
    "            y = 0\n",
    "            z = 0\n",
    "        nose_landmark = nose_landmark()\n",
    "\n",
    "    # Initialize placeholders for left and right hand landmarks\n",
    "    left_hand_landmarks = [(0, 0, 0)] * 21\n",
    "    right_hand_landmarks = [(0, 0, 0)] * 21\n",
    "\n",
    "    # Extract hand landmarks with handedness labeling\n",
    "    if hands_results.multi_hand_landmarks and hands_results.multi_handedness:\n",
    "        for i, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):\n",
    "            label = hands_results.multi_handedness[i].classification[0].label  # 'Left' or 'Right'\n",
    "            \n",
    "            if label == 'Left':\n",
    "                left_hand_landmarks = [(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) for lm in hand_landmarks.landmark]\n",
    "                last_handedness['Left'] = True  # Mark the left hand as active\n",
    "            elif label == 'Right':\n",
    "                right_hand_landmarks = [(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) for lm in hand_landmarks.landmark]\n",
    "                last_handedness['Right'] = True  # Mark the right hand as active\n",
    "\n",
    "    # If one hand goes offscreen, attempt to use the last known handedness\n",
    "    if not hands_results.multi_hand_landmarks or len(hands_results.multi_hand_landmarks) < 2:\n",
    "        if not last_handedness.get('Left'):\n",
    "            left_hand_landmarks = [(0, 0, 0)] * 21\n",
    "        if not last_handedness.get('Right'):\n",
    "            right_hand_landmarks = [(0, 0, 0)] * 21\n",
    "\n",
    "    landmarks.extend(left_hand_landmarks)\n",
    "    landmarks.extend(right_hand_landmarks)\n",
    "\n",
    "    # Extract selected body landmarks (9 landmarks)\n",
    "    selected_body_landmarks = [0, 11, 12, 13, 14, 15, 16, 23, 24]  # Landmarks for nose, arms, and shoulders\n",
    "    if pose_results.pose_landmarks:\n",
    "        for idx in selected_body_landmarks:\n",
    "            lm = pose_results.pose_landmarks.landmark[idx]\n",
    "            landmarks.append((lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z))\n",
    "    else:\n",
    "        landmarks.extend([(0, 0, 0)] * 9)\n",
    "\n",
    "    return np.array(landmarks), last_handedness\n",
    "\n",
    "def process_frame(frame, hands, pose, last_handedness):\n",
    "    \"\"\"\n",
    "    This function processes a single frame, extracting the landmarks and ensuring hand consistency.\n",
    "    \"\"\"\n",
    "    # Convert the BGR image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and extract landmarks\n",
    "    hands_results = hands.process(image)\n",
    "    pose_results = pose.process(image)\n",
    "\n",
    "    # Extract landmarks with handedness robustness\n",
    "    landmarks, last_handedness = extract_landmarks(hands_results, pose_results, last_handedness)\n",
    "\n",
    "    return landmarks, last_handedness\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    indices = np.linspace(0, total_frames - 1, frames_per_video, dtype=int)\n",
    "    frame_set = set(indices)\n",
    "    frame_count = 0\n",
    "\n",
    "    last_handedness = {'Left': False, 'Right': False}  # To track which hands are present\n",
    "    \n",
    "    with mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5) as hands, \\\n",
    "         mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        \n",
    "        while cap.isOpened() and len(frames) < frames_per_video:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_count in frame_set:\n",
    "                landmarks, last_handedness = process_frame(frame, hands, pose, last_handedness)  # Track handedness across frames\n",
    "                frames.append(landmarks)\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Pad if we don't have enough frames\n",
    "    if len(frames) < frames_per_video:\n",
    "        frames.extend([np.zeros((num_landmarks, num_coordinates))] * (frames_per_video - len(frames)))\n",
    "\n",
    "    return np.array(frames)\n",
    "\n",
    "def process_dataset(root_path, handsign_names):\n",
    "    data = []\n",
    "    \n",
    "    for handsign_index in tqdm(range(len(handsign_names)), desc=\"Processing handsigns\"):\n",
    "        # Get the handsign folder name from the handsign_names dictionary\n",
    "        handsign_folder = handsign_names[handsign_index]\n",
    "        handsign_path = os.path.join(root_path, handsign_folder)\n",
    "        \n",
    "        if not os.path.exists(handsign_path):\n",
    "            print(f\"Warning: Directory {handsign_path} does not exist. Skipping.\")\n",
    "            data.append(np.zeros((videos_per_handsign, frames_per_video, num_landmarks, num_coordinates)))  # 51 landmarks total\n",
    "            continue\n",
    "        \n",
    "        videos = [f for f in os.listdir(handsign_path) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        videos = videos[:videos_per_handsign]  # Limit to videos_per_handsign\n",
    "        \n",
    "        handsign_data = []\n",
    "        for video in tqdm(videos, desc=f\"Processing videos for handsign {handsign_index}\", leave=False):\n",
    "            video_path = os.path.join(handsign_path, video)\n",
    "            video_data = process_video(video_path)\n",
    "            handsign_data.append(video_data)\n",
    "        \n",
    "        # Pad if we don't have enough videos\n",
    "        if len(handsign_data) < videos_per_handsign:\n",
    "            padding_needed = videos_per_handsign - len(handsign_data)\n",
    "            warnings.warn(f\"Handsign {handsign_index} ('{handsign_folder}') has only {len(handsign_data)} videos. \"\n",
    "                          f\"Padding with {padding_needed} empty videos.\")\n",
    "            handsign_data.extend([np.zeros((frames_per_video, num_landmarks, num_coordinates))] * padding_needed)\n",
    "        \n",
    "        data.append(np.array(handsign_data))\n",
    "    \n",
    "    return np.array(data)\n",
    "\n",
    "\n"
   ],
   "id": "c6b1d3592b943838",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T02:16:09.717509Z",
     "start_time": "2024-10-11T02:10:21.121324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          PROCESS VIDEOS DATASET FUNC CALLING         ##\n",
    "    \n",
    "data_array = process_dataset(root_path, handsign_names)\n",
    "\n",
    "# Save the data array to a .npy file\n",
    "np.save('handsigns_data.npy', data_array)\n",
    "print(\"Data saved to handsigns_data.npy\")\n",
    "    "
   ],
   "id": "38b563f5e5342b66",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing handsigns:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Processing videos for handsign 0:   0%|          | 0/136 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 0:   1%|          | 1/136 [00:01<02:16,  1.01s/it]\u001B[A\n",
      "Processing videos for handsign 0:   1%|▏         | 2/136 [00:01<01:51,  1.20it/s]\u001B[A\n",
      "Processing videos for handsign 0:   2%|▏         | 3/136 [00:02<01:43,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 0:   3%|▎         | 4/136 [00:03<01:43,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 0:   4%|▎         | 5/136 [00:03<01:41,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 0:   4%|▍         | 6/136 [00:04<01:40,  1.30it/s]\u001B[A\n",
      "Processing videos for handsign 0:   5%|▌         | 7/136 [00:05<01:34,  1.36it/s]\u001B[A\n",
      "Processing videos for handsign 0:   6%|▌         | 8/136 [00:06<01:29,  1.43it/s]\u001B[A\n",
      "Processing videos for handsign 0:   7%|▋         | 9/136 [00:06<01:28,  1.44it/s]\u001B[A\n",
      "Processing videos for handsign 0:   7%|▋         | 10/136 [00:07<01:27,  1.44it/s]\u001B[A\n",
      "Processing videos for handsign 0:   8%|▊         | 11/136 [00:08<01:33,  1.33it/s]\u001B[A\n",
      "Processing videos for handsign 0:   9%|▉         | 12/136 [00:09<01:32,  1.35it/s]\u001B[A\n",
      "Processing videos for handsign 0:  10%|▉         | 13/136 [00:09<01:33,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 0:  10%|█         | 14/136 [00:10<01:32,  1.32it/s]\u001B[A\n",
      "Processing videos for handsign 0:  11%|█         | 15/136 [00:11<01:32,  1.30it/s]\u001B[A\n",
      "Processing videos for handsign 0:  12%|█▏        | 16/136 [00:12<01:32,  1.30it/s]\u001B[A\n",
      "Processing videos for handsign 0:  12%|█▎        | 17/136 [00:12<01:31,  1.30it/s]\u001B[A\n",
      "Processing videos for handsign 0:  13%|█▎        | 18/136 [00:13<01:32,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 0:  14%|█▍        | 19/136 [00:14<01:31,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 0:  15%|█▍        | 20/136 [00:15<01:29,  1.30it/s]\u001B[A\n",
      "Processing videos for handsign 0:  15%|█▌        | 21/136 [00:15<01:22,  1.39it/s]\u001B[A\n",
      "Processing videos for handsign 0:  16%|█▌        | 22/136 [00:16<01:22,  1.38it/s]\u001B[A\n",
      "Processing videos for handsign 0:  17%|█▋        | 23/136 [00:17<01:24,  1.34it/s]\u001B[A\n",
      "Processing videos for handsign 0:  18%|█▊        | 24/136 [00:18<01:21,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 0:  18%|█▊        | 25/136 [00:18<01:19,  1.39it/s]\u001B[A\n",
      "Processing videos for handsign 0:  19%|█▉        | 26/136 [00:19<01:21,  1.35it/s]\u001B[A\n",
      "Processing videos for handsign 0:  20%|█▉        | 27/136 [00:20<01:19,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 0:  21%|██        | 28/136 [00:20<01:17,  1.40it/s]\u001B[A\n",
      "Processing videos for handsign 0:  21%|██▏       | 29/136 [00:21<01:18,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 0:  22%|██▏       | 30/136 [00:22<01:19,  1.33it/s]\u001B[A\n",
      "Processing videos for handsign 0:  23%|██▎       | 31/136 [00:23<01:21,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 0:  24%|██▎       | 32/136 [00:24<01:23,  1.25it/s]\u001B[A\n",
      "Processing videos for handsign 0:  24%|██▍       | 33/136 [00:24<01:20,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 0:  25%|██▌       | 34/136 [00:25<01:19,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 0:  26%|██▌       | 35/136 [00:26<01:21,  1.24it/s]\u001B[A\n",
      "Processing videos for handsign 0:  26%|██▋       | 36/136 [00:27<01:21,  1.23it/s]\u001B[A\n",
      "Processing videos for handsign 0:  27%|██▋       | 37/136 [00:28<01:16,  1.30it/s]\u001B[A\n",
      "Processing videos for handsign 0:  28%|██▊       | 38/136 [00:28<01:17,  1.26it/s]\u001B[A\n",
      "Processing videos for handsign 0:  29%|██▊       | 39/136 [00:29<01:14,  1.30it/s]\u001B[A\n",
      "Processing videos for handsign 0:  29%|██▉       | 40/136 [00:30<01:14,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 0:  30%|███       | 41/136 [00:31<01:12,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 0:  31%|███       | 42/136 [00:31<01:10,  1.33it/s]\u001B[A\n",
      "Processing videos for handsign 0:  32%|███▏      | 43/136 [00:32<01:08,  1.36it/s]\u001B[A\n",
      "Processing videos for handsign 0:  32%|███▏      | 44/136 [00:33<01:09,  1.32it/s]\u001B[A\n",
      "Processing videos for handsign 0:  33%|███▎      | 45/136 [00:34<01:07,  1.34it/s]\u001B[A\n",
      "Processing videos for handsign 0:  34%|███▍      | 46/136 [00:34<01:07,  1.34it/s]\u001B[A\n",
      "Processing videos for handsign 0:  35%|███▍      | 47/136 [00:35<01:08,  1.30it/s]\u001B[A\n",
      "Processing videos for handsign 0:  35%|███▌      | 48/136 [00:36<01:07,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 0:  36%|███▌      | 49/136 [00:37<01:05,  1.33it/s]\u001B[A\n",
      "Processing videos for handsign 0:  37%|███▋      | 50/136 [00:37<01:03,  1.35it/s]\u001B[A\n",
      "Processing videos for handsign 0:  38%|███▊      | 51/136 [00:38<01:00,  1.41it/s]\u001B[A\n",
      "Processing videos for handsign 0:  38%|███▊      | 52/136 [00:39<00:56,  1.48it/s]\u001B[A\n",
      "Processing videos for handsign 0:  39%|███▉      | 53/136 [00:39<00:56,  1.47it/s]\u001B[A\n",
      "Processing videos for handsign 0:  40%|███▉      | 54/136 [00:40<00:56,  1.45it/s]\u001B[A\n",
      "Processing videos for handsign 0:  40%|████      | 55/136 [00:41<00:55,  1.45it/s]\u001B[A\n",
      "Processing videos for handsign 0:  41%|████      | 56/136 [00:41<00:53,  1.49it/s]\u001B[A\n",
      "Processing videos for handsign 0:  42%|████▏     | 57/136 [00:42<00:54,  1.44it/s]\u001B[A\n",
      "Processing videos for handsign 0:  43%|████▎     | 58/136 [00:43<00:57,  1.36it/s]\u001B[A\n",
      "Processing videos for handsign 0:  43%|████▎     | 59/136 [00:44<00:55,  1.40it/s]\u001B[A\n",
      "Processing videos for handsign 0:  44%|████▍     | 60/136 [00:44<00:55,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 0:  45%|████▍     | 61/136 [00:45<00:55,  1.36it/s]\u001B[A\n",
      "Processing videos for handsign 0:  46%|████▌     | 62/136 [00:46<00:57,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 0:  46%|████▋     | 63/136 [00:47<00:56,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 0:  47%|████▋     | 64/136 [00:47<00:55,  1.30it/s]\u001B[A\n",
      "Processing videos for handsign 0:  48%|████▊     | 65/136 [00:48<00:53,  1.33it/s]\u001B[A\n",
      "Processing videos for handsign 0:  49%|████▊     | 66/136 [00:49<00:54,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 0:  49%|████▉     | 67/136 [00:50<00:51,  1.33it/s]\u001B[A\n",
      "Processing videos for handsign 0:  50%|█████     | 68/136 [00:50<00:47,  1.42it/s]\u001B[A\n",
      "Processing videos for handsign 0:  51%|█████     | 69/136 [00:51<00:45,  1.48it/s]\u001B[A\n",
      "Processing videos for handsign 0:  51%|█████▏    | 70/136 [00:52<00:46,  1.43it/s]\u001B[A\n",
      "Processing videos for handsign 0:  52%|█████▏    | 71/136 [00:52<00:46,  1.41it/s]\u001B[A\n",
      "Processing videos for handsign 0:  53%|█████▎    | 72/136 [00:53<00:44,  1.45it/s]\u001B[A\n",
      "Processing videos for handsign 0:  54%|█████▎    | 73/136 [00:54<00:45,  1.40it/s]\u001B[A\n",
      "Processing videos for handsign 0:  54%|█████▍    | 74/136 [00:54<00:42,  1.46it/s]\u001B[A\n",
      "Processing videos for handsign 0:  55%|█████▌    | 75/136 [00:55<00:39,  1.53it/s]\u001B[A\n",
      "Processing videos for handsign 0:  56%|█████▌    | 76/136 [00:56<00:43,  1.39it/s]\u001B[A\n",
      "Processing videos for handsign 0:  57%|█████▋    | 77/136 [00:57<00:44,  1.33it/s]\u001B[A\n",
      "Processing videos for handsign 0:  57%|█████▋    | 78/136 [00:58<00:46,  1.25it/s]\u001B[A\n",
      "Processing videos for handsign 0:  58%|█████▊    | 79/136 [00:58<00:46,  1.24it/s]\u001B[A\n",
      "Processing videos for handsign 0:  59%|█████▉    | 80/136 [00:59<00:46,  1.20it/s]\u001B[A\n",
      "Processing videos for handsign 0:  60%|█████▉    | 81/136 [01:00<00:47,  1.16it/s]\u001B[A\n",
      "Processing videos for handsign 0:  60%|██████    | 82/136 [01:01<00:42,  1.26it/s]\u001B[A\n",
      "Processing videos for handsign 0:  61%|██████    | 83/136 [01:02<00:41,  1.27it/s]\u001B[A\n",
      "Processing videos for handsign 0:  62%|██████▏   | 84/136 [01:02<00:40,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 0:  62%|██████▎   | 85/136 [01:03<00:40,  1.26it/s]\u001B[A\n",
      "Processing videos for handsign 0:  63%|██████▎   | 86/136 [01:04<00:39,  1.27it/s]\u001B[A\n",
      "Processing videos for handsign 0:  64%|██████▍   | 87/136 [01:05<00:39,  1.24it/s]\u001B[A\n",
      "Processing videos for handsign 0:  65%|██████▍   | 88/136 [01:05<00:34,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 0:  65%|██████▌   | 89/136 [01:06<00:34,  1.36it/s]\u001B[A\n",
      "Processing videos for handsign 0:  66%|██████▌   | 90/136 [01:07<00:33,  1.36it/s]\u001B[A\n",
      "Processing videos for handsign 0:  67%|██████▋   | 91/136 [01:08<00:35,  1.26it/s]\u001B[A\n",
      "Processing videos for handsign 0:  68%|██████▊   | 92/136 [01:09<00:34,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 0:  68%|██████▊   | 93/136 [01:10<00:34,  1.23it/s]\u001B[A\n",
      "Processing videos for handsign 0:  69%|██████▉   | 94/136 [01:10<00:33,  1.24it/s]\u001B[A\n",
      "Processing videos for handsign 0:  70%|██████▉   | 95/136 [01:11<00:34,  1.20it/s]\u001B[A\n",
      "Processing videos for handsign 0:  71%|███████   | 96/136 [01:12<00:31,  1.25it/s]\u001B[A\n",
      "Processing videos for handsign 0:  71%|███████▏  | 97/136 [01:13<00:31,  1.25it/s]\u001B[A\n",
      "Processing videos for handsign 0:  72%|███████▏  | 98/136 [01:14<00:34,  1.11it/s]\u001B[A\n",
      "Processing videos for handsign 0:  73%|███████▎  | 99/136 [01:15<00:35,  1.04it/s]\u001B[A\n",
      "Processing videos for handsign 0:  74%|███████▎  | 100/136 [01:16<00:33,  1.08it/s]\u001B[A\n",
      "Processing videos for handsign 0:  74%|███████▍  | 101/136 [01:17<00:32,  1.06it/s]\u001B[A\n",
      "Processing videos for handsign 0:  75%|███████▌  | 102/136 [01:18<00:33,  1.01it/s]\u001B[A\n",
      "Processing videos for handsign 0:  76%|███████▌  | 103/136 [01:19<00:34,  1.03s/it]\u001B[A\n",
      "Processing videos for handsign 0:  76%|███████▋  | 104/136 [01:20<00:32,  1.01s/it]\u001B[A\n",
      "Processing videos for handsign 0:  77%|███████▋  | 105/136 [01:21<00:30,  1.02it/s]\u001B[A\n",
      "Processing videos for handsign 0:  78%|███████▊  | 106/136 [01:22<00:27,  1.09it/s]\u001B[A\n",
      "Processing videos for handsign 0:  79%|███████▊  | 107/136 [01:23<00:26,  1.11it/s]\u001B[A\n",
      "Processing videos for handsign 0:  79%|███████▉  | 108/136 [01:23<00:25,  1.08it/s]\u001B[A\n",
      "Processing videos for handsign 0:  80%|████████  | 109/136 [01:24<00:23,  1.13it/s]\u001B[A\n",
      "Processing videos for handsign 0:  81%|████████  | 110/136 [01:26<00:28,  1.09s/it]\u001B[A\n",
      "Processing videos for handsign 0:  82%|████████▏ | 111/136 [01:28<00:34,  1.38s/it]\u001B[A\n",
      "Processing videos for handsign 0:  82%|████████▏ | 112/136 [01:30<00:35,  1.46s/it]\u001B[A\n",
      "Processing videos for handsign 0:  83%|████████▎ | 113/136 [01:30<00:30,  1.31s/it]\u001B[A\n",
      "Processing videos for handsign 0:  84%|████████▍ | 114/136 [01:32<00:27,  1.27s/it]\u001B[A\n",
      "Processing videos for handsign 0:  85%|████████▍ | 115/136 [01:33<00:27,  1.32s/it]\u001B[A\n",
      "Processing videos for handsign 0:  85%|████████▌ | 116/136 [01:34<00:25,  1.25s/it]\u001B[A\n",
      "Processing videos for handsign 0:  86%|████████▌ | 117/136 [01:35<00:22,  1.20s/it]\u001B[A\n",
      "Processing videos for handsign 0:  87%|████████▋ | 118/136 [01:37<00:23,  1.28s/it]\u001B[A\n",
      "Processing videos for handsign 0:  88%|████████▊ | 119/136 [01:38<00:23,  1.37s/it]\u001B[A\n",
      "Processing videos for handsign 0:  88%|████████▊ | 120/136 [01:39<00:20,  1.28s/it]\u001B[A\n",
      "Processing videos for handsign 0:  89%|████████▉ | 121/136 [01:41<00:19,  1.30s/it]\u001B[A\n",
      "Processing videos for handsign 0:  90%|████████▉ | 122/136 [01:42<00:18,  1.30s/it]\u001B[A\n",
      "Processing videos for handsign 0:  90%|█████████ | 123/136 [01:43<00:16,  1.27s/it]\u001B[A\n",
      "Processing videos for handsign 0:  91%|█████████ | 124/136 [01:44<00:14,  1.22s/it]\u001B[A\n",
      "Processing videos for handsign 0:  92%|█████████▏| 125/136 [01:45<00:12,  1.16s/it]\u001B[A\n",
      "Processing videos for handsign 0:  93%|█████████▎| 126/136 [01:47<00:12,  1.25s/it]\u001B[A\n",
      "Processing videos for handsign 0:  93%|█████████▎| 127/136 [01:48<00:10,  1.15s/it]\u001B[A\n",
      "Processing videos for handsign 0:  94%|█████████▍| 128/136 [01:49<00:08,  1.06s/it]\u001B[A\n",
      "Processing videos for handsign 0:  95%|█████████▍| 129/136 [01:49<00:06,  1.03it/s]\u001B[A\n",
      "Processing videos for handsign 0:  96%|█████████▌| 130/136 [01:50<00:05,  1.04it/s]\u001B[A\n",
      "Processing videos for handsign 0:  96%|█████████▋| 131/136 [01:51<00:04,  1.06it/s]\u001B[A\n",
      "Processing videos for handsign 0:  97%|█████████▋| 132/136 [01:52<00:03,  1.16it/s]\u001B[A\n",
      "Processing videos for handsign 0:  98%|█████████▊| 133/136 [01:53<00:02,  1.22it/s]\u001B[A\n",
      "Processing videos for handsign 0:  99%|█████████▊| 134/136 [01:54<00:01,  1.13it/s]\u001B[A\n",
      "Processing videos for handsign 0:  99%|█████████▉| 135/136 [01:55<00:00,  1.08it/s]\u001B[A\n",
      "Processing videos for handsign 0: 100%|██████████| 136/136 [01:56<00:00,  1.09it/s]\u001B[A\n",
      "Processing handsigns:  25%|██▌       | 1/4 [01:56<05:48, 116.08s/it]               \u001B[A\n",
      "Processing videos for handsign 1:   0%|          | 0/92 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 1:   1%|          | 1/92 [00:00<01:07,  1.36it/s]\u001B[A\n",
      "Processing videos for handsign 1:   2%|▏         | 2/92 [00:01<00:55,  1.63it/s]\u001B[A\n",
      "Processing videos for handsign 1:   3%|▎         | 3/92 [00:01<00:58,  1.53it/s]\u001B[A\n",
      "Processing videos for handsign 1:   4%|▍         | 4/92 [00:02<00:52,  1.69it/s]\u001B[A\n",
      "Processing videos for handsign 1:   5%|▌         | 5/92 [00:03<00:56,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 1:   7%|▋         | 6/92 [00:03<00:52,  1.65it/s]\u001B[A\n",
      "Processing videos for handsign 1:   8%|▊         | 7/92 [00:04<00:52,  1.63it/s]\u001B[A\n",
      "Processing videos for handsign 1:   9%|▊         | 8/92 [00:04<00:48,  1.72it/s]\u001B[A\n",
      "Processing videos for handsign 1:  10%|▉         | 9/92 [00:05<00:55,  1.48it/s]\u001B[A\n",
      "Processing videos for handsign 1:  11%|█         | 10/92 [00:06<00:50,  1.62it/s]\u001B[A\n",
      "Processing videos for handsign 1:  12%|█▏        | 11/92 [00:06<00:51,  1.56it/s]\u001B[A\n",
      "Processing videos for handsign 1:  13%|█▎        | 12/92 [00:07<00:48,  1.64it/s]\u001B[A\n",
      "Processing videos for handsign 1:  14%|█▍        | 13/92 [00:08<00:50,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 1:  15%|█▌        | 14/92 [00:08<00:47,  1.64it/s]\u001B[A\n",
      "Processing videos for handsign 1:  16%|█▋        | 15/92 [00:09<00:50,  1.53it/s]\u001B[A\n",
      "Processing videos for handsign 1:  17%|█▋        | 16/92 [00:10<00:47,  1.61it/s]\u001B[A\n",
      "Processing videos for handsign 1:  18%|█▊        | 17/92 [00:10<00:48,  1.54it/s]\u001B[A\n",
      "Processing videos for handsign 1:  20%|█▉        | 18/92 [00:11<00:45,  1.64it/s]\u001B[A\n",
      "Processing videos for handsign 1:  21%|██        | 19/92 [00:11<00:45,  1.60it/s]\u001B[A\n",
      "Processing videos for handsign 1:  22%|██▏       | 20/92 [00:12<00:42,  1.70it/s]\u001B[A\n",
      "Processing videos for handsign 1:  23%|██▎       | 21/92 [00:12<00:40,  1.77it/s]\u001B[A\n",
      "Processing videos for handsign 1:  24%|██▍       | 22/92 [00:13<00:40,  1.71it/s]\u001B[A\n",
      "Processing videos for handsign 1:  25%|██▌       | 23/92 [00:14<00:38,  1.78it/s]\u001B[A\n",
      "Processing videos for handsign 1:  26%|██▌       | 24/92 [00:14<00:41,  1.65it/s]\u001B[A\n",
      "Processing videos for handsign 1:  27%|██▋       | 25/92 [00:15<00:38,  1.75it/s]\u001B[A\n",
      "Processing videos for handsign 1:  28%|██▊       | 26/92 [00:15<00:38,  1.70it/s]\u001B[A\n",
      "Processing videos for handsign 1:  29%|██▉       | 27/92 [00:16<00:36,  1.80it/s]\u001B[A\n",
      "Processing videos for handsign 1:  30%|███       | 28/92 [00:16<00:36,  1.76it/s]\u001B[A\n",
      "Processing videos for handsign 1:  32%|███▏      | 29/92 [00:17<00:40,  1.57it/s]\u001B[A\n",
      "Processing videos for handsign 1:  33%|███▎      | 30/92 [00:18<00:37,  1.66it/s]\u001B[A\n",
      "Processing videos for handsign 1:  34%|███▎      | 31/92 [00:19<00:41,  1.46it/s]\u001B[A\n",
      "Processing videos for handsign 1:  35%|███▍      | 32/92 [00:19<00:38,  1.56it/s]\u001B[A\n",
      "Processing videos for handsign 1:  36%|███▌      | 33/92 [00:20<00:36,  1.63it/s]\u001B[A\n",
      "Processing videos for handsign 1:  37%|███▋      | 34/92 [00:20<00:33,  1.73it/s]\u001B[A\n",
      "Processing videos for handsign 1:  38%|███▊      | 35/92 [00:21<00:33,  1.69it/s]\u001B[A\n",
      "Processing videos for handsign 1:  39%|███▉      | 36/92 [00:21<00:31,  1.77it/s]\u001B[A\n",
      "Processing videos for handsign 1:  40%|████      | 37/92 [00:22<00:29,  1.85it/s]\u001B[A\n",
      "Processing videos for handsign 1:  41%|████▏     | 38/92 [00:23<00:30,  1.75it/s]\u001B[A\n",
      "Processing videos for handsign 1:  42%|████▏     | 39/92 [00:23<00:32,  1.65it/s]\u001B[A\n",
      "Processing videos for handsign 1:  43%|████▎     | 40/92 [00:24<00:29,  1.79it/s]\u001B[A\n",
      "Processing videos for handsign 1:  45%|████▍     | 41/92 [00:25<00:33,  1.54it/s]\u001B[A\n",
      "Processing videos for handsign 1:  46%|████▌     | 42/92 [00:25<00:29,  1.68it/s]\u001B[A\n",
      "Processing videos for handsign 1:  47%|████▋     | 43/92 [00:26<00:30,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 1:  48%|████▊     | 44/92 [00:26<00:25,  1.90it/s]\u001B[A\n",
      "Processing videos for handsign 1:  49%|████▉     | 45/92 [00:27<00:26,  1.80it/s]\u001B[A\n",
      "Processing videos for handsign 1:  50%|█████     | 46/92 [00:27<00:27,  1.65it/s]\u001B[A\n",
      "Processing videos for handsign 1:  51%|█████     | 47/92 [00:28<00:29,  1.54it/s]\u001B[A\n",
      "Processing videos for handsign 1:  52%|█████▏    | 48/92 [00:29<00:30,  1.44it/s]\u001B[A\n",
      "Processing videos for handsign 1:  53%|█████▎    | 49/92 [00:29<00:28,  1.51it/s]\u001B[A\n",
      "Processing videos for handsign 1:  54%|█████▍    | 50/92 [00:30<00:29,  1.44it/s]\u001B[A\n",
      "Processing videos for handsign 1:  55%|█████▌    | 51/92 [00:31<00:29,  1.39it/s]\u001B[A\n",
      "Processing videos for handsign 1:  57%|█████▋    | 52/92 [00:32<00:25,  1.54it/s]\u001B[A\n",
      "Processing videos for handsign 1:  58%|█████▊    | 53/92 [00:32<00:24,  1.61it/s]\u001B[A\n",
      "Processing videos for handsign 1:  59%|█████▊    | 54/92 [00:33<00:25,  1.50it/s]\u001B[A\n",
      "Processing videos for handsign 1:  60%|█████▉    | 55/92 [00:34<00:25,  1.47it/s]\u001B[A\n",
      "Processing videos for handsign 1:  61%|██████    | 56/92 [00:34<00:24,  1.45it/s]\u001B[A\n",
      "Processing videos for handsign 1:  62%|██████▏   | 57/92 [00:34<00:19,  1.84it/s]\u001B[A\n",
      "Processing videos for handsign 1:  63%|██████▎   | 58/92 [00:35<00:21,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 1:  64%|██████▍   | 59/92 [00:36<00:19,  1.70it/s]\u001B[A\n",
      "Processing videos for handsign 1:  65%|██████▌   | 60/92 [00:37<00:21,  1.50it/s]\u001B[A\n",
      "Processing videos for handsign 1:  66%|██████▋   | 61/92 [00:37<00:19,  1.60it/s]\u001B[A\n",
      "Processing videos for handsign 1:  67%|██████▋   | 62/92 [00:38<00:20,  1.44it/s]\u001B[A\n",
      "Processing videos for handsign 1:  68%|██████▊   | 63/92 [00:39<00:18,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 1:  70%|██████▉   | 64/92 [00:39<00:16,  1.67it/s]\u001B[A\n",
      "Processing videos for handsign 1:  71%|███████   | 65/92 [00:40<00:18,  1.46it/s]\u001B[A\n",
      "Processing videos for handsign 1:  72%|███████▏  | 66/92 [00:40<00:16,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 1:  73%|███████▎  | 67/92 [00:41<00:15,  1.64it/s]\u001B[A\n",
      "Processing videos for handsign 1:  74%|███████▍  | 68/92 [00:42<00:14,  1.67it/s]\u001B[A\n",
      "Processing videos for handsign 1:  75%|███████▌  | 69/92 [00:42<00:13,  1.68it/s]\u001B[A\n",
      "Processing videos for handsign 1:  76%|███████▌  | 70/92 [00:43<00:13,  1.65it/s]\u001B[A\n",
      "Processing videos for handsign 1:  77%|███████▋  | 71/92 [00:43<00:13,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 1:  78%|███████▊  | 72/92 [00:44<00:12,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 1:  79%|███████▉  | 73/92 [00:45<00:12,  1.57it/s]\u001B[A\n",
      "Processing videos for handsign 1:  80%|████████  | 74/92 [00:45<00:11,  1.60it/s]\u001B[A\n",
      "Processing videos for handsign 1:  82%|████████▏ | 75/92 [00:46<00:10,  1.64it/s]\u001B[A\n",
      "Processing videos for handsign 1:  83%|████████▎ | 76/92 [00:47<00:09,  1.64it/s]\u001B[A\n",
      "Processing videos for handsign 1:  84%|████████▎ | 77/92 [00:47<00:09,  1.59it/s]\u001B[A\n",
      "Processing videos for handsign 1:  85%|████████▍ | 78/92 [00:48<00:08,  1.57it/s]\u001B[A\n",
      "Processing videos for handsign 1:  86%|████████▌ | 79/92 [00:48<00:08,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 1:  87%|████████▋ | 80/92 [00:49<00:08,  1.49it/s]\u001B[A\n",
      "Processing videos for handsign 1:  88%|████████▊ | 81/92 [00:50<00:07,  1.52it/s]\u001B[A\n",
      "Processing videos for handsign 1:  89%|████████▉ | 82/92 [00:51<00:06,  1.49it/s]\u001B[A\n",
      "Processing videos for handsign 1:  90%|█████████ | 83/92 [00:51<00:06,  1.48it/s]\u001B[A\n",
      "Processing videos for handsign 1:  91%|█████████▏| 84/92 [00:52<00:05,  1.48it/s]\u001B[A\n",
      "Processing videos for handsign 1:  92%|█████████▏| 85/92 [00:53<00:04,  1.48it/s]\u001B[A\n",
      "Processing videos for handsign 1:  93%|█████████▎| 86/92 [00:53<00:04,  1.49it/s]\u001B[A\n",
      "Processing videos for handsign 1:  95%|█████████▍| 87/92 [00:54<00:03,  1.50it/s]\u001B[A\n",
      "Processing videos for handsign 1:  96%|█████████▌| 88/92 [00:55<00:02,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 1:  97%|█████████▋| 89/92 [00:55<00:01,  1.53it/s]\u001B[A\n",
      "Processing videos for handsign 1:  98%|█████████▊| 90/92 [00:56<00:01,  1.57it/s]\u001B[A\n",
      "Processing videos for handsign 1:  99%|█████████▉| 91/92 [00:56<00:00,  1.57it/s]\u001B[A\n",
      "Processing videos for handsign 1: 100%|██████████| 92/92 [00:57<00:00,  1.56it/s]\u001B[A\n",
      "                                                                                 \u001B[AC:\\Users\\joaqu\\AppData\\Local\\Temp\\ipykernel_21080\\1396058907.py:134: UserWarning: Handsign 1 ('C') has only 92 videos. Padding with 44 empty videos.\n",
      "  warnings.warn(f\"Handsign {handsign_index} ('{handsign_folder}') has only {len(handsign_data)} videos. \"\n",
      "Processing handsigns:  50%|█████     | 2/4 [02:53<02:43, 81.68s/it] \n",
      "Processing videos for handsign 2:   0%|          | 0/107 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 2:   1%|          | 1/107 [00:00<01:31,  1.15it/s]\u001B[A\n",
      "Processing videos for handsign 2:   2%|▏         | 2/107 [00:01<01:29,  1.18it/s]\u001B[A\n",
      "Processing videos for handsign 2:   3%|▎         | 3/107 [00:02<01:30,  1.15it/s]\u001B[A\n",
      "Processing videos for handsign 2:   4%|▎         | 4/107 [00:03<01:28,  1.16it/s]\u001B[A\n",
      "Processing videos for handsign 2:   5%|▍         | 5/107 [00:04<01:26,  1.18it/s]\u001B[A\n",
      "Processing videos for handsign 2:   6%|▌         | 6/107 [00:05<01:35,  1.05it/s]\u001B[A\n",
      "Processing videos for handsign 2:   7%|▋         | 7/107 [00:06<01:38,  1.02it/s]\u001B[A\n",
      "Processing videos for handsign 2:   7%|▋         | 8/107 [00:07<01:32,  1.07it/s]\u001B[A\n",
      "Processing videos for handsign 2:   8%|▊         | 9/107 [00:08<01:31,  1.07it/s]\u001B[A\n",
      "Processing videos for handsign 2:   9%|▉         | 10/107 [00:09<01:30,  1.07it/s]\u001B[A\n",
      "Processing videos for handsign 2:  10%|█         | 11/107 [00:09<01:25,  1.13it/s]\u001B[A\n",
      "Processing videos for handsign 2:  11%|█         | 12/107 [00:10<01:20,  1.18it/s]\u001B[A\n",
      "Processing videos for handsign 2:  12%|█▏        | 13/107 [00:11<01:20,  1.16it/s]\u001B[A\n",
      "Processing videos for handsign 2:  13%|█▎        | 14/107 [00:12<01:24,  1.10it/s]\u001B[A\n",
      "Processing videos for handsign 2:  14%|█▍        | 15/107 [00:13<01:20,  1.14it/s]\u001B[A\n",
      "Processing videos for handsign 2:  15%|█▍        | 16/107 [00:14<01:17,  1.18it/s]\u001B[A\n",
      "Processing videos for handsign 2:  16%|█▌        | 17/107 [00:15<01:15,  1.18it/s]\u001B[A\n",
      "Processing videos for handsign 2:  17%|█▋        | 18/107 [00:15<01:14,  1.19it/s]\u001B[A\n",
      "Processing videos for handsign 2:  18%|█▊        | 19/107 [00:16<01:14,  1.18it/s]\u001B[A\n",
      "Processing videos for handsign 2:  19%|█▊        | 20/107 [00:17<01:12,  1.20it/s]\u001B[A\n",
      "Processing videos for handsign 2:  20%|█▉        | 21/107 [00:18<01:16,  1.12it/s]\u001B[A\n",
      "Processing videos for handsign 2:  21%|██        | 22/107 [00:19<01:14,  1.15it/s]\u001B[A\n",
      "Processing videos for handsign 2:  21%|██▏       | 23/107 [00:20<01:17,  1.09it/s]\u001B[A\n",
      "Processing videos for handsign 2:  22%|██▏       | 24/107 [00:21<01:18,  1.06it/s]\u001B[A\n",
      "Processing videos for handsign 2:  23%|██▎       | 25/107 [00:22<01:18,  1.04it/s]\u001B[A\n",
      "Processing videos for handsign 2:  24%|██▍       | 26/107 [00:23<01:16,  1.05it/s]\u001B[A\n",
      "Processing videos for handsign 2:  25%|██▌       | 27/107 [00:24<01:20,  1.01s/it]\u001B[A\n",
      "Processing videos for handsign 2:  26%|██▌       | 28/107 [00:25<01:19,  1.01s/it]\u001B[A\n",
      "Processing videos for handsign 2:  27%|██▋       | 29/107 [00:26<01:19,  1.02s/it]\u001B[A\n",
      "Processing videos for handsign 2:  28%|██▊       | 30/107 [00:27<01:21,  1.06s/it]\u001B[A\n",
      "Processing videos for handsign 2:  29%|██▉       | 31/107 [00:28<01:14,  1.02it/s]\u001B[A\n",
      "Processing videos for handsign 2:  30%|██▉       | 32/107 [00:29<01:11,  1.05it/s]\u001B[A\n",
      "Processing videos for handsign 2:  31%|███       | 33/107 [00:30<01:09,  1.07it/s]\u001B[A\n",
      "Processing videos for handsign 2:  32%|███▏      | 34/107 [00:31<01:06,  1.10it/s]\u001B[A\n",
      "Processing videos for handsign 2:  33%|███▎      | 35/107 [00:32<01:05,  1.10it/s]\u001B[A\n",
      "Processing videos for handsign 2:  34%|███▎      | 36/107 [00:32<01:04,  1.10it/s]\u001B[A\n",
      "Processing videos for handsign 2:  35%|███▍      | 37/107 [00:33<01:04,  1.09it/s]\u001B[A\n",
      "Processing videos for handsign 2:  36%|███▌      | 38/107 [00:34<01:02,  1.10it/s]\u001B[A\n",
      "Processing videos for handsign 2:  36%|███▋      | 39/107 [00:35<01:01,  1.11it/s]\u001B[A\n",
      "Processing videos for handsign 2:  37%|███▋      | 40/107 [00:36<01:00,  1.10it/s]\u001B[A\n",
      "Processing videos for handsign 2:  38%|███▊      | 41/107 [00:37<00:59,  1.11it/s]\u001B[A\n",
      "Processing videos for handsign 2:  39%|███▉      | 42/107 [00:38<00:56,  1.15it/s]\u001B[A\n",
      "Processing videos for handsign 2:  40%|████      | 43/107 [00:39<00:54,  1.17it/s]\u001B[A\n",
      "Processing videos for handsign 2:  41%|████      | 44/107 [00:39<00:53,  1.18it/s]\u001B[A\n",
      "Processing videos for handsign 2:  42%|████▏     | 45/107 [00:40<00:54,  1.15it/s]\u001B[A\n",
      "Processing videos for handsign 2:  43%|████▎     | 46/107 [00:41<00:53,  1.14it/s]\u001B[A\n",
      "Processing videos for handsign 2:  44%|████▍     | 47/107 [00:42<00:54,  1.10it/s]\u001B[A\n",
      "Processing videos for handsign 2:  45%|████▍     | 48/107 [00:43<00:56,  1.05it/s]\u001B[A\n",
      "Processing videos for handsign 2:  46%|████▌     | 49/107 [00:44<00:55,  1.05it/s]\u001B[A\n",
      "Processing videos for handsign 2:  47%|████▋     | 50/107 [00:45<00:55,  1.04it/s]\u001B[A\n",
      "Processing videos for handsign 2:  48%|████▊     | 51/107 [00:46<00:44,  1.25it/s]\u001B[A\n",
      "Processing videos for handsign 2:  49%|████▊     | 52/107 [00:46<00:39,  1.38it/s]\u001B[A\n",
      "Processing videos for handsign 2:  50%|████▉     | 53/107 [00:47<00:36,  1.49it/s]\u001B[A\n",
      "Processing videos for handsign 2:  50%|█████     | 54/107 [00:47<00:33,  1.60it/s]\u001B[A\n",
      "Processing videos for handsign 2:  51%|█████▏    | 55/107 [00:48<00:29,  1.76it/s]\u001B[A\n",
      "Processing videos for handsign 2:  52%|█████▏    | 56/107 [00:48<00:28,  1.82it/s]\u001B[A\n",
      "Processing videos for handsign 2:  53%|█████▎    | 57/107 [00:49<00:26,  1.86it/s]\u001B[A\n",
      "Processing videos for handsign 2:  54%|█████▍    | 58/107 [00:49<00:26,  1.85it/s]\u001B[A\n",
      "Processing videos for handsign 2:  55%|█████▌    | 59/107 [00:50<00:25,  1.85it/s]\u001B[A\n",
      "Processing videos for handsign 2:  56%|█████▌    | 60/107 [00:50<00:25,  1.86it/s]\u001B[A\n",
      "Processing videos for handsign 2:  57%|█████▋    | 61/107 [00:51<00:24,  1.89it/s]\u001B[A\n",
      "Processing videos for handsign 2:  58%|█████▊    | 62/107 [00:51<00:23,  1.92it/s]\u001B[A\n",
      "Processing videos for handsign 2:  59%|█████▉    | 63/107 [00:52<00:22,  1.92it/s]\u001B[A\n",
      "Processing videos for handsign 2:  60%|█████▉    | 64/107 [00:52<00:22,  1.94it/s]\u001B[A\n",
      "Processing videos for handsign 2:  61%|██████    | 65/107 [00:53<00:21,  1.94it/s]\u001B[A\n",
      "Processing videos for handsign 2:  62%|██████▏   | 66/107 [00:53<00:21,  1.89it/s]\u001B[A\n",
      "Processing videos for handsign 2:  63%|██████▎   | 67/107 [00:54<00:21,  1.90it/s]\u001B[A\n",
      "Processing videos for handsign 2:  64%|██████▎   | 68/107 [00:54<00:20,  1.92it/s]\u001B[A\n",
      "Processing videos for handsign 2:  64%|██████▍   | 69/107 [00:55<00:19,  1.97it/s]\u001B[A\n",
      "Processing videos for handsign 2:  65%|██████▌   | 70/107 [00:55<00:18,  1.99it/s]\u001B[A\n",
      "Processing videos for handsign 2:  66%|██████▋   | 71/107 [00:56<00:17,  2.02it/s]\u001B[A\n",
      "Processing videos for handsign 2:  67%|██████▋   | 72/107 [00:56<00:17,  2.02it/s]\u001B[A\n",
      "Processing videos for handsign 2:  68%|██████▊   | 73/107 [00:57<00:16,  2.12it/s]\u001B[A\n",
      "Processing videos for handsign 2:  69%|██████▉   | 74/107 [00:57<00:16,  2.06it/s]\u001B[A\n",
      "Processing videos for handsign 2:  70%|███████   | 75/107 [00:58<00:15,  2.01it/s]\u001B[A\n",
      "Processing videos for handsign 2:  71%|███████   | 76/107 [00:58<00:15,  2.01it/s]\u001B[A\n",
      "Processing videos for handsign 2:  72%|███████▏  | 77/107 [00:59<00:14,  2.12it/s]\u001B[A\n",
      "Processing videos for handsign 2:  73%|███████▎  | 78/107 [00:59<00:13,  2.09it/s]\u001B[A\n",
      "Processing videos for handsign 2:  74%|███████▍  | 79/107 [01:00<00:13,  2.05it/s]\u001B[A\n",
      "Processing videos for handsign 2:  75%|███████▍  | 80/107 [01:00<00:13,  2.00it/s]\u001B[A\n",
      "Processing videos for handsign 2:  76%|███████▌  | 81/107 [01:01<00:13,  1.96it/s]\u001B[A\n",
      "Processing videos for handsign 2:  77%|███████▋  | 82/107 [01:01<00:12,  1.95it/s]\u001B[A\n",
      "Processing videos for handsign 2:  78%|███████▊  | 83/107 [01:02<00:11,  2.05it/s]\u001B[A\n",
      "Processing videos for handsign 2:  79%|███████▊  | 84/107 [01:02<00:12,  1.88it/s]\u001B[A\n",
      "Processing videos for handsign 2:  79%|███████▉  | 85/107 [01:03<00:12,  1.81it/s]\u001B[A\n",
      "Processing videos for handsign 2:  80%|████████  | 86/107 [01:04<00:12,  1.68it/s]\u001B[A\n",
      "Processing videos for handsign 2:  81%|████████▏ | 87/107 [01:04<00:12,  1.62it/s]\u001B[A\n",
      "Processing videos for handsign 2:  82%|████████▏ | 88/107 [01:05<00:12,  1.57it/s]\u001B[A\n",
      "Processing videos for handsign 2:  83%|████████▎ | 89/107 [01:06<00:11,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 2:  84%|████████▍ | 90/107 [01:06<00:10,  1.59it/s]\u001B[A\n",
      "Processing videos for handsign 2:  85%|████████▌ | 91/107 [01:07<00:09,  1.66it/s]\u001B[A\n",
      "Processing videos for handsign 2:  86%|████████▌ | 92/107 [01:07<00:08,  1.67it/s]\u001B[A\n",
      "Processing videos for handsign 2:  87%|████████▋ | 93/107 [01:08<00:08,  1.70it/s]\u001B[A\n",
      "Processing videos for handsign 2:  88%|████████▊ | 94/107 [01:09<00:07,  1.66it/s]\u001B[A\n",
      "Processing videos for handsign 2:  89%|████████▉ | 95/107 [01:09<00:07,  1.67it/s]\u001B[A\n",
      "Processing videos for handsign 2:  90%|████████▉ | 96/107 [01:10<00:06,  1.66it/s]\u001B[A\n",
      "Processing videos for handsign 2:  91%|█████████ | 97/107 [01:10<00:06,  1.66it/s]\u001B[A\n",
      "Processing videos for handsign 2:  92%|█████████▏| 98/107 [01:11<00:05,  1.66it/s]\u001B[A\n",
      "Processing videos for handsign 2:  93%|█████████▎| 99/107 [01:12<00:04,  1.61it/s]\u001B[A\n",
      "Processing videos for handsign 2:  93%|█████████▎| 100/107 [01:12<00:04,  1.60it/s]\u001B[A\n",
      "Processing videos for handsign 2:  94%|█████████▍| 101/107 [01:13<00:03,  1.63it/s]\u001B[A\n",
      "Processing videos for handsign 2:  95%|█████████▌| 102/107 [01:14<00:03,  1.62it/s]\u001B[A\n",
      "Processing videos for handsign 2:  96%|█████████▋| 103/107 [01:14<00:02,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 2:  97%|█████████▋| 104/107 [01:15<00:01,  1.56it/s]\u001B[A\n",
      "Processing videos for handsign 2:  98%|█████████▊| 105/107 [01:16<00:01,  1.52it/s]\u001B[A\n",
      "Processing videos for handsign 2:  99%|█████████▉| 106/107 [01:16<00:00,  1.49it/s]\u001B[A\n",
      "Processing videos for handsign 2: 100%|██████████| 107/107 [01:17<00:00,  1.48it/s]\u001B[A\n",
      "                                                                                   \u001B[AC:\\Users\\joaqu\\AppData\\Local\\Temp\\ipykernel_21080\\1396058907.py:134: UserWarning: Handsign 2 ('cumpleaños') has only 107 videos. Padding with 29 empty videos.\n",
      "  warnings.warn(f\"Handsign {handsign_index} ('{handsign_folder}') has only {len(handsign_data)} videos. \"\n",
      "Processing handsigns:  75%|███████▌  | 3/4 [04:11<01:19, 79.75s/it]\n",
      "Processing videos for handsign 3:   0%|          | 0/136 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 3:   1%|          | 1/136 [00:00<01:40,  1.34it/s]\u001B[A\n",
      "Processing videos for handsign 3:   1%|▏         | 2/136 [00:01<01:40,  1.33it/s]\u001B[A\n",
      "Processing videos for handsign 3:   2%|▏         | 3/136 [00:02<01:41,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 3:   3%|▎         | 4/136 [00:03<01:40,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 3:   4%|▎         | 5/136 [00:03<01:37,  1.35it/s]\u001B[A\n",
      "Processing videos for handsign 3:   4%|▍         | 6/136 [00:04<01:45,  1.24it/s]\u001B[A\n",
      "Processing videos for handsign 3:   5%|▌         | 7/136 [00:05<01:44,  1.24it/s]\u001B[A\n",
      "Processing videos for handsign 3:   6%|▌         | 8/136 [00:06<01:40,  1.27it/s]\u001B[A\n",
      "Processing videos for handsign 3:   7%|▋         | 9/136 [00:07<01:42,  1.24it/s]\u001B[A\n",
      "Processing videos for handsign 3:   7%|▋         | 10/136 [00:07<01:42,  1.23it/s]\u001B[A\n",
      "Processing videos for handsign 3:   8%|▊         | 11/136 [00:08<01:39,  1.25it/s]\u001B[A\n",
      "Processing videos for handsign 3:   9%|▉         | 12/136 [00:09<01:36,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 3:  10%|▉         | 13/136 [00:10<01:38,  1.25it/s]\u001B[A\n",
      "Processing videos for handsign 3:  10%|█         | 14/136 [00:11<01:36,  1.27it/s]\u001B[A\n",
      "Processing videos for handsign 3:  11%|█         | 15/136 [00:11<01:34,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 3:  12%|█▏        | 16/136 [00:12<01:32,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 3:  12%|█▎        | 17/136 [00:13<01:30,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 3:  13%|█▎        | 18/136 [00:14<01:29,  1.32it/s]\u001B[A\n",
      "Processing videos for handsign 3:  14%|█▍        | 19/136 [00:14<01:28,  1.32it/s]\u001B[A\n",
      "Processing videos for handsign 3:  15%|█▍        | 20/136 [00:15<01:29,  1.30it/s]\u001B[A\n",
      "Processing videos for handsign 3:  15%|█▌        | 21/136 [00:16<01:29,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 3:  16%|█▌        | 22/136 [00:17<01:29,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 3:  17%|█▋        | 23/136 [00:18<01:30,  1.25it/s]\u001B[A\n",
      "Processing videos for handsign 3:  18%|█▊        | 24/136 [00:18<01:29,  1.26it/s]\u001B[A\n",
      "Processing videos for handsign 3:  18%|█▊        | 25/136 [00:19<01:28,  1.26it/s]\u001B[A\n",
      "Processing videos for handsign 3:  19%|█▉        | 26/136 [00:20<01:28,  1.25it/s]\u001B[A\n",
      "Processing videos for handsign 3:  20%|█▉        | 27/136 [00:21<01:27,  1.25it/s]\u001B[A\n",
      "Processing videos for handsign 3:  21%|██        | 28/136 [00:21<01:25,  1.26it/s]\u001B[A\n",
      "Processing videos for handsign 3:  21%|██▏       | 29/136 [00:22<01:23,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 3:  22%|██▏       | 30/136 [00:23<01:23,  1.27it/s]\u001B[A\n",
      "Processing videos for handsign 3:  23%|██▎       | 31/136 [00:24<01:22,  1.27it/s]\u001B[A\n",
      "Processing videos for handsign 3:  24%|██▎       | 32/136 [00:25<01:22,  1.26it/s]\u001B[A\n",
      "Processing videos for handsign 3:  24%|██▍       | 33/136 [00:25<01:20,  1.27it/s]\u001B[A\n",
      "Processing videos for handsign 3:  25%|██▌       | 34/136 [00:26<01:18,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 3:  26%|██▌       | 35/136 [00:27<01:19,  1.28it/s]\u001B[A\n",
      "Processing videos for handsign 3:  26%|██▋       | 36/136 [00:28<01:15,  1.32it/s]\u001B[A\n",
      "Processing videos for handsign 3:  27%|██▋       | 37/136 [00:28<01:13,  1.35it/s]\u001B[A\n",
      "Processing videos for handsign 3:  28%|██▊       | 38/136 [00:29<01:11,  1.38it/s]\u001B[A\n",
      "Processing videos for handsign 3:  29%|██▊       | 39/136 [00:30<01:10,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 3:  29%|██▉       | 40/136 [00:30<01:09,  1.38it/s]\u001B[A\n",
      "Processing videos for handsign 3:  30%|███       | 41/136 [00:31<01:11,  1.33it/s]\u001B[A\n",
      "Processing videos for handsign 3:  31%|███       | 42/136 [00:32<01:10,  1.33it/s]\u001B[A\n",
      "Processing videos for handsign 3:  32%|███▏      | 43/136 [00:33<01:09,  1.34it/s]\u001B[A\n",
      "Processing videos for handsign 3:  32%|███▏      | 44/136 [00:33<01:06,  1.38it/s]\u001B[A\n",
      "Processing videos for handsign 3:  33%|███▎      | 45/136 [00:34<01:04,  1.41it/s]\u001B[A\n",
      "Processing videos for handsign 3:  34%|███▍      | 46/136 [00:35<01:05,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 3:  35%|███▍      | 47/136 [00:36<01:05,  1.36it/s]\u001B[A\n",
      "Processing videos for handsign 3:  35%|███▌      | 48/136 [00:36<01:05,  1.34it/s]\u001B[A\n",
      "Processing videos for handsign 3:  36%|███▌      | 49/136 [00:37<01:06,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 3:  37%|███▋      | 50/136 [00:38<01:06,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 3:  38%|███▊      | 51/136 [00:39<01:02,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 3:  38%|███▊      | 52/136 [00:39<01:02,  1.35it/s]\u001B[A\n",
      "Processing videos for handsign 3:  39%|███▉      | 53/136 [00:40<01:01,  1.34it/s]\u001B[A\n",
      "Processing videos for handsign 3:  40%|███▉      | 54/136 [00:41<01:06,  1.23it/s]\u001B[A\n",
      "Processing videos for handsign 3:  40%|████      | 55/136 [00:42<01:07,  1.19it/s]\u001B[A\n",
      "Processing videos for handsign 3:  41%|████      | 56/136 [00:43<01:11,  1.11it/s]\u001B[A\n",
      "Processing videos for handsign 3:  42%|████▏     | 57/136 [00:44<01:11,  1.10it/s]\u001B[A\n",
      "Processing videos for handsign 3:  43%|████▎     | 58/136 [00:45<01:05,  1.20it/s]\u001B[A\n",
      "Processing videos for handsign 3:  43%|████▎     | 59/136 [00:45<00:58,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 3:  44%|████▍     | 60/136 [00:46<00:58,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 3:  45%|████▍     | 61/136 [00:47<00:57,  1.30it/s]\u001B[A\n",
      "Processing videos for handsign 3:  46%|████▌     | 62/136 [00:48<00:56,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 3:  46%|████▋     | 63/136 [00:48<00:56,  1.29it/s]\u001B[A\n",
      "Processing videos for handsign 3:  47%|████▋     | 64/136 [00:49<00:54,  1.32it/s]\u001B[A\n",
      "Processing videos for handsign 3:  48%|████▊     | 65/136 [00:50<00:52,  1.36it/s]\u001B[A\n",
      "Processing videos for handsign 3:  49%|████▊     | 66/136 [00:51<00:52,  1.34it/s]\u001B[A\n",
      "Processing videos for handsign 3:  49%|████▉     | 67/136 [00:51<00:52,  1.32it/s]\u001B[A\n",
      "Processing videos for handsign 3:  50%|█████     | 68/136 [00:52<00:48,  1.39it/s]\u001B[A\n",
      "Processing videos for handsign 3:  51%|█████     | 69/136 [00:53<00:47,  1.41it/s]\u001B[A\n",
      "Processing videos for handsign 3:  51%|█████▏    | 70/136 [00:53<00:46,  1.43it/s]\u001B[A\n",
      "Processing videos for handsign 3:  52%|█████▏    | 71/136 [00:54<00:45,  1.44it/s]\u001B[A\n",
      "Processing videos for handsign 3:  53%|█████▎    | 72/136 [00:55<00:46,  1.38it/s]\u001B[A\n",
      "Processing videos for handsign 3:  54%|█████▎    | 73/136 [00:56<00:47,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 3:  54%|█████▍    | 74/136 [00:56<00:47,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 3:  55%|█████▌    | 75/136 [00:57<00:44,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 3:  56%|█████▌    | 76/136 [00:58<00:42,  1.40it/s]\u001B[A\n",
      "Processing videos for handsign 3:  57%|█████▋    | 77/136 [00:59<00:44,  1.34it/s]\u001B[A\n",
      "Processing videos for handsign 3:  57%|█████▋    | 78/136 [00:59<00:40,  1.43it/s]\u001B[A\n",
      "Processing videos for handsign 3:  58%|█████▊    | 79/136 [01:00<00:39,  1.44it/s]\u001B[A\n",
      "Processing videos for handsign 3:  59%|█████▉    | 80/136 [01:01<00:38,  1.46it/s]\u001B[A\n",
      "Processing videos for handsign 3:  60%|█████▉    | 81/136 [01:01<00:40,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 3:  60%|██████    | 82/136 [01:02<00:41,  1.31it/s]\u001B[A\n",
      "Processing videos for handsign 3:  61%|██████    | 83/136 [01:03<00:39,  1.36it/s]\u001B[A\n",
      "Processing videos for handsign 3:  62%|██████▏   | 84/136 [01:04<00:38,  1.35it/s]\u001B[A\n",
      "Processing videos for handsign 3:  62%|██████▎   | 85/136 [01:04<00:37,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 3:  63%|██████▎   | 86/136 [01:05<00:33,  1.48it/s]\u001B[A\n",
      "Processing videos for handsign 3:  64%|██████▍   | 87/136 [01:06<00:32,  1.52it/s]\u001B[A\n",
      "Processing videos for handsign 3:  65%|██████▍   | 88/136 [01:06<00:31,  1.54it/s]\u001B[A\n",
      "Processing videos for handsign 3:  65%|██████▌   | 89/136 [01:07<00:29,  1.62it/s]\u001B[A\n",
      "Processing videos for handsign 3:  66%|██████▌   | 90/136 [01:07<00:29,  1.56it/s]\u001B[A\n",
      "Processing videos for handsign 3:  67%|██████▋   | 91/136 [01:08<00:28,  1.57it/s]\u001B[A\n",
      "Processing videos for handsign 3:  68%|██████▊   | 92/136 [01:09<00:28,  1.53it/s]\u001B[A\n",
      "Processing videos for handsign 3:  68%|██████▊   | 93/136 [01:09<00:27,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 3:  69%|██████▉   | 94/136 [01:10<00:28,  1.48it/s]\u001B[A\n",
      "Processing videos for handsign 3:  70%|██████▉   | 95/136 [01:11<00:27,  1.49it/s]\u001B[A\n",
      "Processing videos for handsign 3:  71%|███████   | 96/136 [01:11<00:26,  1.51it/s]\u001B[A\n",
      "Processing videos for handsign 3:  71%|███████▏  | 97/136 [01:12<00:24,  1.59it/s]\u001B[A\n",
      "Processing videos for handsign 3:  72%|███████▏  | 98/136 [01:13<00:26,  1.43it/s]\u001B[A\n",
      "Processing videos for handsign 3:  73%|███████▎  | 99/136 [01:13<00:25,  1.44it/s]\u001B[A\n",
      "Processing videos for handsign 3:  74%|███████▎  | 100/136 [01:14<00:25,  1.39it/s]\u001B[A\n",
      "Processing videos for handsign 3:  74%|███████▍  | 101/136 [01:15<00:22,  1.52it/s]\u001B[A\n",
      "Processing videos for handsign 3:  75%|███████▌  | 102/136 [01:15<00:22,  1.48it/s]\u001B[A\n",
      "Processing videos for handsign 3:  76%|███████▌  | 103/136 [01:16<00:21,  1.51it/s]\u001B[A\n",
      "Processing videos for handsign 3:  76%|███████▋  | 104/136 [01:17<00:21,  1.46it/s]\u001B[A\n",
      "Processing videos for handsign 3:  77%|███████▋  | 105/136 [01:18<00:22,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 3:  78%|███████▊  | 106/136 [01:18<00:21,  1.37it/s]\u001B[A\n",
      "Processing videos for handsign 3:  79%|███████▊  | 107/136 [01:19<00:19,  1.50it/s]\u001B[A\n",
      "Processing videos for handsign 3:  79%|███████▉  | 108/136 [01:19<00:17,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 3:  80%|████████  | 109/136 [01:20<00:15,  1.70it/s]\u001B[A\n",
      "Processing videos for handsign 3:  81%|████████  | 110/136 [01:21<00:15,  1.72it/s]\u001B[A\n",
      "Processing videos for handsign 3:  82%|████████▏ | 111/136 [01:21<00:14,  1.72it/s]\u001B[A\n",
      "Processing videos for handsign 3:  82%|████████▏ | 112/136 [01:22<00:13,  1.76it/s]\u001B[A\n",
      "Processing videos for handsign 3:  83%|████████▎ | 113/136 [01:22<00:12,  1.81it/s]\u001B[A\n",
      "Processing videos for handsign 3:  84%|████████▍ | 114/136 [01:23<00:11,  1.86it/s]\u001B[A\n",
      "Processing videos for handsign 3:  85%|████████▍ | 115/136 [01:23<00:11,  1.76it/s]\u001B[A\n",
      "Processing videos for handsign 3:  85%|████████▌ | 116/136 [01:24<00:11,  1.67it/s]\u001B[A\n",
      "Processing videos for handsign 3:  86%|████████▌ | 117/136 [01:25<00:11,  1.61it/s]\u001B[A\n",
      "Processing videos for handsign 3:  87%|████████▋ | 118/136 [01:25<00:11,  1.54it/s]\u001B[A\n",
      "Processing videos for handsign 3:  88%|████████▊ | 119/136 [01:26<00:10,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 3:  88%|████████▊ | 120/136 [01:27<00:10,  1.56it/s]\u001B[A\n",
      "Processing videos for handsign 3:  89%|████████▉ | 121/136 [01:27<00:09,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 3:  90%|████████▉ | 122/136 [01:28<00:08,  1.60it/s]\u001B[A\n",
      "Processing videos for handsign 3:  90%|█████████ | 123/136 [01:29<00:08,  1.56it/s]\u001B[A\n",
      "Processing videos for handsign 3:  91%|█████████ | 124/136 [01:29<00:07,  1.56it/s]\u001B[A\n",
      "Processing videos for handsign 3:  92%|█████████▏| 125/136 [01:30<00:07,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 3:  93%|█████████▎| 126/136 [01:30<00:06,  1.59it/s]\u001B[A\n",
      "Processing videos for handsign 3:  93%|█████████▎| 127/136 [01:31<00:05,  1.61it/s]\u001B[A\n",
      "Processing videos for handsign 3:  94%|█████████▍| 128/136 [01:32<00:05,  1.59it/s]\u001B[A\n",
      "Processing videos for handsign 3:  95%|█████████▍| 129/136 [01:32<00:04,  1.57it/s]\u001B[A\n",
      "Processing videos for handsign 3:  96%|█████████▌| 130/136 [01:33<00:03,  1.51it/s]\u001B[A\n",
      "Processing videos for handsign 3:  96%|█████████▋| 131/136 [01:34<00:03,  1.56it/s]\u001B[A\n",
      "Processing videos for handsign 3:  97%|█████████▋| 132/136 [01:34<00:02,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 3:  98%|█████████▊| 133/136 [01:35<00:01,  1.52it/s]\u001B[A\n",
      "Processing videos for handsign 3:  99%|█████████▊| 134/136 [01:36<00:01,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 3:  99%|█████████▉| 135/136 [01:36<00:00,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 3: 100%|██████████| 136/136 [01:37<00:00,  1.50it/s]\u001B[A\n",
      "Processing handsigns: 100%|██████████| 4/4 [05:48<00:00, 87.15s/it]                \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to handsigns_data.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T02:06:22.717570Z",
     "start_time": "2024-10-11T02:06:22.702372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##        DATA AUGMENTATION (OPTIONAL)        ##\n",
    "\n",
    "#Augmentation parameters\n",
    "noise_level=0.005 #for the add_noise() function\n",
    "translation_vector=np.random.uniform(-0.05, 0.05, 3) #for the apply_translation() function\n",
    "scale_factor=np.random.uniform(0.6, 1.6) #for the apply_scaling() function\n",
    "angle_degrees=np.random.uniform(-25, 25) #for the apply_rotation()\n",
    "\n",
    "\n",
    "def apply_rotation(landmarks, angle_degrees):\n",
    "    \"\"\"Rotate the landmarks in 3D space by a given angle.\"\"\"\n",
    "    angle_radians = np.radians(angle_degrees)\n",
    "    cos_angle = np.cos(angle_radians)\n",
    "    sin_angle = np.sin(angle_radians)\n",
    "\n",
    "    # Rotation around the Z-axis (you can adjust for other axes if necessary)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_angle, -sin_angle, 0],\n",
    "        [sin_angle, cos_angle, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    return np.dot(landmarks, rotation_matrix)\n",
    "\n",
    "def apply_scaling(landmarks, scale_factor):\n",
    "    \"\"\"Scale the landmarks by a given factor.\"\"\"\n",
    "    return landmarks * scale_factor\n",
    "\n",
    "def apply_translation(landmarks, translation_vector):\n",
    "    \"\"\"Translate the landmarks by a given vector (x, y, z).\"\"\"\n",
    "    return landmarks + translation_vector\n",
    "\n",
    "def add_noise(landmarks, noise_level=0.001):\n",
    "    \"\"\"Add random noise to the landmarks.\"\"\"\n",
    "    noise = np.random.normal(0, noise_level, landmarks.shape)\n",
    "    return landmarks + noise\n",
    "\n",
    "def augment_data(data_array, num_augmented_versions=5):\n",
    "    \"\"\"\n",
    "    Augment the data array by applying transformations.\n",
    "    Creates `num_augmented_versions` augmented copies of each handsign video.\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    for handsign_data in data_array:\n",
    "        augmented_handsign_data = []\n",
    "        for video_data in handsign_data:\n",
    "            augmented_videos = [video_data]  # Start with the original video data\n",
    "\n",
    "            for _ in range(num_augmented_versions):\n",
    "                augmented_video = []\n",
    "                for frame in video_data:\n",
    "                    # Apply a combination of augmentations\n",
    "                    rotated_frame = apply_rotation(frame, angle_degrees)\n",
    "                    scaled_frame = apply_scaling(rotated_frame, scale_factor)\n",
    "                    translated_frame = apply_translation(scaled_frame, translation_vector)\n",
    "                    noisy_frame = add_noise(translated_frame, noise_level)\n",
    "\n",
    "                    augmented_video.append(noisy_frame)\n",
    "                \n",
    "                augmented_videos.append(np.array(augmented_video))\n",
    "\n",
    "            # Flatten the augmented videos for each original video\n",
    "            augmented_handsign_data.extend(augmented_videos)\n",
    "\n",
    "        augmented_data.append(np.array(augmented_handsign_data))\n",
    "    \n",
    "    return np.array(augmented_data)\n",
    "\n",
    "# Load original handsigns data\n",
    "handsigns_data = np.load('handsigns_data.npy')\n",
    "\n",
    "# Apply augmentation\n",
    "if data_augmentation:\n",
    "    \n",
    "    augmented_data = augment_data(handsigns_data, num_augmented_versions)\n",
    "    \n",
    "    # Save the augmented data to a new .npy file\n",
    "    np.save('handsigns_data_augmented.npy', augmented_data)\n",
    "    \n",
    "    # Update the videos per handsign value to match the videos generated by the augmentation\n",
    "    data_array = np.load('handsigns_data_augmented.npy')\n",
    "    videos_per_handsign = data_array.shape[1]\n",
    "    \n",
    "    print(\"Augmented data saved to handsigns_data_augmented.npy, videos_per_handsign augmented by \"+str(num_augmented_versions)+\" per existing video for a total of \"+str(videos_per_handsign)+\" videos per handsign\")\n",
    "else:\n",
    "    print(\"no data augmentation was performed\")"
   ],
   "id": "d0c17cfc27c8ccac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data saved to handsigns_data_augmented.npy, videos_per_handsign augmented by 1 per existing video for a total of 48 videos per handsign\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T00:44:11.360227Z",
     "start_time": "2024-10-11T00:44:11.309644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          MODEL DEFINITION            ##\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Reshape, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Reshape input to (frames_per_video, num_landmarks * num_coordinates)\n",
    "new_input_shape = (frames_per_video, num_landmarks * num_coordinates)\n",
    "\n",
    "model = Sequential([\n",
    "    # Reshape layer\n",
    "    Reshape((frames_per_video, num_landmarks * num_coordinates), input_shape=(frames_per_video, num_landmarks, num_coordinates)),\n",
    "    \n",
    "    # LSTM layers with Dropout and Batch Normalization to reduce overfitting\n",
    "    LSTM(64, return_sequences=True, kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    LSTM(128, return_sequences=False, kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    # Fully connected layer\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    # Output layer for multi-class classification\n",
    "    Dense(num_handsigns, activation='softmax')  # Softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Specify a learning rate\n",
    "learning_rate = 0.0005\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model.summary() # Uncomment if you want to see the model summary\n"
   ],
   "id": "c1f9d72562ce0728",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T00:44:14.064165Z",
     "start_time": "2024-10-11T00:44:14.018977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          DATA PREPROCESSING FOR TRAINING            ##\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# Load the data from the .npy file, making a copy to use for training as to not modify the original extracted data\n",
    "if data_augmentation:\n",
    "    shutil.copy('handsigns_data_augmented.npy', 'handsigns_data_training_copy.npy')\n",
    "    data_array = np.load('handsigns_data_training_copy.npy')\n",
    "    \n",
    "    # Update videos_per_handsign based on augmentation\n",
    "    #videos_per_handsign = data_array.shape[1]  # Dynamically update based on the new augmented shape\n",
    "    print(\"after augmentation videos per handsign updated to: \" + str(data_array.shape[1]))\n",
    "else:\n",
    "    shutil.copy('handsigns_data.npy', 'handsigns_data_training_copy.npy')\n",
    "    data_array = np.load('handsigns_data_training_copy.npy')\n",
    "\n",
    "\n",
    "# X remains unchanged\n",
    "X = data_array \n",
    "\n",
    "# Create labels for each handsign (0 to num_handsigns-1)\n",
    "# This creates a label for each hand sign, repeated for each video\n",
    "y = np.repeat(np.arange(num_handsigns), videos_per_handsign)\n",
    "y = y.reshape(num_handsigns, videos_per_handsign)\n",
    "\n",
    "# Initialize lists to hold training and validation data\n",
    "X_train_list = []\n",
    "X_val_list = []\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "\n",
    "# Split videos and labels for each handsign\n",
    "for handsign_index in range(num_handsigns):\n",
    "    # Split the videos within each handsign\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        np.arange(videos_per_handsign), \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Select training and validation data for this handsign\n",
    "    X_train_list.append(data_array[handsign_index, train_indices])\n",
    "    X_val_list.append(data_array[handsign_index, val_indices])\n",
    "    \n",
    "    # Select corresponding labels\n",
    "    y_train_list.append(y[handsign_index, train_indices])\n",
    "    y_val_list.append(y[handsign_index, val_indices])\n",
    "\n",
    "# Concatenate lists to form the final training and validation sets\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "X_val = np.concatenate(X_val_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "y_val = np.concatenate(y_val_list, axis=0)\n",
    "\n",
    "# Reshape X_train and X_val to fit the model's expected input shape\n",
    "X_train = X_train.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "X_val = X_val.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "\n",
    "# Flatten y_train and y_val\n",
    "y_train = y_train.flatten()\n",
    "y_val = y_val.flatten()"
   ],
   "id": "664f881d08e116f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after augmentation videos per handsign updated to: 544\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T00:45:33.878151Z",
     "start_time": "2024-10-11T00:44:22.635276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          MODEL TRAINING          ##\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Callback helpers for model training #\n",
    "# Early stopping to stop training when validation loss stops improving\n",
    "# Model checkpointing to save the best model during training\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)  \n",
    "checkpoint = ModelCheckpoint('best_handsigns_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)  \n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[early_stopping, checkpoint, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "model.save('handsigns_model.h5')\n",
    "\n",
    "# Optionally, save the training history\n",
    "import pickle\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "    \n",
    "\n",
    "    \n",
    "##          TRAINING HISTORY ANALYSIS           ##\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# If you want to save the plot instead of displaying it:\n",
    "# plt.savefig('training_history.png')"
   ],
   "id": "febb1178fa7e41a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001B[1m47/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.2946 - loss: 20.9840\n",
      "Epoch 1: val_loss improved from inf to 16.42857, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 11ms/step - accuracy: 0.2982 - loss: 20.7788 - val_accuracy: 0.3440 - val_loss: 16.4286 - learning_rate: 5.0000e-04\n",
      "Epoch 2/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.3455 - loss: 16.5227\n",
      "Epoch 2: val_loss improved from 16.42857 to 13.25227, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.3464 - loss: 16.4109 - val_accuracy: 0.3784 - val_loss: 13.2523 - learning_rate: 5.0000e-04\n",
      "Epoch 3/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.3985 - loss: 13.3120\n",
      "Epoch 3: val_loss improved from 13.25227 to 10.95412, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4004 - loss: 13.2384 - val_accuracy: 0.4037 - val_loss: 10.9541 - learning_rate: 5.0000e-04\n",
      "Epoch 4/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.4612 - loss: 10.9635\n",
      "Epoch 4: val_loss improved from 10.95412 to 9.18566, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4587 - loss: 10.9141 - val_accuracy: 0.5413 - val_loss: 9.1857 - learning_rate: 5.0000e-04\n",
      "Epoch 5/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.4806 - loss: 9.2502\n",
      "Epoch 5: val_loss improved from 9.18566 to 7.78841, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4808 - loss: 9.2105 - val_accuracy: 0.6307 - val_loss: 7.7884 - learning_rate: 5.0000e-04\n",
      "Epoch 6/500\n",
      "\u001B[1m48/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5259 - loss: 7.9235\n",
      "Epoch 6: val_loss improved from 7.78841 to 6.73368, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.5253 - loss: 7.8847 - val_accuracy: 0.6032 - val_loss: 6.7337 - learning_rate: 5.0000e-04\n",
      "Epoch 7/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5419 - loss: 6.7875\n",
      "Epoch 7: val_loss improved from 6.73368 to 5.82204, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.5438 - loss: 6.7642 - val_accuracy: 0.6812 - val_loss: 5.8220 - learning_rate: 5.0000e-04\n",
      "Epoch 8/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5820 - loss: 5.9846\n",
      "Epoch 8: val_loss improved from 5.82204 to 5.02533, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5823 - loss: 5.9804 - val_accuracy: 0.7202 - val_loss: 5.0253 - learning_rate: 5.0000e-04\n",
      "Epoch 9/500\n",
      "\u001B[1m48/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6031 - loss: 5.2117\n",
      "Epoch 9: val_loss improved from 5.02533 to 4.49722, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6058 - loss: 5.1843 - val_accuracy: 0.6950 - val_loss: 4.4972 - learning_rate: 5.0000e-04\n",
      "Epoch 10/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6463 - loss: 4.5583\n",
      "Epoch 10: val_loss improved from 4.49722 to 3.99783, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6487 - loss: 4.5361 - val_accuracy: 0.6606 - val_loss: 3.9978 - learning_rate: 5.0000e-04\n",
      "Epoch 11/500\n",
      "\u001B[1m47/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6548 - loss: 4.0329\n",
      "Epoch 11: val_loss improved from 3.99783 to 3.38027, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6586 - loss: 4.0126 - val_accuracy: 0.7936 - val_loss: 3.3803 - learning_rate: 5.0000e-04\n",
      "Epoch 12/500\n",
      "\u001B[1m46/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6804 - loss: 3.5350\n",
      "Epoch 12: val_loss improved from 3.38027 to 2.98496, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.6851 - loss: 3.5182 - val_accuracy: 0.8028 - val_loss: 2.9850 - learning_rate: 5.0000e-04\n",
      "Epoch 13/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7267 - loss: 3.1476\n",
      "Epoch 13: val_loss improved from 2.98496 to 2.65219, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7266 - loss: 3.1444 - val_accuracy: 0.8257 - val_loss: 2.6522 - learning_rate: 5.0000e-04\n",
      "Epoch 14/500\n",
      "\u001B[1m47/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7770 - loss: 2.7687\n",
      "Epoch 14: val_loss improved from 2.65219 to 2.59230, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7761 - loss: 2.7604 - val_accuracy: 0.7844 - val_loss: 2.5923 - learning_rate: 5.0000e-04\n",
      "Epoch 15/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7712 - loss: 2.5017\n",
      "Epoch 15: val_loss improved from 2.59230 to 2.20990, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7725 - loss: 2.4934 - val_accuracy: 0.7844 - val_loss: 2.2099 - learning_rate: 5.0000e-04\n",
      "Epoch 16/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7882 - loss: 2.2352\n",
      "Epoch 16: val_loss improved from 2.20990 to 2.11074, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7885 - loss: 2.2297 - val_accuracy: 0.7798 - val_loss: 2.1107 - learning_rate: 5.0000e-04\n",
      "Epoch 17/500\n",
      "\u001B[1m46/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7771 - loss: 2.0894\n",
      "Epoch 17: val_loss improved from 2.11074 to 1.79783, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.7777 - loss: 2.0734 - val_accuracy: 0.8257 - val_loss: 1.7978 - learning_rate: 5.0000e-04\n",
      "Epoch 18/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8116 - loss: 1.8245\n",
      "Epoch 18: val_loss improved from 1.79783 to 1.62206, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8118 - loss: 1.8213 - val_accuracy: 0.8532 - val_loss: 1.6221 - learning_rate: 5.0000e-04\n",
      "Epoch 19/500\n",
      "\u001B[1m52/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8236 - loss: 1.6543\n",
      "Epoch 19: val_loss improved from 1.62206 to 1.45294, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8232 - loss: 1.6530 - val_accuracy: 0.8211 - val_loss: 1.4529 - learning_rate: 5.0000e-04\n",
      "Epoch 20/500\n",
      "\u001B[1m48/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8311 - loss: 1.5201\n",
      "Epoch 20: val_loss improved from 1.45294 to 1.30660, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8295 - loss: 1.5206 - val_accuracy: 0.8761 - val_loss: 1.3066 - learning_rate: 5.0000e-04\n",
      "Epoch 21/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8274 - loss: 1.4326\n",
      "Epoch 21: val_loss improved from 1.30660 to 1.20178, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8279 - loss: 1.4307 - val_accuracy: 0.8670 - val_loss: 1.2018 - learning_rate: 5.0000e-04\n",
      "Epoch 22/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8218 - loss: 1.3379\n",
      "Epoch 22: val_loss improved from 1.20178 to 1.07587, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8222 - loss: 1.3344 - val_accuracy: 0.8784 - val_loss: 1.0759 - learning_rate: 5.0000e-04\n",
      "Epoch 23/500\n",
      "\u001B[1m47/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8353 - loss: 1.2082\n",
      "Epoch 23: val_loss did not improve from 1.07587\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8335 - loss: 1.2100 - val_accuracy: 0.8280 - val_loss: 1.1143 - learning_rate: 5.0000e-04\n",
      "Epoch 24/500\n",
      "\u001B[1m46/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8383 - loss: 1.1525\n",
      "Epoch 24: val_loss did not improve from 1.07587\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8379 - loss: 1.1514 - val_accuracy: 0.6307 - val_loss: 1.5206 - learning_rate: 5.0000e-04\n",
      "Epoch 25/500\n",
      "\u001B[1m48/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8427 - loss: 1.0762\n",
      "Epoch 25: val_loss improved from 1.07587 to 0.87297, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8432 - loss: 1.0730 - val_accuracy: 0.9106 - val_loss: 0.8730 - learning_rate: 5.0000e-04\n",
      "Epoch 26/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8369 - loss: 1.0303\n",
      "Epoch 26: val_loss did not improve from 0.87297\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8348 - loss: 1.0344 - val_accuracy: 0.7362 - val_loss: 1.2509 - learning_rate: 5.0000e-04\n",
      "Epoch 27/500\n",
      "\u001B[1m52/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8276 - loss: 1.0158\n",
      "Epoch 27: val_loss did not improve from 0.87297\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8275 - loss: 1.0150 - val_accuracy: 0.8463 - val_loss: 0.8933 - learning_rate: 5.0000e-04\n",
      "Epoch 28/500\n",
      "\u001B[1m48/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8430 - loss: 0.9455\n",
      "Epoch 28: val_loss improved from 0.87297 to 0.77185, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8418 - loss: 0.9458 - val_accuracy: 0.8968 - val_loss: 0.7719 - learning_rate: 5.0000e-04\n",
      "Epoch 29/500\n",
      "\u001B[1m47/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8250 - loss: 0.9206\n",
      "Epoch 29: val_loss did not improve from 0.77185\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8289 - loss: 0.9147 - val_accuracy: 0.8693 - val_loss: 0.7820 - learning_rate: 5.0000e-04\n",
      "Epoch 30/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8490 - loss: 0.8846\n",
      "Epoch 30: val_loss improved from 0.77185 to 0.72460, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8489 - loss: 0.8836 - val_accuracy: 0.8876 - val_loss: 0.7246 - learning_rate: 5.0000e-04\n",
      "Epoch 31/500\n",
      "\u001B[1m46/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8394 - loss: 0.8354\n",
      "Epoch 31: val_loss did not improve from 0.72460\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8400 - loss: 0.8353 - val_accuracy: 0.8716 - val_loss: 0.7335 - learning_rate: 5.0000e-04\n",
      "Epoch 32/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8582 - loss: 0.7720\n",
      "Epoch 32: val_loss improved from 0.72460 to 0.61436, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8578 - loss: 0.7724 - val_accuracy: 0.9060 - val_loss: 0.6144 - learning_rate: 5.0000e-04\n",
      "Epoch 33/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8410 - loss: 0.7987\n",
      "Epoch 33: val_loss did not improve from 0.61436\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8410 - loss: 0.7980 - val_accuracy: 0.8624 - val_loss: 0.6706 - learning_rate: 5.0000e-04\n",
      "Epoch 34/500\n",
      "\u001B[1m47/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8532 - loss: 0.7241\n",
      "Epoch 34: val_loss did not improve from 0.61436\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8548 - loss: 0.7203 - val_accuracy: 0.8096 - val_loss: 0.7629 - learning_rate: 5.0000e-04\n",
      "Epoch 35/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8538 - loss: 0.7317\n",
      "Epoch 35: val_loss improved from 0.61436 to 0.56129, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8538 - loss: 0.7319 - val_accuracy: 0.9106 - val_loss: 0.5613 - learning_rate: 5.0000e-04\n",
      "Epoch 36/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8533 - loss: 0.7302\n",
      "Epoch 36: val_loss did not improve from 0.56129\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.8538 - loss: 0.7294 - val_accuracy: 0.8876 - val_loss: 0.5935 - learning_rate: 5.0000e-04\n",
      "Epoch 37/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8502 - loss: 0.7322\n",
      "Epoch 37: val_loss did not improve from 0.56129\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8503 - loss: 0.7312 - val_accuracy: 0.9060 - val_loss: 0.5669 - learning_rate: 5.0000e-04\n",
      "Epoch 38/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8752 - loss: 0.6488\n",
      "Epoch 38: val_loss did not improve from 0.56129\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8750 - loss: 0.6491 - val_accuracy: 0.8532 - val_loss: 0.6473 - learning_rate: 5.0000e-04\n",
      "Epoch 39/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8550 - loss: 0.6611\n",
      "Epoch 39: val_loss did not improve from 0.56129\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8556 - loss: 0.6610 - val_accuracy: 0.8624 - val_loss: 0.6564 - learning_rate: 5.0000e-04\n",
      "Epoch 40/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8456 - loss: 0.6856\n",
      "Epoch 40: val_loss did not improve from 0.56129\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8458 - loss: 0.6851 - val_accuracy: 0.8555 - val_loss: 0.5943 - learning_rate: 5.0000e-04\n",
      "Epoch 41/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8738 - loss: 0.6026\n",
      "Epoch 41: val_loss improved from 0.56129 to 0.47804, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8740 - loss: 0.6029 - val_accuracy: 0.9106 - val_loss: 0.4780 - learning_rate: 2.5000e-04\n",
      "Epoch 42/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8947 - loss: 0.5664\n",
      "Epoch 42: val_loss did not improve from 0.47804\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8938 - loss: 0.5670 - val_accuracy: 0.9014 - val_loss: 0.4965 - learning_rate: 2.5000e-04\n",
      "Epoch 43/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8771 - loss: 0.5848\n",
      "Epoch 43: val_loss improved from 0.47804 to 0.44637, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8776 - loss: 0.5839 - val_accuracy: 0.9151 - val_loss: 0.4464 - learning_rate: 2.5000e-04\n",
      "Epoch 44/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8850 - loss: 0.5741\n",
      "Epoch 44: val_loss improved from 0.44637 to 0.44018, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8847 - loss: 0.5749 - val_accuracy: 0.9128 - val_loss: 0.4402 - learning_rate: 2.5000e-04\n",
      "Epoch 45/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8861 - loss: 0.5517\n",
      "Epoch 45: val_loss improved from 0.44018 to 0.43876, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8859 - loss: 0.5518 - val_accuracy: 0.9106 - val_loss: 0.4388 - learning_rate: 2.5000e-04\n",
      "Epoch 46/500\n",
      "\u001B[1m47/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9125 - loss: 0.5194\n",
      "Epoch 46: val_loss did not improve from 0.43876\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9092 - loss: 0.5237 - val_accuracy: 0.9037 - val_loss: 0.4522 - learning_rate: 2.5000e-04\n",
      "Epoch 47/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8825 - loss: 0.5685\n",
      "Epoch 47: val_loss did not improve from 0.43876\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8826 - loss: 0.5682 - val_accuracy: 0.8096 - val_loss: 0.7296 - learning_rate: 2.5000e-04\n",
      "Epoch 48/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8489 - loss: 0.5771\n",
      "Epoch 48: val_loss improved from 0.43876 to 0.43166, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8503 - loss: 0.5749 - val_accuracy: 0.9151 - val_loss: 0.4317 - learning_rate: 2.5000e-04\n",
      "Epoch 49/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8941 - loss: 0.5045\n",
      "Epoch 49: val_loss did not improve from 0.43166\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8930 - loss: 0.5067 - val_accuracy: 0.8945 - val_loss: 0.4871 - learning_rate: 2.5000e-04\n",
      "Epoch 50/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8885 - loss: 0.4981\n",
      "Epoch 50: val_loss did not improve from 0.43166\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8884 - loss: 0.4985 - val_accuracy: 0.8601 - val_loss: 0.5713 - learning_rate: 2.5000e-04\n",
      "Epoch 51/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8763 - loss: 0.5264\n",
      "Epoch 51: val_loss improved from 0.43166 to 0.40190, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8766 - loss: 0.5257 - val_accuracy: 0.9151 - val_loss: 0.4019 - learning_rate: 2.5000e-04\n",
      "Epoch 52/500\n",
      "\u001B[1m52/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9038 - loss: 0.4589\n",
      "Epoch 52: val_loss did not improve from 0.40190\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9044 - loss: 0.4581 - val_accuracy: 0.8601 - val_loss: 0.5651 - learning_rate: 2.5000e-04\n",
      "Epoch 53/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9009 - loss: 0.4819\n",
      "Epoch 53: val_loss did not improve from 0.40190\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9005 - loss: 0.4823 - val_accuracy: 0.9060 - val_loss: 0.4289 - learning_rate: 2.5000e-04\n",
      "Epoch 54/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8951 - loss: 0.4662\n",
      "Epoch 54: val_loss did not improve from 0.40190\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8950 - loss: 0.4670 - val_accuracy: 0.9128 - val_loss: 0.4264 - learning_rate: 2.5000e-04\n",
      "Epoch 55/500\n",
      "\u001B[1m47/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8829 - loss: 0.5073\n",
      "Epoch 55: val_loss improved from 0.40190 to 0.38270, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8828 - loss: 0.5074 - val_accuracy: 0.9220 - val_loss: 0.3827 - learning_rate: 2.5000e-04\n",
      "Epoch 56/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8915 - loss: 0.4670\n",
      "Epoch 56: val_loss did not improve from 0.38270\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8922 - loss: 0.4667 - val_accuracy: 0.9174 - val_loss: 0.3835 - learning_rate: 2.5000e-04\n",
      "Epoch 57/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8826 - loss: 0.4978\n",
      "Epoch 57: val_loss did not improve from 0.38270\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8835 - loss: 0.4970 - val_accuracy: 0.9174 - val_loss: 0.4037 - learning_rate: 2.5000e-04\n",
      "Epoch 58/500\n",
      "\u001B[1m47/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8751 - loss: 0.4951\n",
      "Epoch 58: val_loss did not improve from 0.38270\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8770 - loss: 0.4919 - val_accuracy: 0.9106 - val_loss: 0.3834 - learning_rate: 2.5000e-04\n",
      "Epoch 59/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8902 - loss: 0.4712\n",
      "Epoch 59: val_loss did not improve from 0.38270\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8900 - loss: 0.4716 - val_accuracy: 0.8761 - val_loss: 0.4655 - learning_rate: 2.5000e-04\n",
      "Epoch 60/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8862 - loss: 0.4819\n",
      "Epoch 60: val_loss improved from 0.38270 to 0.37181, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8870 - loss: 0.4799 - val_accuracy: 0.9220 - val_loss: 0.3718 - learning_rate: 2.5000e-04\n",
      "Epoch 61/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8913 - loss: 0.4962\n",
      "Epoch 61: val_loss did not improve from 0.37181\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8913 - loss: 0.4957 - val_accuracy: 0.9151 - val_loss: 0.3827 - learning_rate: 2.5000e-04\n",
      "Epoch 62/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8915 - loss: 0.4541\n",
      "Epoch 62: val_loss did not improve from 0.37181\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8919 - loss: 0.4547 - val_accuracy: 0.8853 - val_loss: 0.4304 - learning_rate: 2.5000e-04\n",
      "Epoch 63/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9069 - loss: 0.4414\n",
      "Epoch 63: val_loss improved from 0.37181 to 0.34734, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9065 - loss: 0.4410 - val_accuracy: 0.9243 - val_loss: 0.3473 - learning_rate: 2.5000e-04\n",
      "Epoch 64/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9092 - loss: 0.4304\n",
      "Epoch 64: val_loss did not improve from 0.34734\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9082 - loss: 0.4322 - val_accuracy: 0.9174 - val_loss: 0.3544 - learning_rate: 2.5000e-04\n",
      "Epoch 65/500\n",
      "\u001B[1m48/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8966 - loss: 0.4592\n",
      "Epoch 65: val_loss did not improve from 0.34734\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8973 - loss: 0.4540 - val_accuracy: 0.9174 - val_loss: 0.3766 - learning_rate: 2.5000e-04\n",
      "Epoch 66/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9097 - loss: 0.4282\n",
      "Epoch 66: val_loss did not improve from 0.34734\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9095 - loss: 0.4286 - val_accuracy: 0.9174 - val_loss: 0.3557 - learning_rate: 2.5000e-04\n",
      "Epoch 67/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8999 - loss: 0.4172\n",
      "Epoch 67: val_loss did not improve from 0.34734\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8991 - loss: 0.4176 - val_accuracy: 0.8830 - val_loss: 0.4309 - learning_rate: 2.5000e-04\n",
      "Epoch 68/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8921 - loss: 0.4749\n",
      "Epoch 68: val_loss did not improve from 0.34734\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8919 - loss: 0.4750 - val_accuracy: 0.8922 - val_loss: 0.4133 - learning_rate: 2.5000e-04\n",
      "Epoch 69/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9155 - loss: 0.4043\n",
      "Epoch 69: val_loss did not improve from 0.34734\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9150 - loss: 0.4052 - val_accuracy: 0.9197 - val_loss: 0.3511 - learning_rate: 1.2500e-04\n",
      "Epoch 70/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8961 - loss: 0.4456\n",
      "Epoch 70: val_loss did not improve from 0.34734\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8960 - loss: 0.4455 - val_accuracy: 0.8991 - val_loss: 0.3918 - learning_rate: 1.2500e-04\n",
      "Epoch 71/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9093 - loss: 0.4047\n",
      "Epoch 71: val_loss improved from 0.34734 to 0.31737, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9096 - loss: 0.4043 - val_accuracy: 0.9266 - val_loss: 0.3174 - learning_rate: 1.2500e-04\n",
      "Epoch 72/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9058 - loss: 0.3939\n",
      "Epoch 72: val_loss did not improve from 0.31737\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9054 - loss: 0.3949 - val_accuracy: 0.9220 - val_loss: 0.3185 - learning_rate: 1.2500e-04\n",
      "Epoch 73/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8992 - loss: 0.4162\n",
      "Epoch 73: val_loss did not improve from 0.31737\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8992 - loss: 0.4161 - val_accuracy: 0.9197 - val_loss: 0.3757 - learning_rate: 1.2500e-04\n",
      "Epoch 74/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8991 - loss: 0.4250\n",
      "Epoch 74: val_loss did not improve from 0.31737\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8991 - loss: 0.4251 - val_accuracy: 0.9014 - val_loss: 0.4016 - learning_rate: 1.2500e-04\n",
      "Epoch 75/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8822 - loss: 0.4426\n",
      "Epoch 75: val_loss did not improve from 0.31737\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8828 - loss: 0.4414 - val_accuracy: 0.9266 - val_loss: 0.3311 - learning_rate: 1.2500e-04\n",
      "Epoch 76/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9014 - loss: 0.4067\n",
      "Epoch 76: val_loss did not improve from 0.31737\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9017 - loss: 0.4059 - val_accuracy: 0.9243 - val_loss: 0.3255 - learning_rate: 1.2500e-04\n",
      "Epoch 77/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9234 - loss: 0.3809\n",
      "Epoch 77: val_loss improved from 0.31737 to 0.30443, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9229 - loss: 0.3813 - val_accuracy: 0.9243 - val_loss: 0.3044 - learning_rate: 6.2500e-05\n",
      "Epoch 78/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9058 - loss: 0.3829\n",
      "Epoch 78: val_loss did not improve from 0.30443\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9059 - loss: 0.3828 - val_accuracy: 0.9174 - val_loss: 0.3198 - learning_rate: 6.2500e-05\n",
      "Epoch 79/500\n",
      "\u001B[1m47/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9091 - loss: 0.3883\n",
      "Epoch 79: val_loss improved from 0.30443 to 0.30369, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9088 - loss: 0.3878 - val_accuracy: 0.9220 - val_loss: 0.3037 - learning_rate: 6.2500e-05\n",
      "Epoch 80/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9136 - loss: 0.3691\n",
      "Epoch 80: val_loss did not improve from 0.30369\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9136 - loss: 0.3691 - val_accuracy: 0.9220 - val_loss: 0.3074 - learning_rate: 6.2500e-05\n",
      "Epoch 81/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9025 - loss: 0.3781\n",
      "Epoch 81: val_loss did not improve from 0.30369\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9035 - loss: 0.3762 - val_accuracy: 0.9266 - val_loss: 0.3134 - learning_rate: 6.2500e-05\n",
      "Epoch 82/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9145 - loss: 0.3673\n",
      "Epoch 82: val_loss improved from 0.30369 to 0.30319, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9139 - loss: 0.3684 - val_accuracy: 0.9243 - val_loss: 0.3032 - learning_rate: 6.2500e-05\n",
      "Epoch 83/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9150 - loss: 0.3831\n",
      "Epoch 83: val_loss did not improve from 0.30319\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9151 - loss: 0.3823 - val_accuracy: 0.9266 - val_loss: 0.3107 - learning_rate: 6.2500e-05\n",
      "Epoch 84/500\n",
      "\u001B[1m52/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9014 - loss: 0.4009\n",
      "Epoch 84: val_loss improved from 0.30319 to 0.29887, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9016 - loss: 0.4007 - val_accuracy: 0.9312 - val_loss: 0.2989 - learning_rate: 6.2500e-05\n",
      "Epoch 85/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9155 - loss: 0.3635\n",
      "Epoch 85: val_loss did not improve from 0.29887\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9151 - loss: 0.3629 - val_accuracy: 0.9174 - val_loss: 0.3030 - learning_rate: 6.2500e-05\n",
      "Epoch 86/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9228 - loss: 0.3404\n",
      "Epoch 86: val_loss did not improve from 0.29887\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9223 - loss: 0.3412 - val_accuracy: 0.9266 - val_loss: 0.3014 - learning_rate: 6.2500e-05\n",
      "Epoch 87/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9260 - loss: 0.3421\n",
      "Epoch 87: val_loss did not improve from 0.29887\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9254 - loss: 0.3427 - val_accuracy: 0.9220 - val_loss: 0.3139 - learning_rate: 6.2500e-05\n",
      "Epoch 88/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9317 - loss: 0.3379\n",
      "Epoch 88: val_loss improved from 0.29887 to 0.29209, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9308 - loss: 0.3388 - val_accuracy: 0.9266 - val_loss: 0.2921 - learning_rate: 6.2500e-05\n",
      "Epoch 89/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9090 - loss: 0.3511\n",
      "Epoch 89: val_loss did not improve from 0.29209\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9091 - loss: 0.3516 - val_accuracy: 0.9220 - val_loss: 0.2926 - learning_rate: 6.2500e-05\n",
      "Epoch 90/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9247 - loss: 0.3441\n",
      "Epoch 90: val_loss improved from 0.29209 to 0.28234, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9240 - loss: 0.3446 - val_accuracy: 0.9312 - val_loss: 0.2823 - learning_rate: 6.2500e-05\n",
      "Epoch 91/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9208 - loss: 0.3519\n",
      "Epoch 91: val_loss did not improve from 0.28234\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 13ms/step - accuracy: 0.9205 - loss: 0.3525 - val_accuracy: 0.9266 - val_loss: 0.2875 - learning_rate: 6.2500e-05\n",
      "Epoch 92/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9284 - loss: 0.3392\n",
      "Epoch 92: val_loss did not improve from 0.28234\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.9282 - loss: 0.3394 - val_accuracy: 0.9289 - val_loss: 0.2933 - learning_rate: 6.2500e-05\n",
      "Epoch 93/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9269 - loss: 0.3393\n",
      "Epoch 93: val_loss did not improve from 0.28234\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9263 - loss: 0.3400 - val_accuracy: 0.9243 - val_loss: 0.2882 - learning_rate: 6.2500e-05\n",
      "Epoch 94/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9191 - loss: 0.3468\n",
      "Epoch 94: val_loss did not improve from 0.28234\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9183 - loss: 0.3481 - val_accuracy: 0.9220 - val_loss: 0.2914 - learning_rate: 6.2500e-05\n",
      "Epoch 95/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9043 - loss: 0.3783\n",
      "Epoch 95: val_loss did not improve from 0.28234\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9047 - loss: 0.3776 - val_accuracy: 0.9243 - val_loss: 0.2911 - learning_rate: 6.2500e-05\n",
      "Epoch 96/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9028 - loss: 0.3447\n",
      "Epoch 96: val_loss did not improve from 0.28234\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9032 - loss: 0.3453 - val_accuracy: 0.9243 - val_loss: 0.2898 - learning_rate: 3.1250e-05\n",
      "Epoch 97/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9213 - loss: 0.3345\n",
      "Epoch 97: val_loss did not improve from 0.28234\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9213 - loss: 0.3349 - val_accuracy: 0.9266 - val_loss: 0.2834 - learning_rate: 3.1250e-05\n",
      "Epoch 98/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9170 - loss: 0.3451\n",
      "Epoch 98: val_loss improved from 0.28234 to 0.27023, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9169 - loss: 0.3452 - val_accuracy: 0.9358 - val_loss: 0.2702 - learning_rate: 3.1250e-05\n",
      "Epoch 99/500\n",
      "\u001B[1m52/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9096 - loss: 0.3484\n",
      "Epoch 99: val_loss improved from 0.27023 to 0.26879, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9102 - loss: 0.3479 - val_accuracy: 0.9381 - val_loss: 0.2688 - learning_rate: 3.1250e-05\n",
      "Epoch 100/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9202 - loss: 0.3375\n",
      "Epoch 100: val_loss did not improve from 0.26879\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9189 - loss: 0.3397 - val_accuracy: 0.9243 - val_loss: 0.2780 - learning_rate: 3.1250e-05\n",
      "Epoch 101/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9131 - loss: 0.3360\n",
      "Epoch 101: val_loss did not improve from 0.26879\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9131 - loss: 0.3359 - val_accuracy: 0.9335 - val_loss: 0.2729 - learning_rate: 3.1250e-05\n",
      "Epoch 102/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9251 - loss: 0.3303\n",
      "Epoch 102: val_loss improved from 0.26879 to 0.26598, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9238 - loss: 0.3317 - val_accuracy: 0.9381 - val_loss: 0.2660 - learning_rate: 3.1250e-05\n",
      "Epoch 103/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9157 - loss: 0.3350\n",
      "Epoch 103: val_loss did not improve from 0.26598\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9163 - loss: 0.3341 - val_accuracy: 0.9335 - val_loss: 0.2666 - learning_rate: 3.1250e-05\n",
      "Epoch 104/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9230 - loss: 0.3234\n",
      "Epoch 104: val_loss did not improve from 0.26598\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9222 - loss: 0.3245 - val_accuracy: 0.9312 - val_loss: 0.2685 - learning_rate: 3.1250e-05\n",
      "Epoch 105/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9149 - loss: 0.3397\n",
      "Epoch 105: val_loss did not improve from 0.26598\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9140 - loss: 0.3404 - val_accuracy: 0.9266 - val_loss: 0.2878 - learning_rate: 3.1250e-05\n",
      "Epoch 106/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9126 - loss: 0.3498\n",
      "Epoch 106: val_loss did not improve from 0.26598\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9127 - loss: 0.3489 - val_accuracy: 0.9312 - val_loss: 0.2709 - learning_rate: 3.1250e-05\n",
      "Epoch 107/500\n",
      "\u001B[1m47/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9067 - loss: 0.3586\n",
      "Epoch 107: val_loss did not improve from 0.26598\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9078 - loss: 0.3553 - val_accuracy: 0.9289 - val_loss: 0.2767 - learning_rate: 3.1250e-05\n",
      "Epoch 108/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9294 - loss: 0.3220\n",
      "Epoch 108: val_loss did not improve from 0.26598\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9291 - loss: 0.3220 - val_accuracy: 0.9358 - val_loss: 0.2688 - learning_rate: 1.5625e-05\n",
      "Epoch 109/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9171 - loss: 0.3200\n",
      "Epoch 109: val_loss did not improve from 0.26598\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9169 - loss: 0.3205 - val_accuracy: 0.9289 - val_loss: 0.2723 - learning_rate: 1.5625e-05\n",
      "Epoch 110/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9098 - loss: 0.3386\n",
      "Epoch 110: val_loss did not improve from 0.26598\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9112 - loss: 0.3374 - val_accuracy: 0.9335 - val_loss: 0.2683 - learning_rate: 1.5625e-05\n",
      "Epoch 111/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9270 - loss: 0.3301\n",
      "Epoch 111: val_loss improved from 0.26598 to 0.26503, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9265 - loss: 0.3296 - val_accuracy: 0.9335 - val_loss: 0.2650 - learning_rate: 1.5625e-05\n",
      "Epoch 112/500\n",
      "\u001B[1m52/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9241 - loss: 0.3220\n",
      "Epoch 112: val_loss did not improve from 0.26503\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9236 - loss: 0.3231 - val_accuracy: 0.9335 - val_loss: 0.2656 - learning_rate: 1.5625e-05\n",
      "Epoch 113/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9207 - loss: 0.3459\n",
      "Epoch 113: val_loss improved from 0.26503 to 0.26010, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.9212 - loss: 0.3439 - val_accuracy: 0.9335 - val_loss: 0.2601 - learning_rate: 1.5625e-05\n",
      "Epoch 114/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9125 - loss: 0.3278\n",
      "Epoch 114: val_loss did not improve from 0.26010\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.9126 - loss: 0.3277 - val_accuracy: 0.9358 - val_loss: 0.2612 - learning_rate: 1.5625e-05\n",
      "Epoch 115/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9356 - loss: 0.2977\n",
      "Epoch 115: val_loss did not improve from 0.26010\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9348 - loss: 0.3001 - val_accuracy: 0.9358 - val_loss: 0.2637 - learning_rate: 1.5625e-05\n",
      "Epoch 116/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9216 - loss: 0.3259\n",
      "Epoch 116: val_loss did not improve from 0.26010\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9209 - loss: 0.3266 - val_accuracy: 0.9358 - val_loss: 0.2661 - learning_rate: 1.5625e-05\n",
      "Epoch 117/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9242 - loss: 0.3325\n",
      "Epoch 117: val_loss did not improve from 0.26010\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9242 - loss: 0.3322 - val_accuracy: 0.9358 - val_loss: 0.2633 - learning_rate: 1.5625e-05\n",
      "Epoch 118/500\n",
      "\u001B[1m52/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9126 - loss: 0.3316\n",
      "Epoch 118: val_loss did not improve from 0.26010\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9134 - loss: 0.3307 - val_accuracy: 0.9335 - val_loss: 0.2634 - learning_rate: 1.5625e-05\n",
      "Epoch 119/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9304 - loss: 0.3143\n",
      "Epoch 119: val_loss did not improve from 0.26010\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9301 - loss: 0.3148 - val_accuracy: 0.9358 - val_loss: 0.2635 - learning_rate: 7.8125e-06\n",
      "Epoch 120/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9154 - loss: 0.3183\n",
      "Epoch 120: val_loss did not improve from 0.26010\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9154 - loss: 0.3184 - val_accuracy: 0.9335 - val_loss: 0.2641 - learning_rate: 7.8125e-06\n",
      "Epoch 121/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9121 - loss: 0.3260\n",
      "Epoch 121: val_loss did not improve from 0.26010\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9124 - loss: 0.3257 - val_accuracy: 0.9358 - val_loss: 0.2604 - learning_rate: 7.8125e-06\n",
      "Epoch 122/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9141 - loss: 0.3117\n",
      "Epoch 122: val_loss improved from 0.26010 to 0.25757, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 13ms/step - accuracy: 0.9142 - loss: 0.3116 - val_accuracy: 0.9381 - val_loss: 0.2576 - learning_rate: 7.8125e-06\n",
      "Epoch 123/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9283 - loss: 0.3087\n",
      "Epoch 123: val_loss did not improve from 0.25757\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9278 - loss: 0.3095 - val_accuracy: 0.9358 - val_loss: 0.2579 - learning_rate: 7.8125e-06\n",
      "Epoch 124/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9147 - loss: 0.3258\n",
      "Epoch 124: val_loss did not improve from 0.25757\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9148 - loss: 0.3257 - val_accuracy: 0.9381 - val_loss: 0.2589 - learning_rate: 7.8125e-06\n",
      "Epoch 125/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9196 - loss: 0.3117\n",
      "Epoch 125: val_loss did not improve from 0.25757\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9191 - loss: 0.3132 - val_accuracy: 0.9381 - val_loss: 0.2597 - learning_rate: 7.8125e-06\n",
      "Epoch 126/500\n",
      "\u001B[1m53/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9155 - loss: 0.3120\n",
      "Epoch 126: val_loss improved from 0.25757 to 0.25750, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9161 - loss: 0.3113 - val_accuracy: 0.9404 - val_loss: 0.2575 - learning_rate: 7.8125e-06\n",
      "Epoch 127/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9161 - loss: 0.3199\n",
      "Epoch 127: val_loss did not improve from 0.25750\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9164 - loss: 0.3198 - val_accuracy: 0.9381 - val_loss: 0.2578 - learning_rate: 7.8125e-06\n",
      "Epoch 128/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9201 - loss: 0.3168\n",
      "Epoch 128: val_loss did not improve from 0.25750\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9202 - loss: 0.3164 - val_accuracy: 0.9358 - val_loss: 0.2587 - learning_rate: 3.9063e-06\n",
      "Epoch 129/500\n",
      "\u001B[1m49/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9294 - loss: 0.3067\n",
      "Epoch 129: val_loss did not improve from 0.25750\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9287 - loss: 0.3078 - val_accuracy: 0.9358 - val_loss: 0.2584 - learning_rate: 3.9063e-06\n",
      "Epoch 130/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9058 - loss: 0.3346\n",
      "Epoch 130: val_loss improved from 0.25750 to 0.25625, saving model to best_handsigns_model.keras\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.9068 - loss: 0.3332 - val_accuracy: 0.9358 - val_loss: 0.2563 - learning_rate: 3.9063e-06\n",
      "Epoch 131/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9320 - loss: 0.3224\n",
      "Epoch 131: val_loss did not improve from 0.25625\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9318 - loss: 0.3222 - val_accuracy: 0.9358 - val_loss: 0.2575 - learning_rate: 3.9063e-06\n",
      "Epoch 132/500\n",
      "\u001B[1m50/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9318 - loss: 0.3084\n",
      "Epoch 132: val_loss did not improve from 0.25625\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9308 - loss: 0.3088 - val_accuracy: 0.9381 - val_loss: 0.2569 - learning_rate: 3.9063e-06\n",
      "Epoch 133/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9128 - loss: 0.3585\n",
      "Epoch 133: val_loss did not improve from 0.25625\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9129 - loss: 0.3581 - val_accuracy: 0.9381 - val_loss: 0.2571 - learning_rate: 3.9063e-06\n",
      "Epoch 134/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9287 - loss: 0.3064\n",
      "Epoch 134: val_loss did not improve from 0.25625\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9284 - loss: 0.3068 - val_accuracy: 0.9358 - val_loss: 0.2584 - learning_rate: 3.9063e-06\n",
      "Epoch 135/500\n",
      "\u001B[1m51/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9113 - loss: 0.3312\n",
      "Epoch 135: val_loss did not improve from 0.25625\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9115 - loss: 0.3310 - val_accuracy: 0.9358 - val_loss: 0.2598 - learning_rate: 3.9063e-06\n",
      "Epoch 136/500\n",
      "\u001B[1m52/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9337 - loss: 0.2974\n",
      "Epoch 136: val_loss did not improve from 0.25625\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9332 - loss: 0.2985 - val_accuracy: 0.9358 - val_loss: 0.2595 - learning_rate: 1.9531e-06\n",
      "Epoch 137/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9384 - loss: 0.2909\n",
      "Epoch 137: val_loss did not improve from 0.25625\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9382 - loss: 0.2912 - val_accuracy: 0.9358 - val_loss: 0.2592 - learning_rate: 1.9531e-06\n",
      "Epoch 138/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9271 - loss: 0.3254\n",
      "Epoch 138: val_loss did not improve from 0.25625\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9270 - loss: 0.3251 - val_accuracy: 0.9358 - val_loss: 0.2590 - learning_rate: 1.9531e-06\n",
      "Epoch 139/500\n",
      "\u001B[1m54/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9283 - loss: 0.3085\n",
      "Epoch 139: val_loss did not improve from 0.25625\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9280 - loss: 0.3088 - val_accuracy: 0.9381 - val_loss: 0.2580 - learning_rate: 1.9531e-06\n",
      "Epoch 140/500\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9284 - loss: 0.2993\n",
      "Epoch 140: val_loss did not improve from 0.25625\n",
      "\u001B[1m55/55\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 10ms/step - accuracy: 0.9284 - loss: 0.2994 - val_accuracy: 0.9381 - val_loss: 0.2573 - learning_rate: 1.9531e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "##          SINGLE VIDEO PREDICTION TEST         ##\n",
    "def predict_handsign(video_path, model):\n",
    "    # Process the video to extract landmarks\n",
    "    video_data = process_video(video_path)\n",
    "    \n",
    "    # Reshape the data to match the model input shape (add batch dimension for a single video)\n",
    "    video_data = video_data.reshape(1, frames_per_video, num_landmarks, num_coordinates)\n",
    "        # Make the prediction\n",
    "    prediction = model.predict(video_data)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    \n",
    "    return predicted_class, confidence  \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model('best_handsigns_model.keras')\n",
    "    \n",
    "    test_directory = \"Model testing videos\"\n",
    "    for video_file in os.listdir(test_directory):\n",
    "        if video_file.endswith(('.mp4', '.avi', '.mov')):\n",
    "            video_path = os.path.join(test_directory, video_file)\n",
    "            predicted_class, confidence = predict_handsign(video_path, model)\n",
    "            \n",
    "            # Get hand sign name\n",
    "            predicted_handsign = handsign_names.get(predicted_class, f\"HandSign_{predicted_class}\")\n",
    "            \n",
    "            # Apply confidence threshold\n",
    "            if confidence < 0.7:\n",
    "                predicted_handsign = \"Inseguro (\"+predicted_handsign+\")\"\n",
    "                \n",
    "            print(f\"Video: {video_file}\")\n",
    "            print(f\"Predicted Hand Sign: {predicted_handsign}\")\n",
    "            print(f\"Confidence: {confidence:.2f}\")\n",
    "            print(\"--------------------\")\n"
   ],
   "id": "4f9ed1d4df51b1c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T00:49:01.292844Z",
     "start_time": "2024-10-11T00:48:05.076424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          CONTINUOUS PREDICTION WITH SLIDING WINDOW           ##\n",
    "\n",
    "import collections\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from scipy.interpolate import interp1d  # For smoothing landmarks\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('best_handsigns_model.keras')\n",
    "\n",
    "# Initialize Mediapipe solutions outside the loop for efficiency\n",
    "mp_hands = mp.solutions.hands.Hands(static_image_mode=False, \n",
    "                                    max_num_hands=2, \n",
    "                                    min_detection_confidence=0.4,  # Lowered confidence to allow for fast movement detection\n",
    "                                    min_tracking_confidence=0.4)   # Lowered tracking confidence\n",
    "mp_pose = mp.solutions.pose.Pose(static_image_mode=False, \n",
    "                                 min_detection_confidence=0.4, \n",
    "                                 min_tracking_confidence=0.4)\n",
    "\n",
    "# Open webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Sliding window buffer for frames\n",
    "frame_buffer = collections.deque(maxlen=frames_per_video)\n",
    "\n",
    "# To smooth predictions, keep track of recent predictions\n",
    "prediction_buffer = collections.deque(maxlen=3)\n",
    "\n",
    "# Store the last prediction\n",
    "last_prediction = \"No Prediction\"\n",
    "last_confidence = 0.0\n",
    "\n",
    "# Track missing hands to reset landmarks if missing for too long\n",
    "hand_missing_threshold = 5\n",
    "left_hand_missing_count = 0\n",
    "right_hand_missing_count = 0\n",
    "\n",
    "# Store the last known hand landmarks to compare in future frames\n",
    "last_left_hand_landmarks = None\n",
    "last_right_hand_landmarks = None\n",
    "\n",
    "# Movement delta threshold for fast movements\n",
    "movement_threshold = 0.9  # Adjusted threshold for movement delta\n",
    "\n",
    "# Smoothing factor for missing landmarks\n",
    "smoothing_factor = 0.8  # Weight to smooth landmarks during quick movements\n",
    "\n",
    "# Draw landmarks on the frame\n",
    "def draw_landmarks(frame, landmarks):\n",
    "    \"\"\"Draw landmarks on the frame.\"\"\"\n",
    "    for i, (x, y, z) in enumerate(landmarks):\n",
    "        h, w, _ = frame.shape\n",
    "        x = int(x * w + 325)\n",
    "        y = int(y * h + 250)\n",
    "        \n",
    "        if i < 21:  # Left hand landmarks\n",
    "            color = (0, 255, 0)\n",
    "        elif i < 42:  # Right hand landmarks\n",
    "            color = (0, 0, 255)\n",
    "        else:  # Body landmarks\n",
    "            color = (255, 0, 0)\n",
    "        \n",
    "        cv2.circle(frame, (x, y), 5, color, -1)\n",
    "\n",
    "def smooth_landmarks(new_landmarks, old_landmarks):\n",
    "    \"\"\"Smooth landmarks by interpolating between old and new.\"\"\"\n",
    "    if old_landmarks is None:\n",
    "        return new_landmarks\n",
    "\n",
    "    return old_landmarks * (1 - smoothing_factor) + new_landmarks * smoothing_factor\n",
    "\n",
    "def process_frame(frame):\n",
    "    global last_left_hand_landmarks, last_right_hand_landmarks\n",
    "    global left_hand_missing_count, right_hand_missing_count\n",
    "\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    hands_results = mp_hands.process(image)\n",
    "    pose_results = mp_pose.process(image)\n",
    "\n",
    "    # Initialize a zero-filled array for landmarks (51 landmarks, each with x, y, z)\n",
    "    landmarks = np.zeros((num_landmarks, num_coordinates))\n",
    "\n",
    "    # Detect nose for relative normalization\n",
    "    try:\n",
    "        nose_landmark = pose_results.pose_landmarks.landmark[0]\n",
    "    except:\n",
    "        class nose_landmark:\n",
    "            x = 0\n",
    "            y = 0\n",
    "            z = 0\n",
    "        nose_landmark = nose_landmark()\n",
    "\n",
    "    if hands_results.multi_hand_landmarks:\n",
    "        handedness_labels = [hand.classification[0].label for hand in hands_results.multi_handedness]\n",
    "\n",
    "        for i, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):\n",
    "            if handedness_labels[i] == 'Left':\n",
    "                left_hand = np.array([(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) \n",
    "                                      for lm in hand_landmarks.landmark])\n",
    "\n",
    "                # Smooth the transition between frames\n",
    "                left_hand = smooth_landmarks(left_hand, last_left_hand_landmarks)\n",
    "                \n",
    "                # Update the stored landmarks for the next frame\n",
    "                last_left_hand_landmarks = left_hand\n",
    "                landmarks[:21] = left_hand  # Insert the left hand landmarks into the first 21 slots\n",
    "\n",
    "            elif handedness_labels[i] == 'Right':\n",
    "                right_hand = np.array([(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) \n",
    "                                       for lm in hand_landmarks.landmark])\n",
    "\n",
    "                # Smooth the transition between frames\n",
    "                right_hand = smooth_landmarks(right_hand, last_right_hand_landmarks)\n",
    "                \n",
    "                # Update the stored landmarks for the next frame\n",
    "                last_right_hand_landmarks = right_hand\n",
    "                landmarks[21:42] = right_hand  # Insert the right hand landmarks into slots 21-42\n",
    "\n",
    "        # Reset the missing counts if hands are detected\n",
    "        left_hand_missing_count = 0\n",
    "        right_hand_missing_count = 0\n",
    "    else:\n",
    "        # Increment missing count when hands are not detected\n",
    "        left_hand_missing_count += 1\n",
    "        right_hand_missing_count += 1\n",
    "\n",
    "        # Reuse last known landmarks if available and hands are missing for too long\n",
    "        if last_left_hand_landmarks is not None:\n",
    "            landmarks[:21] = last_left_hand_landmarks\n",
    "        if last_right_hand_landmarks is not None:\n",
    "            landmarks[21:42] = last_right_hand_landmarks\n",
    "\n",
    "        # Reset landmarks if hands are missing for too long\n",
    "        if left_hand_missing_count > hand_missing_threshold:\n",
    "            last_left_hand_landmarks = None\n",
    "        if right_hand_missing_count > hand_missing_threshold:\n",
    "            last_right_hand_landmarks = None\n",
    "\n",
    "    # Fill in body landmarks (9 selected)\n",
    "    selected_body_landmarks = [0, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "    if pose_results.pose_landmarks:\n",
    "        for idx, landmark_idx in enumerate(selected_body_landmarks):\n",
    "            lm = pose_results.pose_landmarks.landmark[landmark_idx]\n",
    "            landmarks[42 + idx] = (lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z)\n",
    "\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "# Make a prediction based on the buffer\n",
    "def predict_handsign(buffer):\n",
    "    \"\"\"Make a prediction based on a buffer of frames.\"\"\"    \n",
    "    video_data = np.array(buffer)\n",
    "    video_data = video_data.reshape(1, frames_per_video, num_landmarks, num_coordinates)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(video_data, verbose=0)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_class]\n",
    "\n",
    "    return predicted_class, confidence\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Process every frame (no skipping)\n",
    "    landmarks = process_frame(frame)\n",
    "\n",
    "    # Add the landmarks to the frame buffer\n",
    "    frame_buffer.append(landmarks)\n",
    "\n",
    "    # Draw the landmarks on the frame\n",
    "    draw_landmarks(frame, landmarks)\n",
    "\n",
    "    # Once the buffer is full, make a prediction using the sliding window\n",
    "    if len(frame_buffer) == frames_per_video:\n",
    "        predicted_class, confidence = predict_handsign(frame_buffer)\n",
    "        predicted_handsign = handsign_names.get(predicted_class, f\"HandSign_{predicted_class}\")\n",
    "\n",
    "        # Update the last prediction\n",
    "        last_prediction = predicted_handsign\n",
    "        last_confidence = confidence\n",
    "\n",
    "        # Store prediction and confidence in the buffer for smoothing\n",
    "        print((predicted_class, confidence))\n",
    "        prediction_buffer.append((predicted_class, confidence))\n",
    "\n",
    "        # Average the last N predictions to smooth the output\n",
    "        avg_pred_class = np.argmax(np.bincount([p[0] for p in prediction_buffer]))\n",
    "        avg_confidence = np.mean([p[1] for p in prediction_buffer if p[0] == avg_pred_class])\n",
    "\n",
    "        if avg_confidence > 0.8:\n",
    "            last_prediction = handsign_names.get(avg_pred_class, f\"HandSign_{avg_pred_class}\")\n",
    "            last_confidence = avg_confidence\n",
    "        elif 0.45 < avg_confidence < 0.8:\n",
    "            last_prediction = \"deteccion insegura: \"+handsign_names.get(avg_pred_class, f\"HandSign_{avg_pred_class}\")\n",
    "            last_confidence = avg_confidence\n",
    "        else:\n",
    "            last_prediction = \"deteccion nula\"\n",
    "            last_confidence = avg_confidence\n",
    "            \n",
    "    # Display the last prediction on the frame\n",
    "    cv2.putText(frame, f\"Predicted: {last_prediction} Conf: {last_confidence:.2f}\", \n",
    "                (10, 30), cv2.FONT_ITALIC, 0.7, (0, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('Hands Recognition', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "ee106e95cdc75678",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.97838724)\n",
      "(0, 0.9954774)\n",
      "(0, 0.9951037)\n",
      "(0, 0.98615175)\n",
      "(0, 0.90928227)\n",
      "(0, 0.57304335)\n",
      "(1, 0.447943)\n",
      "(3, 0.5251119)\n",
      "(3, 0.5808057)\n",
      "(3, 0.6230256)\n",
      "(3, 0.46068683)\n",
      "(3, 0.3753471)\n",
      "(3, 0.33169287)\n",
      "(1, 0.2860005)\n",
      "(0, 0.3087752)\n",
      "(0, 0.38757145)\n",
      "(0, 0.4074373)\n",
      "(0, 0.4067363)\n",
      "(0, 0.39298075)\n",
      "(0, 0.39478242)\n",
      "(0, 0.39286348)\n",
      "(0, 0.39237496)\n",
      "(0, 0.40828562)\n",
      "(0, 0.46494734)\n",
      "(0, 0.5032218)\n",
      "(0, 0.52032244)\n",
      "(0, 0.642009)\n",
      "(0, 0.73598945)\n",
      "(0, 0.81641126)\n",
      "(0, 0.8003146)\n",
      "(0, 0.6032168)\n",
      "(1, 0.59286636)\n",
      "(1, 0.8880304)\n",
      "(1, 0.96464425)\n",
      "(1, 0.9880172)\n",
      "(1, 0.9956136)\n",
      "(1, 0.9979652)\n",
      "(1, 0.9989237)\n",
      "(1, 0.9993399)\n",
      "(1, 0.9994486)\n",
      "(1, 0.9994886)\n",
      "(1, 0.99949515)\n",
      "(1, 0.999496)\n",
      "(1, 0.99951375)\n",
      "(1, 0.99952877)\n",
      "(1, 0.99953794)\n",
      "(1, 0.9995347)\n",
      "(1, 0.9995153)\n",
      "(1, 0.99947065)\n",
      "(1, 0.9993887)\n",
      "(1, 0.9992411)\n",
      "(1, 0.99898654)\n",
      "(1, 0.9985514)\n",
      "(1, 0.9976993)\n",
      "(1, 0.99588)\n",
      "(1, 0.99127066)\n",
      "(1, 0.98447937)\n",
      "(1, 0.97032386)\n",
      "(1, 0.9539358)\n",
      "(1, 0.9378359)\n",
      "(1, 0.9046542)\n",
      "(1, 0.85538435)\n",
      "(1, 0.7829272)\n",
      "(1, 0.75513375)\n",
      "(1, 0.7424793)\n",
      "(1, 0.74390286)\n",
      "(1, 0.7643431)\n",
      "(1, 0.7829019)\n",
      "(1, 0.7969617)\n",
      "(1, 0.79520416)\n",
      "(1, 0.78522015)\n",
      "(1, 0.7867285)\n",
      "(1, 0.8334132)\n",
      "(1, 0.89448476)\n",
      "(1, 0.94749415)\n",
      "(1, 0.974517)\n",
      "(1, 0.98550344)\n",
      "(1, 0.9877815)\n",
      "(1, 0.9849311)\n",
      "(1, 0.9694929)\n",
      "(1, 0.8780696)\n",
      "(1, 0.42115483)\n",
      "(3, 0.5531662)\n",
      "(3, 0.6111808)\n",
      "(3, 0.8947538)\n",
      "(3, 0.9763365)\n",
      "(3, 0.9891488)\n",
      "(3, 0.97052884)\n",
      "(3, 0.87321126)\n",
      "(3, 0.71578217)\n",
      "(3, 0.56326693)\n",
      "(0, 0.55503553)\n",
      "(0, 0.5582068)\n",
      "(3, 0.50527394)\n",
      "(3, 0.6181533)\n",
      "(3, 0.75004894)\n",
      "(3, 0.8603147)\n",
      "(3, 0.8762915)\n",
      "(3, 0.5267044)\n",
      "(2, 0.7717587)\n",
      "(2, 0.78214467)\n",
      "(2, 0.7295495)\n",
      "(2, 0.7697576)\n",
      "(2, 0.77017534)\n",
      "(2, 0.6733084)\n",
      "(2, 0.47164717)\n",
      "(3, 0.66832936)\n",
      "(3, 0.7309507)\n",
      "(3, 0.74183017)\n",
      "(3, 0.7024124)\n",
      "(3, 0.5670629)\n",
      "(3, 0.4608345)\n",
      "(3, 0.545451)\n",
      "(3, 0.7161249)\n",
      "(3, 0.8631395)\n",
      "(3, 0.9147098)\n",
      "(3, 0.9257546)\n",
      "(3, 0.8984284)\n",
      "(3, 0.7577177)\n",
      "(3, 0.90820485)\n",
      "(3, 0.9586116)\n",
      "(3, 0.95387644)\n",
      "(3, 0.943118)\n",
      "(3, 0.92880744)\n",
      "(3, 0.9235979)\n",
      "(3, 0.9294327)\n",
      "(3, 0.9612343)\n",
      "(3, 0.9723985)\n",
      "(3, 0.9726107)\n",
      "(3, 0.94526845)\n",
      "(3, 0.7480167)\n",
      "(2, 0.7010562)\n",
      "(2, 0.84921914)\n",
      "(2, 0.8933264)\n",
      "(2, 0.77536297)\n",
      "(0, 0.5331589)\n",
      "(0, 0.82677466)\n",
      "(0, 0.9277257)\n",
      "(0, 0.87863934)\n",
      "(0, 0.8359272)\n",
      "(0, 0.6906515)\n",
      "(3, 0.628068)\n",
      "(3, 0.91679466)\n",
      "(3, 0.9391546)\n",
      "(3, 0.91567546)\n",
      "(3, 0.9391215)\n",
      "(3, 0.94440514)\n",
      "(3, 0.9361498)\n",
      "(3, 0.9398453)\n",
      "(3, 0.903018)\n",
      "(3, 0.8735578)\n",
      "(3, 0.72653276)\n",
      "(3, 0.526622)\n",
      "(0, 0.8242428)\n",
      "(0, 0.9573746)\n",
      "(0, 0.8849076)\n",
      "(0, 0.6139761)\n",
      "(0, 0.6092873)\n",
      "(0, 0.64232767)\n",
      "(0, 0.7231698)\n",
      "(0, 0.77384007)\n",
      "(0, 0.77790517)\n",
      "(0, 0.68549144)\n",
      "(3, 0.53958124)\n",
      "(3, 0.8194015)\n",
      "(3, 0.9586572)\n",
      "(3, 0.98818284)\n",
      "(3, 0.9950283)\n",
      "(3, 0.99529856)\n",
      "(3, 0.98979026)\n",
      "(3, 0.9625177)\n",
      "(3, 0.65928274)\n",
      "(0, 0.74809366)\n",
      "(0, 0.92236507)\n",
      "(0, 0.9875245)\n",
      "(0, 0.9882069)\n",
      "(0, 0.79414403)\n",
      "(3, 0.5149938)\n",
      "(3, 0.6294402)\n",
      "(3, 0.5217253)\n",
      "(0, 0.8066041)\n",
      "(0, 0.96965945)\n",
      "(0, 0.994204)\n",
      "(0, 0.99836177)\n",
      "(0, 0.998831)\n",
      "(0, 0.99749655)\n",
      "(0, 0.9907787)\n",
      "(0, 0.95293635)\n",
      "(0, 0.7801242)\n",
      "(2, 0.3421967)\n",
      "(2, 0.34434205)\n",
      "(2, 0.34582147)\n",
      "(2, 0.32657763)\n",
      "(1, 0.31583762)\n",
      "(0, 0.3168278)\n",
      "(0, 0.31724483)\n",
      "(2, 0.32404092)\n",
      "(2, 0.33785972)\n",
      "(0, 0.35702798)\n",
      "(0, 0.4591136)\n",
      "(0, 0.5962134)\n",
      "(0, 0.7259961)\n",
      "(0, 0.77234215)\n",
      "(0, 0.7572977)\n",
      "(0, 0.66463953)\n",
      "(3, 0.52393836)\n",
      "(3, 0.8025551)\n",
      "(3, 0.9625402)\n",
      "(3, 0.9527045)\n",
      "(3, 0.97379005)\n",
      "(3, 0.98872644)\n",
      "(3, 0.99329233)\n",
      "(3, 0.99650013)\n",
      "(3, 0.9975055)\n",
      "(3, 0.9978854)\n",
      "(3, 0.99821544)\n",
      "(3, 0.9980769)\n",
      "(3, 0.9962245)\n",
      "(3, 0.9893036)\n",
      "(3, 0.9365455)\n",
      "(3, 0.7605874)\n",
      "(3, 0.5591026)\n",
      "(3, 0.5437544)\n",
      "(3, 0.78683895)\n",
      "(3, 0.9635371)\n",
      "(3, 0.99282736)\n",
      "(3, 0.9928281)\n",
      "(3, 0.9795346)\n",
      "(3, 0.87334293)\n",
      "(3, 0.38701826)\n",
      "(2, 0.4638538)\n",
      "(2, 0.41177765)\n",
      "(0, 0.5758025)\n",
      "(0, 0.52243966)\n",
      "(2, 0.5014677)\n",
      "(2, 0.5390916)\n",
      "(2, 0.47398224)\n",
      "(0, 0.4944258)\n",
      "(0, 0.44799927)\n",
      "(0, 0.4631287)\n",
      "(0, 0.4453876)\n",
      "(0, 0.45163316)\n",
      "(0, 0.46388367)\n",
      "(0, 0.48842674)\n",
      "(0, 0.49382627)\n",
      "(0, 0.49100336)\n",
      "(0, 0.5114841)\n",
      "(0, 0.5046492)\n",
      "(0, 0.510353)\n",
      "(0, 0.4890627)\n",
      "(0, 0.4513116)\n",
      "(0, 0.41889074)\n",
      "(0, 0.39616662)\n",
      "(0, 0.38851944)\n",
      "(0, 0.41531554)\n",
      "(0, 0.48638853)\n",
      "(0, 0.6252532)\n",
      "(0, 0.74810493)\n",
      "(0, 0.810033)\n",
      "(0, 0.81739193)\n",
      "(0, 0.78285235)\n",
      "(0, 0.6963507)\n",
      "(0, 0.58621097)\n",
      "(0, 0.5084741)\n",
      "(0, 0.5265955)\n",
      "(0, 0.60634005)\n",
      "(0, 0.6961103)\n",
      "(0, 0.7005428)\n",
      "(0, 0.69329345)\n",
      "(0, 0.697843)\n",
      "(0, 0.7205159)\n",
      "(0, 0.7271033)\n",
      "(0, 0.7315427)\n",
      "(0, 0.73510486)\n",
      "(0, 0.72612584)\n",
      "(0, 0.7151342)\n",
      "(0, 0.6774243)\n",
      "(0, 0.6313326)\n",
      "(0, 0.5881426)\n",
      "(0, 0.5238722)\n",
      "(0, 0.45965928)\n",
      "(0, 0.4031424)\n",
      "(0, 0.35322732)\n",
      "(0, 0.34197465)\n",
      "(0, 0.34421813)\n",
      "(0, 0.35590327)\n",
      "(0, 0.36245018)\n",
      "(0, 0.4110009)\n",
      "(0, 0.47717813)\n",
      "(0, 0.54656184)\n",
      "(0, 0.6256869)\n",
      "(0, 0.693035)\n",
      "(0, 0.74404615)\n",
      "(0, 0.7751785)\n",
      "(0, 0.79389226)\n",
      "(0, 0.78075504)\n",
      "(0, 0.8239904)\n",
      "(0, 0.83000433)\n",
      "(0, 0.7561442)\n",
      "(0, 0.582085)\n",
      "(2, 0.4154793)\n",
      "(2, 0.63563967)\n",
      "(2, 0.8113655)\n",
      "(2, 0.9331799)\n",
      "(2, 0.98359954)\n",
      "(2, 0.9961521)\n",
      "(2, 0.99949455)\n",
      "(2, 0.9997948)\n",
      "(2, 0.9999025)\n",
      "(2, 0.99994814)\n",
      "(2, 0.99996173)\n",
      "(2, 0.99996555)\n",
      "(2, 0.9999646)\n",
      "(2, 0.99995685)\n",
      "(2, 0.9999409)\n",
      "(2, 0.9999058)\n",
      "(2, 0.9998281)\n",
      "(2, 0.99969125)\n",
      "(2, 0.9995183)\n",
      "(2, 0.99930227)\n",
      "(2, 0.9995921)\n",
      "(2, 0.9997389)\n",
      "(2, 0.9996631)\n",
      "(2, 0.99926513)\n",
      "(2, 0.99671113)\n",
      "(2, 0.93896234)\n",
      "(0, 0.644589)\n",
      "(0, 0.6185232)\n",
      "(0, 0.5866719)\n",
      "(0, 0.59241617)\n",
      "(0, 0.5943954)\n",
      "(0, 0.60122967)\n",
      "(0, 0.6386836)\n",
      "(0, 0.64241886)\n",
      "(0, 0.6333578)\n",
      "(0, 0.6220069)\n",
      "(0, 0.58989096)\n",
      "(0, 0.5668495)\n",
      "(0, 0.5530371)\n",
      "(0, 0.53973)\n",
      "(0, 0.49495757)\n",
      "(0, 0.46942848)\n",
      "(0, 0.4765022)\n",
      "(0, 0.5001653)\n",
      "(0, 0.542288)\n",
      "(0, 0.61366224)\n",
      "(0, 0.6944186)\n",
      "(0, 0.7412719)\n",
      "(0, 0.7724119)\n",
      "(0, 0.74964094)\n",
      "(0, 0.680465)\n",
      "(0, 0.6171507)\n",
      "(0, 0.57945114)\n",
      "(0, 0.5431548)\n",
      "(0, 0.53860724)\n",
      "(0, 0.55014586)\n",
      "(0, 0.5561464)\n",
      "(0, 0.54210144)\n",
      "(0, 0.4809472)\n",
      "(0, 0.47669697)\n",
      "(0, 0.4634978)\n",
      "(0, 0.44419417)\n",
      "(0, 0.4239147)\n",
      "(0, 0.45827782)\n",
      "(0, 0.47612882)\n",
      "(0, 0.4808323)\n",
      "(0, 0.46328422)\n",
      "(0, 0.43249357)\n",
      "(2, 0.4100219)\n",
      "(0, 0.43094292)\n",
      "(0, 0.44684944)\n",
      "(0, 0.42912585)\n",
      "(0, 0.422472)\n",
      "(0, 0.42912015)\n",
      "(0, 0.44825915)\n",
      "(0, 0.49384347)\n",
      "(0, 0.46610788)\n",
      "(0, 0.46939138)\n",
      "(0, 0.50656724)\n",
      "(0, 0.51854664)\n",
      "(0, 0.5514923)\n",
      "(0, 0.5720959)\n",
      "(0, 0.59123254)\n",
      "(0, 0.60348225)\n",
      "(0, 0.62102515)\n",
      "(0, 0.6140766)\n",
      "(0, 0.6038044)\n",
      "(0, 0.578981)\n",
      "(0, 0.54038167)\n",
      "(0, 0.48780558)\n",
      "(0, 0.42503014)\n",
      "(2, 0.45424664)\n",
      "(2, 0.4682979)\n",
      "(2, 0.46539107)\n",
      "(2, 0.4525627)\n",
      "(2, 0.43713698)\n",
      "(0, 0.4475846)\n",
      "(0, 0.50777096)\n",
      "(0, 0.53338027)\n",
      "(0, 0.5316087)\n",
      "(0, 0.5206215)\n",
      "(0, 0.52739257)\n",
      "(0, 0.5615035)\n",
      "(0, 0.60677963)\n",
      "(0, 0.65626895)\n",
      "(0, 0.6703484)\n",
      "(0, 0.6354661)\n",
      "(0, 0.61372006)\n",
      "(0, 0.5980259)\n",
      "(0, 0.60249233)\n",
      "(0, 0.6199887)\n",
      "(0, 0.63797426)\n",
      "(0, 0.6726737)\n",
      "(0, 0.6998058)\n",
      "(0, 0.7255263)\n",
      "(0, 0.75128686)\n",
      "(0, 0.7394544)\n",
      "(0, 0.71838623)\n",
      "(0, 0.69527555)\n",
      "(0, 0.67042065)\n",
      "(0, 0.6818232)\n",
      "(0, 0.6863523)\n",
      "(0, 0.70119953)\n",
      "(0, 0.71679944)\n",
      "(0, 0.71188146)\n",
      "(0, 0.6955096)\n",
      "(0, 0.6452509)\n",
      "(0, 0.5838815)\n",
      "(0, 0.5186246)\n",
      "(0, 0.46098027)\n",
      "(0, 0.42841065)\n",
      "(0, 0.41317666)\n",
      "(0, 0.44636738)\n",
      "(0, 0.46561608)\n",
      "(0, 0.47457874)\n",
      "(0, 0.48762915)\n",
      "(0, 0.5049304)\n",
      "(0, 0.5337864)\n",
      "(0, 0.577341)\n",
      "(0, 0.6104309)\n",
      "(0, 0.6502375)\n",
      "(0, 0.70070213)\n",
      "(0, 0.7333409)\n",
      "(0, 0.72168815)\n",
      "(0, 0.74281746)\n",
      "(0, 0.74729663)\n",
      "(0, 0.75261503)\n",
      "(0, 0.73992497)\n",
      "(0, 0.70839447)\n",
      "(0, 0.630944)\n",
      "(0, 0.5757755)\n",
      "(0, 0.52702963)\n",
      "(0, 0.520393)\n",
      "(0, 0.5165821)\n",
      "(0, 0.5161759)\n",
      "(0, 0.47718078)\n",
      "(0, 0.47532058)\n",
      "(0, 0.45201787)\n",
      "(0, 0.44225273)\n",
      "(0, 0.45124876)\n",
      "(0, 0.48348373)\n",
      "(0, 0.50398016)\n",
      "(0, 0.52835244)\n",
      "(0, 0.5606976)\n",
      "(0, 0.6297593)\n",
      "(0, 0.72111785)\n",
      "(0, 0.72389907)\n",
      "(0, 0.725629)\n",
      "(0, 0.71514803)\n",
      "(0, 0.69854736)\n",
      "(0, 0.68620133)\n",
      "(0, 0.68144464)\n",
      "(0, 0.6787471)\n",
      "(0, 0.6829981)\n",
      "(0, 0.7096529)\n",
      "(0, 0.7515882)\n",
      "(0, 0.8018004)\n",
      "(0, 0.8324297)\n",
      "(0, 0.85399914)\n",
      "(0, 0.86787456)\n",
      "(0, 0.8789242)\n",
      "(0, 0.8839243)\n",
      "(0, 0.8699385)\n",
      "(0, 0.84900814)\n",
      "(0, 0.8315406)\n",
      "(0, 0.8206229)\n",
      "(0, 0.80919594)\n",
      "(0, 0.79189134)\n",
      "(0, 0.8439036)\n",
      "(0, 0.9141058)\n",
      "(0, 0.9617002)\n",
      "(0, 0.9802392)\n",
      "(0, 0.98633724)\n",
      "(0, 0.98401743)\n",
      "(0, 0.9518604)\n",
      "(0, 0.66687703)\n",
      "(3, 0.898933)\n",
      "(3, 0.99190736)\n",
      "(3, 0.99597)\n",
      "(3, 0.99587077)\n",
      "(3, 0.9948991)\n",
      "(3, 0.9862411)\n",
      "(3, 0.93431586)\n",
      "(3, 0.9312885)\n",
      "(3, 0.93329036)\n",
      "(3, 0.9401766)\n",
      "(3, 0.9462462)\n",
      "(3, 0.9366299)\n",
      "(3, 0.87308156)\n",
      "(3, 0.585621)\n",
      "(2, 0.47658327)\n",
      "(2, 0.6443209)\n",
      "(2, 0.68856066)\n",
      "(2, 0.801357)\n",
      "(2, 0.85407984)\n",
      "(2, 0.8372109)\n",
      "(2, 0.572429)\n",
      "(0, 0.8307255)\n",
      "(0, 0.8876322)\n",
      "(0, 0.9078136)\n",
      "(0, 0.9112857)\n",
      "(0, 0.90884966)\n",
      "(0, 0.8795547)\n",
      "(0, 0.8079063)\n",
      "(0, 0.67586607)\n",
      "(3, 0.51697534)\n",
      "(0, 0.85247517)\n",
      "(0, 0.99007696)\n",
      "(0, 0.9930397)\n",
      "(0, 0.99409676)\n",
      "(0, 0.994418)\n",
      "(0, 0.99461186)\n",
      "(0, 0.99554956)\n",
      "(0, 0.9964713)\n",
      "(0, 0.9972198)\n",
      "(0, 0.99728787)\n",
      "(0, 0.9972914)\n",
      "(0, 0.99731773)\n",
      "(0, 0.99730706)\n",
      "(0, 0.9966258)\n",
      "(0, 0.99581414)\n",
      "(0, 0.99505144)\n",
      "(0, 0.9947463)\n",
      "(0, 0.9948714)\n",
      "(0, 0.99513525)\n",
      "(0, 0.99600214)\n",
      "(0, 0.99678063)\n",
      "(0, 0.99703014)\n",
      "(0, 0.9972716)\n",
      "(0, 0.9977549)\n",
      "(0, 0.9976494)\n",
      "(0, 0.9969741)\n",
      "(0, 0.99531806)\n",
      "(0, 0.99309313)\n",
      "(0, 0.98865426)\n",
      "(0, 0.98086447)\n",
      "(0, 0.9435687)\n",
      "(0, 0.94784635)\n",
      "(0, 0.9799653)\n",
      "(0, 0.97561353)\n",
      "(0, 0.9097254)\n",
      "(0, 0.7915518)\n",
      "(0, 0.78161997)\n",
      "(0, 0.59479594)\n",
      "(3, 0.70193964)\n",
      "(3, 0.9321384)\n",
      "(3, 0.9889649)\n",
      "(3, 0.9814)\n",
      "(3, 0.9887056)\n",
      "(3, 0.9864179)\n",
      "(3, 0.979154)\n",
      "(3, 0.9409602)\n",
      "(3, 0.75806296)\n",
      "(3, 0.54289705)\n",
      "(0, 0.62268376)\n",
      "(0, 0.81956714)\n",
      "(0, 0.8622309)\n",
      "(0, 0.85537565)\n",
      "(0, 0.72978526)\n",
      "(3, 0.6236133)\n",
      "(3, 0.91525483)\n",
      "(3, 0.97355753)\n",
      "(3, 0.97719145)\n",
      "(3, 0.95611316)\n",
      "(3, 0.8137204)\n",
      "(0, 0.44896898)\n",
      "(0, 0.71080345)\n",
      "(0, 0.89852154)\n",
      "(0, 0.9669942)\n",
      "(0, 0.9524286)\n",
      "(0, 0.8915841)\n",
      "(0, 0.68532073)\n",
      "(3, 0.52795786)\n",
      "(3, 0.6693571)\n",
      "(3, 0.5102837)\n",
      "(0, 0.6522691)\n",
      "(0, 0.8666312)\n",
      "(0, 0.9007775)\n",
      "(0, 0.8892853)\n",
      "(0, 0.8020782)\n",
      "(0, 0.7033496)\n",
      "(0, 0.68850577)\n",
      "(0, 0.7829935)\n",
      "(0, 0.88378173)\n",
      "(0, 0.95004946)\n",
      "(0, 0.95028335)\n",
      "(0, 0.8529834)\n",
      "(0, 0.64167863)\n",
      "(0, 0.49716574)\n",
      "(0, 0.5231982)\n",
      "(0, 0.70490605)\n",
      "(0, 0.7004301)\n",
      "(0, 0.73112434)\n",
      "(0, 0.76224923)\n",
      "(0, 0.7609015)\n",
      "(0, 0.76773036)\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "##          MODEL TESTING          ##\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_and_preprocess_test_data(test_data_path):\n",
    "    # Reuse the process_dataset function\n",
    "    test_data = process_dataset(test_data_path)\n",
    "    \n",
    "    # Reshape the data to match the model input shape\n",
    "    X_test = test_data.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "    y_test = np.repeat(np.arange(num_handsigns), videos_per_handsign)\n",
    "    \n",
    "    return X_test, y_test\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Generate classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_classes))\n",
    "    \n",
    "    return y_pred_classes\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_misclassifications(X_test, y_test, y_pred, num_samples=5):\n",
    "    misclassified = np.where(y_test != y_pred)[0]\n",
    "    np.random.shuffle(misclassified)\n",
    "    \n",
    "    for i in range(min(num_samples, len(misclassified))):\n",
    "        idx = misclassified[i]\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Plot a representation of the hand sign (e.g., first frame landmarks)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(X_test[idx, 0, :, 0], X_test[idx, 0, :, 1])\n",
    "        plt.title(f\"True: {y_test[idx]}, Predicted: {y_pred[idx]}\")\n",
    "        plt.xlabel(\"X coordinate\")\n",
    "        plt.ylabel(\"Y coordinate\")\n",
    "        \n",
    "        # Plot the confidence scores for each class\n",
    "        plt.subplot(1, 2, 2)\n",
    "        confidence_scores = model.predict(X_test[idx:idx+1])[0]\n",
    "        plt.bar(range(num_handsigns), confidence_scores)\n",
    "        plt.title(\"Confidence Scores\")\n",
    "        plt.xlabel(\"Hand Sign Class\")\n",
    "        plt.ylabel(\"Confidence\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model('handsigns_model.h5')\n",
    "    \n",
    "    # Load and preprocess test data\n",
    "    test_data_path = \"Model testing videos\"  # Replace with your test dataset path\n",
    "    X_test, y_test = load_and_preprocess_test_data(test_data_path)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Visualize some misclassifications\n",
    "    visualize_misclassifications(X_test, y_test, y_pred)"
   ],
   "id": "67b4c8b4c4f1ca0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
