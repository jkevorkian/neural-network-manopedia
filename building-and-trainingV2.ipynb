{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T19:29:58.515968Z",
     "start_time": "2024-10-10T19:29:58.502587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          DATA SHAPE DEFINITION           ##\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define the parameters for the data shape\n",
    "videos_per_handsign = 33  # Adjust if necessary\n",
    "frames_per_video = 5\n",
    "num_landmarks = 51\n",
    "num_coordinates = 3\n",
    "\n",
    "data_augmentation = True\n",
    "num_augmented_versions = 2  # How many videos will be created from augmenting each video from the dataset\n",
    "\n",
    "# Define the root directory containing handsign folders\n",
    "root_path = \"ACOTADONomenclatedDataset\"\n",
    "\n",
    "def get_handsign_folders(root_path):\n",
    "    handsign_names = {}\n",
    "    handsign_count = 0\n",
    "    \n",
    "    # Walk through the root directory\n",
    "    for folder in os.listdir(root_path):\n",
    "        folder_path = os.path.join(root_path, folder)\n",
    "        \n",
    "        # Ignore non-directories\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # If the folder starts with \"#\", check its subdirectories\n",
    "        if folder.startswith(\"#\"):\n",
    "            for subfolder in os.listdir(folder_path):\n",
    "                subfolder_path = os.path.join(folder_path, subfolder)\n",
    "                if os.path.isdir(subfolder_path):\n",
    "                    handsign_names[handsign_count] = subfolder\n",
    "                    handsign_count += 1\n",
    "        else:\n",
    "            # Directly add the folder as a handsign\n",
    "            handsign_names[handsign_count] = folder\n",
    "            handsign_count += 1\n",
    "    \n",
    "    return handsign_names\n",
    "\n",
    "# Get the handsign names automatically\n",
    "handsign_names = get_handsign_folders(root_path)\n",
    "num_handsigns = len(handsign_names)\n",
    "\n",
    "# Output the handsign names and number of handsigns\n",
    "print(f\"Number of handsigns: {num_handsigns}\")\n",
    "print(\"Handsign names:\")\n",
    "print(json.dumps(handsign_names, indent=4))"
   ],
   "id": "823e51359a2141fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of handsigns: 3\n",
      "Handsign names:\n",
      "{\n",
      "    \"0\": \"cumplea\\u00f1os\",\n",
      "    \"1\": \"hijo\",\n",
      "    \"2\": \"mujer\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T19:30:01.411174Z",
     "start_time": "2024-10-10T19:30:01.394008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# Generate dummy data\n",
    "data = [np.random.rand(videos_per_handsign, frames_per_video, num_landmarks, num_coordinates) for _ in range(num_handsigns)]\n",
    "\n",
    "# Convert the list to a numpy array with shape (num_handsigns, videos_per_handsign, frames_per_video, num_landmarks, num_coordinates)\n",
    "data_array = np.array(data)\n",
    "\n",
    "# Save the data array to a .npy file\n",
    "np.save('handsigns_data.npy', data_array)"
   ],
   "id": "fa59d6b8b575718a",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T19:30:03.180142Z",
     "start_time": "2024-10-10T19:30:03.162887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          PROCESS VIDEO DATASET FUNC DEFINITIONS         ##\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "def extract_landmarks(hands_results, pose_results, last_handedness):\n",
    "    landmarks = []\n",
    "\n",
    "    try:\n",
    "        nose_landmark = pose_results.pose_landmarks.landmark[0]  # all landmarks are relative to the nose\n",
    "    except:\n",
    "        class nose_landmark:\n",
    "            x = 0\n",
    "            y = 0\n",
    "            z = 0\n",
    "        nose_landmark = nose_landmark()\n",
    "\n",
    "    # Initialize placeholders for left and right hand landmarks\n",
    "    left_hand_landmarks = [(0, 0, 0)] * 21\n",
    "    right_hand_landmarks = [(0, 0, 0)] * 21\n",
    "\n",
    "    # Extract hand landmarks with handedness labeling\n",
    "    if hands_results.multi_hand_landmarks and hands_results.multi_handedness:\n",
    "        for i, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):\n",
    "            label = hands_results.multi_handedness[i].classification[0].label  # 'Left' or 'Right'\n",
    "            \n",
    "            if label == 'Left':\n",
    "                left_hand_landmarks = [(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) for lm in hand_landmarks.landmark]\n",
    "                last_handedness['Left'] = True  # Mark the left hand as active\n",
    "            elif label == 'Right':\n",
    "                right_hand_landmarks = [(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) for lm in hand_landmarks.landmark]\n",
    "                last_handedness['Right'] = True  # Mark the right hand as active\n",
    "\n",
    "    # If one hand goes offscreen, attempt to use the last known handedness\n",
    "    if not hands_results.multi_hand_landmarks or len(hands_results.multi_hand_landmarks) < 2:\n",
    "        if not last_handedness.get('Left'):\n",
    "            left_hand_landmarks = [(0, 0, 0)] * 21\n",
    "        if not last_handedness.get('Right'):\n",
    "            right_hand_landmarks = [(0, 0, 0)] * 21\n",
    "\n",
    "    landmarks.extend(left_hand_landmarks)\n",
    "    landmarks.extend(right_hand_landmarks)\n",
    "\n",
    "    # Extract selected body landmarks (9 landmarks)\n",
    "    selected_body_landmarks = [0, 11, 12, 13, 14, 15, 16, 23, 24]  # Landmarks for nose, arms, and shoulders\n",
    "    if pose_results.pose_landmarks:\n",
    "        for idx in selected_body_landmarks:\n",
    "            lm = pose_results.pose_landmarks.landmark[idx]\n",
    "            landmarks.append((lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z))\n",
    "    else:\n",
    "        landmarks.extend([(0, 0, 0)] * 9)\n",
    "\n",
    "    return np.array(landmarks), last_handedness\n",
    "\n",
    "def process_frame(frame, hands, pose, last_handedness):\n",
    "    \"\"\"\n",
    "    This function processes a single frame, extracting the landmarks and ensuring hand consistency.\n",
    "    \"\"\"\n",
    "    # Convert the BGR image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image and extract landmarks\n",
    "    hands_results = hands.process(image)\n",
    "    pose_results = pose.process(image)\n",
    "\n",
    "    # Extract landmarks with handedness robustness\n",
    "    landmarks, last_handedness = extract_landmarks(hands_results, pose_results, last_handedness)\n",
    "\n",
    "    return landmarks, last_handedness\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    indices = np.linspace(0, total_frames - 1, frames_per_video, dtype=int)\n",
    "    frame_set = set(indices)\n",
    "    frame_count = 0\n",
    "\n",
    "    last_handedness = {'Left': False, 'Right': False}  # To track which hands are present\n",
    "    \n",
    "    with mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5) as hands, \\\n",
    "         mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        \n",
    "        while cap.isOpened() and len(frames) < frames_per_video:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_count in frame_set:\n",
    "                landmarks, last_handedness = process_frame(frame, hands, pose, last_handedness)  # Track handedness across frames\n",
    "                frames.append(landmarks)\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Pad if we don't have enough frames\n",
    "    if len(frames) < frames_per_video:\n",
    "        frames.extend([np.zeros((num_landmarks, num_coordinates))] * (frames_per_video - len(frames)))\n",
    "\n",
    "    return np.array(frames)\n",
    "\n",
    "import warnings\n",
    "\n",
    "def process_dataset(root_path, handsign_names):\n",
    "    data = []\n",
    "    \n",
    "    for handsign_index in tqdm(range(len(handsign_names)), desc=\"Processing handsigns\"):\n",
    "        # Get the handsign folder name from the handsign_names dictionary\n",
    "        handsign_folder = handsign_names[handsign_index]\n",
    "        handsign_path = os.path.join(root_path, handsign_folder)\n",
    "        \n",
    "        if not os.path.exists(handsign_path):\n",
    "            print(f\"Warning: Directory {handsign_path} does not exist. Skipping.\")\n",
    "            data.append(np.zeros((videos_per_handsign, frames_per_video, num_landmarks, num_coordinates)))  # 51 landmarks total\n",
    "            continue\n",
    "        \n",
    "        videos = [f for f in os.listdir(handsign_path) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        videos = videos[:videos_per_handsign]  # Limit to videos_per_handsign\n",
    "        \n",
    "        handsign_data = []\n",
    "        for video in tqdm(videos, desc=f\"Processing videos for handsign {handsign_index}\", leave=False):\n",
    "            video_path = os.path.join(handsign_path, video)\n",
    "            video_data = process_video(video_path)\n",
    "            handsign_data.append(video_data)\n",
    "        \n",
    "        # Pad if we don't have enough videos\n",
    "        if len(handsign_data) < videos_per_handsign:\n",
    "            padding_needed = videos_per_handsign - len(handsign_data)\n",
    "            warnings.warn(f\"Handsign {handsign_index} ('{handsign_folder}') has only {len(handsign_data)} videos. \"\n",
    "                          f\"Padding with {padding_needed} empty videos.\")\n",
    "            handsign_data.extend([np.zeros((frames_per_video, num_landmarks, num_coordinates))] * padding_needed)\n",
    "        \n",
    "        data.append(np.array(handsign_data))\n",
    "    \n",
    "    return np.array(data)\n",
    "\n",
    "\n"
   ],
   "id": "c6b1d3592b943838",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T19:31:55.500292Z",
     "start_time": "2024-10-10T19:31:04.227036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          PROCESS VIDEOS DATASET FUNC CALLING         ##\n",
    "    \n",
    "data_array = process_dataset(root_path, handsign_names)\n",
    "\n",
    "# Save the data array to a .npy file\n",
    "np.save('handsigns_data.npy', data_array)\n",
    "print(\"Data saved to handsigns_data.npy\")\n",
    "    "
   ],
   "id": "38b563f5e5342b66",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing handsigns:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Processing videos for handsign 0:   0%|          | 0/33 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 0:   3%|▎         | 1/33 [00:00<00:10,  3.03it/s]\u001B[A\n",
      "Processing videos for handsign 0:   6%|▌         | 2/33 [00:00<00:15,  1.98it/s]\u001B[A\n",
      "Processing videos for handsign 0:   9%|▉         | 3/33 [00:01<00:15,  1.99it/s]\u001B[A\n",
      "Processing videos for handsign 0:  12%|█▏        | 4/33 [00:01<00:13,  2.19it/s]\u001B[A\n",
      "Processing videos for handsign 0:  15%|█▌        | 5/33 [00:02<00:11,  2.46it/s]\u001B[A\n",
      "Processing videos for handsign 0:  18%|█▊        | 6/33 [00:02<00:10,  2.56it/s]\u001B[A\n",
      "Processing videos for handsign 0:  21%|██        | 7/33 [00:02<00:09,  2.65it/s]\u001B[A\n",
      "Processing videos for handsign 0:  24%|██▍       | 8/33 [00:03<00:09,  2.60it/s]\u001B[A\n",
      "Processing videos for handsign 0:  27%|██▋       | 9/33 [00:03<00:09,  2.55it/s]\u001B[A\n",
      "Processing videos for handsign 0:  30%|███       | 10/33 [00:04<00:08,  2.56it/s]\u001B[A\n",
      "Processing videos for handsign 0:  33%|███▎      | 11/33 [00:04<00:08,  2.59it/s]\u001B[A\n",
      "Processing videos for handsign 0:  36%|███▋      | 12/33 [00:04<00:08,  2.56it/s]\u001B[A\n",
      "Processing videos for handsign 0:  39%|███▉      | 13/33 [00:05<00:07,  2.57it/s]\u001B[A\n",
      "Processing videos for handsign 0:  42%|████▏     | 14/33 [00:05<00:07,  2.61it/s]\u001B[A\n",
      "Processing videos for handsign 0:  45%|████▌     | 15/33 [00:05<00:06,  2.58it/s]\u001B[A\n",
      "Processing videos for handsign 0:  48%|████▊     | 16/33 [00:06<00:06,  2.52it/s]\u001B[A\n",
      "Processing videos for handsign 0:  52%|█████▏    | 17/33 [00:06<00:06,  2.52it/s]\u001B[A\n",
      "Processing videos for handsign 0:  55%|█████▍    | 18/33 [00:07<00:05,  2.61it/s]\u001B[A\n",
      "Processing videos for handsign 0:  58%|█████▊    | 19/33 [00:07<00:05,  2.72it/s]\u001B[A\n",
      "Processing videos for handsign 0:  61%|██████    | 20/33 [00:07<00:04,  2.75it/s]\u001B[A\n",
      "Processing videos for handsign 0:  64%|██████▎   | 21/33 [00:08<00:04,  2.69it/s]\u001B[A\n",
      "Processing videos for handsign 0:  67%|██████▋   | 22/33 [00:08<00:04,  2.70it/s]\u001B[A\n",
      "Processing videos for handsign 0:  70%|██████▉   | 23/33 [00:08<00:03,  2.85it/s]\u001B[A\n",
      "Processing videos for handsign 0:  73%|███████▎  | 24/33 [00:09<00:03,  2.73it/s]\u001B[A\n",
      "Processing videos for handsign 0:  76%|███████▌  | 25/33 [00:09<00:03,  2.66it/s]\u001B[A\n",
      "Processing videos for handsign 0:  79%|███████▉  | 26/33 [00:10<00:02,  2.68it/s]\u001B[A\n",
      "Processing videos for handsign 0:  82%|████████▏ | 27/33 [00:10<00:02,  2.87it/s]\u001B[A\n",
      "Processing videos for handsign 0:  85%|████████▍ | 28/33 [00:10<00:01,  2.86it/s]\u001B[A\n",
      "Processing videos for handsign 0:  88%|████████▊ | 29/33 [00:11<00:01,  2.78it/s]\u001B[A\n",
      "Processing videos for handsign 0:  91%|█████████ | 30/33 [00:11<00:01,  2.74it/s]\u001B[A\n",
      "Processing videos for handsign 0:  94%|█████████▍| 31/33 [00:11<00:00,  2.73it/s]\u001B[A\n",
      "Processing videos for handsign 0:  97%|█████████▋| 32/33 [00:12<00:00,  2.72it/s]\u001B[A\n",
      "Processing videos for handsign 0: 100%|██████████| 33/33 [00:12<00:00,  2.87it/s]\u001B[A\n",
      "Processing handsigns:  33%|███▎      | 1/3 [00:12<00:25, 12.52s/it]              \u001B[A\n",
      "Processing videos for handsign 1:   0%|          | 0/33 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 1:   3%|▎         | 1/33 [00:00<00:19,  1.65it/s]\u001B[A\n",
      "Processing videos for handsign 1:   6%|▌         | 2/33 [00:01<00:17,  1.79it/s]\u001B[A\n",
      "Processing videos for handsign 1:   9%|▉         | 3/33 [00:01<00:16,  1.82it/s]\u001B[A\n",
      "Processing videos for handsign 1:  12%|█▏        | 4/33 [00:02<00:14,  1.94it/s]\u001B[A\n",
      "Processing videos for handsign 1:  15%|█▌        | 5/33 [00:02<00:15,  1.83it/s]\u001B[A\n",
      "Processing videos for handsign 1:  18%|█▊        | 6/33 [00:03<00:15,  1.75it/s]\u001B[A\n",
      "Processing videos for handsign 1:  21%|██        | 7/33 [00:04<00:15,  1.65it/s]\u001B[A\n",
      "Processing videos for handsign 1:  24%|██▍       | 8/33 [00:04<00:14,  1.75it/s]\u001B[A\n",
      "Processing videos for handsign 1:  27%|██▋       | 9/33 [00:05<00:13,  1.76it/s]\u001B[A\n",
      "Processing videos for handsign 1:  30%|███       | 10/33 [00:05<00:12,  1.78it/s]\u001B[A\n",
      "Processing videos for handsign 1:  33%|███▎      | 11/33 [00:06<00:12,  1.79it/s]\u001B[A\n",
      "Processing videos for handsign 1:  36%|███▋      | 12/33 [00:06<00:11,  1.78it/s]\u001B[A\n",
      "Processing videos for handsign 1:  39%|███▉      | 13/33 [00:07<00:11,  1.77it/s]\u001B[A\n",
      "Processing videos for handsign 1:  42%|████▏     | 14/33 [00:07<00:10,  1.78it/s]\u001B[A\n",
      "Processing videos for handsign 1:  45%|████▌     | 15/33 [00:08<00:10,  1.74it/s]\u001B[A\n",
      "Processing videos for handsign 1:  48%|████▊     | 16/33 [00:08<00:09,  1.82it/s]\u001B[A\n",
      "Processing videos for handsign 1:  52%|█████▏    | 17/33 [00:09<00:08,  1.82it/s]\u001B[A\n",
      "Processing videos for handsign 1:  55%|█████▍    | 18/33 [00:10<00:08,  1.80it/s]\u001B[A\n",
      "Processing videos for handsign 1:  58%|█████▊    | 19/33 [00:10<00:07,  1.75it/s]\u001B[A\n",
      "Processing videos for handsign 1:  61%|██████    | 20/33 [00:11<00:07,  1.67it/s]\u001B[A\n",
      "Processing videos for handsign 1:  64%|██████▎   | 21/33 [00:11<00:06,  1.76it/s]\u001B[A\n",
      "Processing videos for handsign 1:  67%|██████▋   | 22/33 [00:12<00:05,  1.89it/s]\u001B[A\n",
      "Processing videos for handsign 1:  70%|██████▉   | 23/33 [00:12<00:05,  1.83it/s]\u001B[A\n",
      "Processing videos for handsign 1:  73%|███████▎  | 24/33 [00:13<00:05,  1.78it/s]\u001B[A\n",
      "Processing videos for handsign 1:  76%|███████▌  | 25/33 [00:14<00:04,  1.80it/s]\u001B[A\n",
      "Processing videos for handsign 1:  79%|███████▉  | 26/33 [00:14<00:03,  1.80it/s]\u001B[A\n",
      "Processing videos for handsign 1:  82%|████████▏ | 27/33 [00:15<00:03,  1.86it/s]\u001B[A\n",
      "Processing videos for handsign 1:  85%|████████▍ | 28/33 [00:15<00:02,  1.85it/s]\u001B[A\n",
      "Processing videos for handsign 1:  88%|████████▊ | 29/33 [00:16<00:02,  1.95it/s]\u001B[A\n",
      "Processing videos for handsign 1:  91%|█████████ | 30/33 [00:16<00:01,  2.00it/s]\u001B[A\n",
      "Processing videos for handsign 1:  94%|█████████▍| 31/33 [00:17<00:01,  1.93it/s]\u001B[A\n",
      "Processing videos for handsign 1:  97%|█████████▋| 32/33 [00:17<00:00,  2.00it/s]\u001B[A\n",
      "Processing videos for handsign 1: 100%|██████████| 33/33 [00:18<00:00,  1.93it/s]\u001B[A\n",
      "Processing handsigns:  67%|██████▋   | 2/3 [00:30<00:15, 15.82s/it]              \u001B[A\n",
      "Processing videos for handsign 2:   0%|          | 0/33 [00:00<?, ?it/s]\u001B[A\n",
      "Processing videos for handsign 2:   3%|▎         | 1/33 [00:00<00:17,  1.80it/s]\u001B[A\n",
      "Processing videos for handsign 2:   6%|▌         | 2/33 [00:01<00:18,  1.69it/s]\u001B[A\n",
      "Processing videos for handsign 2:   9%|▉         | 3/33 [00:01<00:19,  1.54it/s]\u001B[A\n",
      "Processing videos for handsign 2:  12%|█▏        | 4/33 [00:02<00:18,  1.57it/s]\u001B[A\n",
      "Processing videos for handsign 2:  15%|█▌        | 5/33 [00:03<00:16,  1.67it/s]\u001B[A\n",
      "Processing videos for handsign 2:  18%|█▊        | 6/33 [00:03<00:16,  1.61it/s]\u001B[A\n",
      "Processing videos for handsign 2:  21%|██        | 7/33 [00:04<00:15,  1.65it/s]\u001B[A\n",
      "Processing videos for handsign 2:  24%|██▍       | 8/33 [00:04<00:14,  1.67it/s]\u001B[A\n",
      "Processing videos for handsign 2:  27%|██▋       | 9/33 [00:05<00:15,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 2:  30%|███       | 10/33 [00:06<00:14,  1.59it/s]\u001B[A\n",
      "Processing videos for handsign 2:  33%|███▎      | 11/33 [00:06<00:13,  1.65it/s]\u001B[A\n",
      "Processing videos for handsign 2:  36%|███▋      | 12/33 [00:07<00:12,  1.67it/s]\u001B[A\n",
      "Processing videos for handsign 2:  39%|███▉      | 13/33 [00:08<00:12,  1.60it/s]\u001B[A\n",
      "Processing videos for handsign 2:  42%|████▏     | 14/33 [00:08<00:11,  1.64it/s]\u001B[A\n",
      "Processing videos for handsign 2:  45%|████▌     | 15/33 [00:09<00:11,  1.61it/s]\u001B[A\n",
      "Processing videos for handsign 2:  48%|████▊     | 16/33 [00:09<00:10,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 2:  52%|█████▏    | 17/33 [00:10<00:10,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 2:  55%|█████▍    | 18/33 [00:11<00:09,  1.61it/s]\u001B[A\n",
      "Processing videos for handsign 2:  58%|█████▊    | 19/33 [00:11<00:08,  1.64it/s]\u001B[A\n",
      "Processing videos for handsign 2:  61%|██████    | 20/33 [00:12<00:07,  1.64it/s]\u001B[A\n",
      "Processing videos for handsign 2:  64%|██████▎   | 21/33 [00:12<00:07,  1.62it/s]\u001B[A\n",
      "Processing videos for handsign 2:  67%|██████▋   | 22/33 [00:13<00:06,  1.59it/s]\u001B[A\n",
      "Processing videos for handsign 2:  70%|██████▉   | 23/33 [00:14<00:06,  1.55it/s]\u001B[A\n",
      "Processing videos for handsign 2:  73%|███████▎  | 24/33 [00:14<00:05,  1.57it/s]\u001B[A\n",
      "Processing videos for handsign 2:  76%|███████▌  | 25/33 [00:15<00:05,  1.56it/s]\u001B[A\n",
      "Processing videos for handsign 2:  79%|███████▉  | 26/33 [00:16<00:04,  1.59it/s]\u001B[A\n",
      "Processing videos for handsign 2:  82%|████████▏ | 27/33 [00:16<00:03,  1.62it/s]\u001B[A\n",
      "Processing videos for handsign 2:  85%|████████▍ | 28/33 [00:17<00:03,  1.51it/s]\u001B[A\n",
      "Processing videos for handsign 2:  88%|████████▊ | 29/33 [00:18<00:02,  1.57it/s]\u001B[A\n",
      "Processing videos for handsign 2:  91%|█████████ | 30/33 [00:18<00:01,  1.54it/s]\u001B[A\n",
      "Processing videos for handsign 2:  94%|█████████▍| 31/33 [00:19<00:01,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 2:  97%|█████████▋| 32/33 [00:20<00:00,  1.58it/s]\u001B[A\n",
      "Processing videos for handsign 2: 100%|██████████| 33/33 [00:20<00:00,  1.60it/s]\u001B[A\n",
      "Processing handsigns: 100%|██████████| 3/3 [00:51<00:00, 17.09s/it]              \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to handsigns_data.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T19:33:49.643324Z",
     "start_time": "2024-10-10T19:33:49.613013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##        DATA AUGMENTATION (OPTIONAL)        ##\n",
    "\n",
    "def apply_rotation(landmarks, angle_degrees):\n",
    "    \"\"\"Rotate the landmarks in 3D space by a given angle.\"\"\"\n",
    "    angle_radians = np.radians(angle_degrees)\n",
    "    cos_angle = np.cos(angle_radians)\n",
    "    sin_angle = np.sin(angle_radians)\n",
    "\n",
    "    # Rotation around the Z-axis (you can adjust for other axes if necessary)\n",
    "    rotation_matrix = np.array([\n",
    "        [cos_angle, -sin_angle, 0],\n",
    "        [sin_angle, cos_angle, 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    return np.dot(landmarks, rotation_matrix)\n",
    "\n",
    "def apply_scaling(landmarks, scale_factor):\n",
    "    \"\"\"Scale the landmarks by a given factor.\"\"\"\n",
    "    return landmarks * scale_factor\n",
    "\n",
    "def apply_translation(landmarks, translation_vector):\n",
    "    \"\"\"Translate the landmarks by a given vector (x, y, z).\"\"\"\n",
    "    return landmarks + translation_vector\n",
    "\n",
    "def add_noise(landmarks, noise_level=0.01):\n",
    "    \"\"\"Add random noise to the landmarks.\"\"\"\n",
    "    noise = np.random.normal(0, noise_level, landmarks.shape)\n",
    "    return landmarks + noise\n",
    "\n",
    "def augment_data(data_array, num_augmented_versions=5):\n",
    "    \"\"\"\n",
    "    Augment the data array by applying transformations.\n",
    "    Creates `num_augmented_versions` augmented copies of each handsign video.\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    for handsign_data in data_array:\n",
    "        augmented_handsign_data = []\n",
    "        for video_data in handsign_data:\n",
    "            augmented_videos = [video_data]  # Start with the original video data\n",
    "\n",
    "            for _ in range(num_augmented_versions):\n",
    "                augmented_video = []\n",
    "                for frame in video_data:\n",
    "                    # Apply a combination of augmentations\n",
    "                    rotated_frame = apply_rotation(frame, angle_degrees=np.random.uniform(-10, 10))\n",
    "                    scaled_frame = apply_scaling(rotated_frame, scale_factor=np.random.uniform(0.9, 1.1))\n",
    "                    translated_frame = apply_translation(scaled_frame, translation_vector=np.random.uniform(-0.05, 0.05, 3))\n",
    "                    noisy_frame = add_noise(translated_frame, noise_level=0.02)\n",
    "\n",
    "                    augmented_video.append(noisy_frame)\n",
    "                \n",
    "                augmented_videos.append(np.array(augmented_video))\n",
    "\n",
    "            # Flatten the augmented videos for each original video\n",
    "            augmented_handsign_data.extend(augmented_videos)\n",
    "\n",
    "        augmented_data.append(np.array(augmented_handsign_data))\n",
    "    \n",
    "    return np.array(augmented_data)\n",
    "\n",
    "# Load original handsigns data\n",
    "handsigns_data = np.load('handsigns_data.npy')\n",
    "\n",
    "# Apply augmentation\n",
    "if data_augmentation:\n",
    "    \n",
    "    augmented_data = augment_data(handsigns_data, num_augmented_versions)\n",
    "    \n",
    "    # Save the augmented data to a new .npy file\n",
    "    np.save('handsigns_data_augmented.npy', augmented_data)\n",
    "    \n",
    "    # Update the videos per handsign value to match the videos generated by the augmentation\n",
    "    data_array = np.load('handsigns_data_augmented.npy')\n",
    "    videos_per_handsign = data_array.shape[1]\n",
    "    \n",
    "    print(\"Augmented data saved to handsigns_data_augmented.npy, videos_per_handsign augmented by \"+str(num_augmented_versions)+\" per existing video for a total of \"+str(videos_per_handsign)+\" videos per handsign\")\n",
    "else:\n",
    "    print(\"no data augmentation was performed\")"
   ],
   "id": "d0c17cfc27c8ccac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data saved to handsigns_data_augmented.npy, videos_per_handsign augmented by 2 per existing video for a total of 99 videos per handsign\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T19:33:54.110975Z",
     "start_time": "2024-10-10T19:33:53.868347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          MODEL DEFINITION            ##\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Reshape, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Reshape input to (frames_per_video, num_landmarks * num_coordinates)\n",
    "new_input_shape = (frames_per_video, num_landmarks * num_coordinates)\n",
    "\n",
    "model = Sequential([\n",
    "    # Reshape layer\n",
    "    Reshape((frames_per_video, num_landmarks * num_coordinates), input_shape=(frames_per_video, num_landmarks, num_coordinates)),\n",
    "    \n",
    "    # LSTM layers with Dropout and Batch Normalization to reduce overfitting\n",
    "    LSTM(64, return_sequences=True, kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    LSTM(128, return_sequences=False, kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    # Fully connected layer\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.05)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    \n",
    "    # Output layer for multi-class classification\n",
    "    Dense(num_handsigns, activation='softmax')  # Softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Specify a learning rate\n",
    "learning_rate = 0.0005\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model.summary() # Uncomment if you want to see the model summary\n"
   ],
   "id": "c1f9d72562ce0728",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T19:33:56.936723Z",
     "start_time": "2024-10-10T19:33:56.216157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          DATA PREPROCESSING FOR TRAINING            ##\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# Load the data from the .npy file, making a copy to use for training as to not modify the original extracted data\n",
    "if data_augmentation:\n",
    "    shutil.copy('handsigns_data_augmented.npy', 'handsigns_data_training_copy.npy')\n",
    "    data_array = np.load('handsigns_data_training_copy.npy')\n",
    "    \n",
    "    # Update videos_per_handsign based on augmentation\n",
    "    #videos_per_handsign = data_array.shape[1]  # Dynamically update based on the new augmented shape\n",
    "    print(\"after augmentation videos per handsign updated to: \" + str(data_array.shape[1]))\n",
    "else:\n",
    "    shutil.copy('handsigns_data.npy', 'handsigns_data_training_copy.npy')\n",
    "    data_array = np.load('handsigns_data_training_copy.npy')\n",
    "\n",
    "\n",
    "# X remains unchanged\n",
    "X = data_array \n",
    "\n",
    "# Create labels for each handsign (0 to num_handsigns-1)\n",
    "# This creates a label for each hand sign, repeated for each video\n",
    "y = np.repeat(np.arange(num_handsigns), videos_per_handsign)\n",
    "y = y.reshape(num_handsigns, videos_per_handsign)\n",
    "\n",
    "# Initialize lists to hold training and validation data\n",
    "X_train_list = []\n",
    "X_val_list = []\n",
    "y_train_list = []\n",
    "y_val_list = []\n",
    "\n",
    "# Split videos and labels for each handsign\n",
    "for handsign_index in range(num_handsigns):\n",
    "    # Split the videos within each handsign\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        np.arange(videos_per_handsign), \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Select training and validation data for this handsign\n",
    "    X_train_list.append(data_array[handsign_index, train_indices])\n",
    "    X_val_list.append(data_array[handsign_index, val_indices])\n",
    "    \n",
    "    # Select corresponding labels\n",
    "    y_train_list.append(y[handsign_index, train_indices])\n",
    "    y_val_list.append(y[handsign_index, val_indices])\n",
    "\n",
    "# Concatenate lists to form the final training and validation sets\n",
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "X_val = np.concatenate(X_val_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "y_val = np.concatenate(y_val_list, axis=0)\n",
    "\n",
    "# Reshape X_train and X_val to fit the model's expected input shape\n",
    "X_train = X_train.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "X_val = X_val.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "\n",
    "# Flatten y_train and y_val\n",
    "y_train = y_train.flatten()\n",
    "y_val = y_val.flatten()"
   ],
   "id": "664f881d08e116f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after augmentation videos per handsign updated to: 99\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T19:34:28.632005Z",
     "start_time": "2024-10-10T19:34:03.541209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          MODEL TRAINING          ##\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Callback helpers for model training #\n",
    "# Early stopping to stop training when validation loss stops improving\n",
    "# Model checkpointing to save the best model during training\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)  \n",
    "checkpoint = ModelCheckpoint('best_handsigns_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)  \n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=[early_stopping, checkpoint, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "model.save('handsigns_model.h5')\n",
    "\n",
    "# Optionally, save the training history\n",
    "import pickle\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "    \n",
    "\n",
    "    \n",
    "##          TRAINING HISTORY ANALYSIS           ##\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# If you want to save the plot instead of displaying it:\n",
    "# plt.savefig('training_history.png')"
   ],
   "id": "febb1178fa7e41a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m19s\u001B[0m 3s/step - accuracy: 0.1875 - loss: 22.5149\n",
      "Epoch 1: val_loss improved from inf to 19.85861, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 57ms/step - accuracy: 0.2696 - loss: 21.8558 - val_accuracy: 0.3333 - val_loss: 19.8586 - learning_rate: 5.0000e-04\n",
      "Epoch 2/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.5625 - loss: 20.5006\n",
      "Epoch 2: val_loss improved from 19.85861 to 19.12121, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.4174 - loss: 20.4507 - val_accuracy: 0.3333 - val_loss: 19.1212 - learning_rate: 5.0000e-04\n",
      "Epoch 3/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.4688 - loss: 19.3158\n",
      "Epoch 3: val_loss improved from 19.12121 to 18.41265, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.4656 - loss: 19.3958 - val_accuracy: 0.3333 - val_loss: 18.4126 - learning_rate: 5.0000e-04\n",
      "Epoch 4/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.4688 - loss: 18.6801\n",
      "Epoch 4: val_loss improved from 18.41265 to 17.74043, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.4859 - loss: 18.7538 - val_accuracy: 0.3333 - val_loss: 17.7404 - learning_rate: 5.0000e-04\n",
      "Epoch 5/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.5625 - loss: 17.8286\n",
      "Epoch 5: val_loss improved from 17.74043 to 17.08960, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.5603 - loss: 17.7002 - val_accuracy: 0.3333 - val_loss: 17.0896 - learning_rate: 5.0000e-04\n",
      "Epoch 6/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.5625 - loss: 17.1859\n",
      "Epoch 6: val_loss improved from 17.08960 to 16.46942, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.4969 - loss: 17.2596 - val_accuracy: 0.3333 - val_loss: 16.4694 - learning_rate: 5.0000e-04\n",
      "Epoch 7/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.5625 - loss: 16.4250\n",
      "Epoch 7: val_loss improved from 16.46942 to 15.87444, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.6058 - loss: 16.2910 - val_accuracy: 0.3333 - val_loss: 15.8744 - learning_rate: 5.0000e-04\n",
      "Epoch 8/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.5000 - loss: 15.9124\n",
      "Epoch 8: val_loss improved from 15.87444 to 15.30303, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.5674 - loss: 15.8815 - val_accuracy: 0.3500 - val_loss: 15.3030 - learning_rate: 5.0000e-04\n",
      "Epoch 9/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7188 - loss: 14.8233\n",
      "Epoch 9: val_loss improved from 15.30303 to 14.75411, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.6179 - loss: 15.0435 - val_accuracy: 0.3667 - val_loss: 14.7541 - learning_rate: 5.0000e-04\n",
      "Epoch 10/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.5938 - loss: 14.6770\n",
      "Epoch 10: val_loss improved from 14.75411 to 14.22663, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.6116 - loss: 14.5659 - val_accuracy: 0.4000 - val_loss: 14.2266 - learning_rate: 5.0000e-04\n",
      "Epoch 11/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7812 - loss: 13.9377\n",
      "Epoch 11: val_loss improved from 14.22663 to 13.71953, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.6837 - loss: 13.9442 - val_accuracy: 0.4000 - val_loss: 13.7195 - learning_rate: 5.0000e-04\n",
      "Epoch 12/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7188 - loss: 13.7816\n",
      "Epoch 12: val_loss improved from 13.71953 to 13.23434, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.6857 - loss: 13.5477 - val_accuracy: 0.4000 - val_loss: 13.2343 - learning_rate: 5.0000e-04\n",
      "Epoch 13/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7812 - loss: 12.8133\n",
      "Epoch 13: val_loss improved from 13.23434 to 12.76704, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.7142 - loss: 12.8671 - val_accuracy: 0.4167 - val_loss: 12.7670 - learning_rate: 5.0000e-04\n",
      "Epoch 14/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7188 - loss: 12.5273\n",
      "Epoch 14: val_loss improved from 12.76704 to 12.31892, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.7294 - loss: 12.3553 - val_accuracy: 0.4167 - val_loss: 12.3189 - learning_rate: 5.0000e-04\n",
      "Epoch 15/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8125 - loss: 12.1295\n",
      "Epoch 15: val_loss improved from 12.31892 to 11.88707, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7511 - loss: 12.0017 - val_accuracy: 0.4167 - val_loss: 11.8871 - learning_rate: 5.0000e-04\n",
      "Epoch 16/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.6875 - loss: 11.8045\n",
      "Epoch 16: val_loss improved from 11.88707 to 11.47266, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7202 - loss: 11.5266 - val_accuracy: 0.4167 - val_loss: 11.4727 - learning_rate: 5.0000e-04\n",
      "Epoch 17/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.7500 - loss: 11.2121\n",
      "Epoch 17: val_loss improved from 11.47266 to 11.07766, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7303 - loss: 11.1475 - val_accuracy: 0.4167 - val_loss: 11.0777 - learning_rate: 5.0000e-04\n",
      "Epoch 18/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.8750 - loss: 10.5899\n",
      "Epoch 18: val_loss improved from 11.07766 to 10.69861, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8125 - loss: 10.6605 - val_accuracy: 0.4500 - val_loss: 10.6986 - learning_rate: 5.0000e-04\n",
      "Epoch 19/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.6875 - loss: 10.4295\n",
      "Epoch 19: val_loss improved from 10.69861 to 10.33587, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.7354 - loss: 10.3613 - val_accuracy: 0.4667 - val_loss: 10.3359 - learning_rate: 5.0000e-04\n",
      "Epoch 20/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8438 - loss: 9.9946\n",
      "Epoch 20: val_loss improved from 10.33587 to 9.98835, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.7704 - loss: 10.0427 - val_accuracy: 0.4833 - val_loss: 9.9883 - learning_rate: 5.0000e-04\n",
      "Epoch 21/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8125 - loss: 9.5822\n",
      "Epoch 21: val_loss improved from 9.98835 to 9.65003, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7974 - loss: 9.5081 - val_accuracy: 0.5500 - val_loss: 9.6500 - learning_rate: 5.0000e-04\n",
      "Epoch 22/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.6875 - loss: 9.6538\n",
      "Epoch 22: val_loss improved from 9.65003 to 9.32990, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.7729 - loss: 9.3717 - val_accuracy: 0.5667 - val_loss: 9.3299 - learning_rate: 5.0000e-04\n",
      "Epoch 23/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.8438 - loss: 8.9522\n",
      "Epoch 23: val_loss improved from 9.32990 to 9.01465, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8204 - loss: 8.8977 - val_accuracy: 0.6167 - val_loss: 9.0147 - learning_rate: 5.0000e-04\n",
      "Epoch 24/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.7812 - loss: 8.5994\n",
      "Epoch 24: val_loss improved from 9.01465 to 8.71089, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8238 - loss: 8.5783 - val_accuracy: 0.7333 - val_loss: 8.7109 - learning_rate: 5.0000e-04\n",
      "Epoch 25/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8750 - loss: 8.4435\n",
      "Epoch 25: val_loss improved from 8.71089 to 8.41304, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8412 - loss: 8.4190 - val_accuracy: 0.8667 - val_loss: 8.4130 - learning_rate: 5.0000e-04\n",
      "Epoch 26/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8750 - loss: 8.0076\n",
      "Epoch 26: val_loss improved from 8.41304 to 8.12985, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8461 - loss: 8.0374 - val_accuracy: 0.8833 - val_loss: 8.1298 - learning_rate: 5.0000e-04\n",
      "Epoch 27/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9375 - loss: 7.6376\n",
      "Epoch 27: val_loss improved from 8.12985 to 7.86192, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8359 - loss: 7.7862 - val_accuracy: 0.9000 - val_loss: 7.8619 - learning_rate: 5.0000e-04\n",
      "Epoch 28/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.6562 - loss: 8.1145\n",
      "Epoch 28: val_loss improved from 7.86192 to 7.60957, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.7567 - loss: 7.7769 - val_accuracy: 0.9000 - val_loss: 7.6096 - learning_rate: 5.0000e-04\n",
      "Epoch 29/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.7812 - loss: 7.4820\n",
      "Epoch 29: val_loss improved from 7.60957 to 7.36702, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8271 - loss: 7.3602 - val_accuracy: 0.9000 - val_loss: 7.3670 - learning_rate: 5.0000e-04\n",
      "Epoch 30/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 6.9237\n",
      "Epoch 30: val_loss improved from 7.36702 to 7.13541, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.8715 - loss: 7.0379 - val_accuracy: 0.9000 - val_loss: 7.1354 - learning_rate: 5.0000e-04\n",
      "Epoch 31/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8750 - loss: 6.8377\n",
      "Epoch 31: val_loss improved from 7.13541 to 6.91459, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8765 - loss: 6.8497 - val_accuracy: 0.9000 - val_loss: 6.9146 - learning_rate: 5.0000e-04\n",
      "Epoch 32/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8125 - loss: 6.7829\n",
      "Epoch 32: val_loss improved from 6.91459 to 6.69970, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8272 - loss: 6.7106 - val_accuracy: 0.9000 - val_loss: 6.6997 - learning_rate: 5.0000e-04\n",
      "Epoch 33/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9375 - loss: 6.2988\n",
      "Epoch 33: val_loss improved from 6.69970 to 6.49507, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.8501 - loss: 6.4695 - val_accuracy: 0.8833 - val_loss: 6.4951 - learning_rate: 5.0000e-04\n",
      "Epoch 34/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.7188 - loss: 6.8060\n",
      "Epoch 34: val_loss improved from 6.49507 to 6.29640, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.8300 - loss: 6.3938 - val_accuracy: 0.8667 - val_loss: 6.2964 - learning_rate: 5.0000e-04\n",
      "Epoch 35/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8750 - loss: 6.0764\n",
      "Epoch 35: val_loss improved from 6.29640 to 6.11230, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8821 - loss: 6.0746 - val_accuracy: 0.8500 - val_loss: 6.1123 - learning_rate: 5.0000e-04\n",
      "Epoch 36/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8125 - loss: 6.1209\n",
      "Epoch 36: val_loss improved from 6.11230 to 5.93248, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.8584 - loss: 5.9486 - val_accuracy: 0.8500 - val_loss: 5.9325 - learning_rate: 5.0000e-04\n",
      "Epoch 37/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.8750 - loss: 5.8044\n",
      "Epoch 37: val_loss improved from 5.93248 to 5.76041, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8897 - loss: 5.7273 - val_accuracy: 0.8500 - val_loss: 5.7604 - learning_rate: 5.0000e-04\n",
      "Epoch 38/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8125 - loss: 5.7214\n",
      "Epoch 38: val_loss improved from 5.76041 to 5.58874, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.8239 - loss: 5.7028 - val_accuracy: 0.8500 - val_loss: 5.5887 - learning_rate: 5.0000e-04\n",
      "Epoch 39/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9062 - loss: 5.4559\n",
      "Epoch 39: val_loss improved from 5.58874 to 5.41139, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8508 - loss: 5.5028 - val_accuracy: 0.8833 - val_loss: 5.4114 - learning_rate: 5.0000e-04\n",
      "Epoch 40/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9062 - loss: 5.3216\n",
      "Epoch 40: val_loss improved from 5.41139 to 5.24350, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8703 - loss: 5.3128 - val_accuracy: 0.8833 - val_loss: 5.2435 - learning_rate: 5.0000e-04\n",
      "Epoch 41/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.7812 - loss: 5.4438\n",
      "Epoch 41: val_loss improved from 5.24350 to 5.09248, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8433 - loss: 5.2178 - val_accuracy: 0.8667 - val_loss: 5.0925 - learning_rate: 5.0000e-04\n",
      "Epoch 42/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 4.8541\n",
      "Epoch 42: val_loss improved from 5.09248 to 4.95407, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8889 - loss: 4.9545 - val_accuracy: 0.8500 - val_loss: 4.9541 - learning_rate: 5.0000e-04\n",
      "Epoch 43/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8438 - loss: 4.9547\n",
      "Epoch 43: val_loss improved from 4.95407 to 4.82676, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.8831 - loss: 4.8260 - val_accuracy: 0.8333 - val_loss: 4.8268 - learning_rate: 5.0000e-04\n",
      "Epoch 44/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8125 - loss: 4.9810\n",
      "Epoch 44: val_loss improved from 4.82676 to 4.68507, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8674 - loss: 4.7556 - val_accuracy: 0.8500 - val_loss: 4.6851 - learning_rate: 5.0000e-04\n",
      "Epoch 45/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8438 - loss: 4.6764\n",
      "Epoch 45: val_loss improved from 4.68507 to 4.56154, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9029 - loss: 4.5378 - val_accuracy: 0.8500 - val_loss: 4.5615 - learning_rate: 5.0000e-04\n",
      "Epoch 46/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.8750 - loss: 4.4790\n",
      "Epoch 46: val_loss improved from 4.56154 to 4.43288, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8855 - loss: 4.4472 - val_accuracy: 0.8500 - val_loss: 4.4329 - learning_rate: 5.0000e-04\n",
      "Epoch 47/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8750 - loss: 4.3524\n",
      "Epoch 47: val_loss improved from 4.43288 to 4.29675, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.8724 - loss: 4.3602 - val_accuracy: 0.8667 - val_loss: 4.2968 - learning_rate: 5.0000e-04\n",
      "Epoch 48/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7812 - loss: 4.5250\n",
      "Epoch 48: val_loss improved from 4.29675 to 4.16930, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.8687 - loss: 4.2815 - val_accuracy: 0.8833 - val_loss: 4.1693 - learning_rate: 5.0000e-04\n",
      "Epoch 49/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 3.9688\n",
      "Epoch 49: val_loss improved from 4.16930 to 4.05139, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9297 - loss: 4.0540 - val_accuracy: 0.9000 - val_loss: 4.0514 - learning_rate: 5.0000e-04\n",
      "Epoch 50/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8750 - loss: 3.9972\n",
      "Epoch 50: val_loss improved from 4.05139 to 3.94036, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8828 - loss: 4.0141 - val_accuracy: 0.9000 - val_loss: 3.9404 - learning_rate: 5.0000e-04\n",
      "Epoch 51/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9688 - loss: 3.7395\n",
      "Epoch 51: val_loss improved from 3.94036 to 3.83818, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9100 - loss: 3.8988 - val_accuracy: 0.9000 - val_loss: 3.8382 - learning_rate: 5.0000e-04\n",
      "Epoch 52/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.8750 - loss: 3.8324\n",
      "Epoch 52: val_loss improved from 3.83818 to 3.73136, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.8940 - loss: 3.7717 - val_accuracy: 0.9000 - val_loss: 3.7314 - learning_rate: 5.0000e-04\n",
      "Epoch 53/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.9062 - loss: 3.7905\n",
      "Epoch 53: val_loss improved from 3.73136 to 3.63503, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9067 - loss: 3.7422 - val_accuracy: 0.9000 - val_loss: 3.6350 - learning_rate: 5.0000e-04\n",
      "Epoch 54/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8750 - loss: 3.7546\n",
      "Epoch 54: val_loss improved from 3.63503 to 3.53899, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9119 - loss: 3.6197 - val_accuracy: 0.9000 - val_loss: 3.5390 - learning_rate: 5.0000e-04\n",
      "Epoch 55/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9062 - loss: 3.4778\n",
      "Epoch 55: val_loss improved from 3.53899 to 3.46138, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.8963 - loss: 3.5229 - val_accuracy: 0.8833 - val_loss: 3.4614 - learning_rate: 5.0000e-04\n",
      "Epoch 56/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 1.0000 - loss: 3.2858\n",
      "Epoch 56: val_loss improved from 3.46138 to 3.38744, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9143 - loss: 3.4177 - val_accuracy: 0.8667 - val_loss: 3.3874 - learning_rate: 5.0000e-04\n",
      "Epoch 57/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8750 - loss: 3.3876\n",
      "Epoch 57: val_loss improved from 3.38744 to 3.29335, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9008 - loss: 3.3580 - val_accuracy: 0.8667 - val_loss: 3.2933 - learning_rate: 5.0000e-04\n",
      "Epoch 58/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9062 - loss: 3.2136\n",
      "Epoch 58: val_loss improved from 3.29335 to 3.22119, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.8905 - loss: 3.2853 - val_accuracy: 0.8500 - val_loss: 3.2212 - learning_rate: 5.0000e-04\n",
      "Epoch 59/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8750 - loss: 3.1628\n",
      "Epoch 59: val_loss improved from 3.22119 to 3.12308, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8889 - loss: 3.2173 - val_accuracy: 0.8667 - val_loss: 3.1231 - learning_rate: 5.0000e-04\n",
      "Epoch 60/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8750 - loss: 3.1448\n",
      "Epoch 60: val_loss improved from 3.12308 to 3.02112, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8958 - loss: 3.1013 - val_accuracy: 0.9167 - val_loss: 3.0211 - learning_rate: 5.0000e-04\n",
      "Epoch 61/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9062 - loss: 3.0600\n",
      "Epoch 61: val_loss improved from 3.02112 to 2.94342, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9017 - loss: 3.0783 - val_accuracy: 0.9333 - val_loss: 2.9434 - learning_rate: 5.0000e-04\n",
      "Epoch 62/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8750 - loss: 3.0233\n",
      "Epoch 62: val_loss improved from 2.94342 to 2.92785, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.8936 - loss: 2.9834 - val_accuracy: 0.8500 - val_loss: 2.9279 - learning_rate: 5.0000e-04\n",
      "Epoch 63/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 2.7350\n",
      "Epoch 63: val_loss improved from 2.92785 to 2.87941, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9210 - loss: 2.8326 - val_accuracy: 0.8333 - val_loss: 2.8794 - learning_rate: 5.0000e-04\n",
      "Epoch 64/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8750 - loss: 2.8588\n",
      "Epoch 64: val_loss improved from 2.87941 to 2.79032, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9053 - loss: 2.8120 - val_accuracy: 0.8667 - val_loss: 2.7903 - learning_rate: 5.0000e-04\n",
      "Epoch 65/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8438 - loss: 2.8594\n",
      "Epoch 65: val_loss improved from 2.79032 to 2.69433, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8782 - loss: 2.7994 - val_accuracy: 0.8833 - val_loss: 2.6943 - learning_rate: 5.0000e-04\n",
      "Epoch 66/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9062 - loss: 2.6606\n",
      "Epoch 66: val_loss improved from 2.69433 to 2.63639, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9113 - loss: 2.6953 - val_accuracy: 0.8833 - val_loss: 2.6364 - learning_rate: 5.0000e-04\n",
      "Epoch 67/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9062 - loss: 2.5876\n",
      "Epoch 67: val_loss improved from 2.63639 to 2.55700, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.8918 - loss: 2.6601 - val_accuracy: 0.9000 - val_loss: 2.5570 - learning_rate: 5.0000e-04\n",
      "Epoch 68/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9062 - loss: 2.6927\n",
      "Epoch 68: val_loss improved from 2.55700 to 2.48638, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9102 - loss: 2.5850 - val_accuracy: 0.9167 - val_loss: 2.4864 - learning_rate: 5.0000e-04\n",
      "Epoch 69/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8750 - loss: 2.7734\n",
      "Epoch 69: val_loss improved from 2.48638 to 2.42193, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9337 - loss: 2.5330 - val_accuracy: 0.9500 - val_loss: 2.4219 - learning_rate: 5.0000e-04\n",
      "Epoch 70/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9375 - loss: 2.5014\n",
      "Epoch 70: val_loss improved from 2.42193 to 2.36554, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9098 - loss: 2.4852 - val_accuracy: 0.9500 - val_loss: 2.3655 - learning_rate: 5.0000e-04\n",
      "Epoch 71/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9688 - loss: 2.3468\n",
      "Epoch 71: val_loss improved from 2.36554 to 2.31288, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9130 - loss: 2.3781 - val_accuracy: 0.9667 - val_loss: 2.3129 - learning_rate: 5.0000e-04\n",
      "Epoch 72/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8438 - loss: 2.7119\n",
      "Epoch 72: val_loss improved from 2.31288 to 2.25634, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9017 - loss: 2.4225 - val_accuracy: 0.9667 - val_loss: 2.2563 - learning_rate: 5.0000e-04\n",
      "Epoch 73/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9375 - loss: 2.2733\n",
      "Epoch 73: val_loss improved from 2.25634 to 2.20315, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9227 - loss: 2.2927 - val_accuracy: 0.9667 - val_loss: 2.2032 - learning_rate: 5.0000e-04\n",
      "Epoch 74/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9062 - loss: 2.2674\n",
      "Epoch 74: val_loss improved from 2.20315 to 2.15880, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9178 - loss: 2.2543 - val_accuracy: 0.9333 - val_loss: 2.1588 - learning_rate: 5.0000e-04\n",
      "Epoch 75/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 2.2280\n",
      "Epoch 75: val_loss improved from 2.15880 to 2.11549, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9208 - loss: 2.1867 - val_accuracy: 0.9167 - val_loss: 2.1155 - learning_rate: 5.0000e-04\n",
      "Epoch 76/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 30ms/step - accuracy: 0.9688 - loss: 2.0354\n",
      "Epoch 76: val_loss improved from 2.11549 to 2.07682, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9281 - loss: 2.1051 - val_accuracy: 0.9000 - val_loss: 2.0768 - learning_rate: 5.0000e-04\n",
      "Epoch 77/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9062 - loss: 2.1216\n",
      "Epoch 77: val_loss improved from 2.07682 to 2.01239, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.8974 - loss: 2.1175 - val_accuracy: 0.9167 - val_loss: 2.0124 - learning_rate: 5.0000e-04\n",
      "Epoch 78/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8125 - loss: 2.1764\n",
      "Epoch 78: val_loss improved from 2.01239 to 1.95057, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.8919 - loss: 2.0618 - val_accuracy: 0.9500 - val_loss: 1.9506 - learning_rate: 5.0000e-04\n",
      "Epoch 79/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 1.8800\n",
      "Epoch 79: val_loss improved from 1.95057 to 1.92360, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9457 - loss: 1.9556 - val_accuracy: 0.9167 - val_loss: 1.9236 - learning_rate: 5.0000e-04\n",
      "Epoch 80/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 2.0234\n",
      "Epoch 80: val_loss improved from 1.92360 to 1.88009, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9214 - loss: 1.9948 - val_accuracy: 0.9167 - val_loss: 1.8801 - learning_rate: 5.0000e-04\n",
      "Epoch 81/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 1.8071\n",
      "Epoch 81: val_loss improved from 1.88009 to 1.82445, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9413 - loss: 1.8646 - val_accuracy: 0.9500 - val_loss: 1.8244 - learning_rate: 5.0000e-04\n",
      "Epoch 82/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9375 - loss: 1.9664\n",
      "Epoch 82: val_loss improved from 1.82445 to 1.79501, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9201 - loss: 1.9111 - val_accuracy: 0.9167 - val_loss: 1.7950 - learning_rate: 5.0000e-04\n",
      "Epoch 83/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9375 - loss: 1.7882\n",
      "Epoch 83: val_loss improved from 1.79501 to 1.74102, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9291 - loss: 1.8200 - val_accuracy: 0.9500 - val_loss: 1.7410 - learning_rate: 5.0000e-04\n",
      "Epoch 84/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9375 - loss: 1.7420\n",
      "Epoch 84: val_loss improved from 1.74102 to 1.68991, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9227 - loss: 1.7816 - val_accuracy: 0.9667 - val_loss: 1.6899 - learning_rate: 5.0000e-04\n",
      "Epoch 85/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9062 - loss: 1.7879\n",
      "Epoch 85: val_loss improved from 1.68991 to 1.64686, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9038 - loss: 1.8210 - val_accuracy: 0.9667 - val_loss: 1.6469 - learning_rate: 5.0000e-04\n",
      "Epoch 86/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9062 - loss: 1.7695\n",
      "Epoch 86: val_loss improved from 1.64686 to 1.61250, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9144 - loss: 1.7278 - val_accuracy: 0.9667 - val_loss: 1.6125 - learning_rate: 5.0000e-04\n",
      "Epoch 87/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 33ms/step - accuracy: 0.9688 - loss: 1.5883\n",
      "Epoch 87: val_loss improved from 1.61250 to 1.60194, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9293 - loss: 1.6315 - val_accuracy: 0.9167 - val_loss: 1.6019 - learning_rate: 5.0000e-04\n",
      "Epoch 88/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 34ms/step - accuracy: 0.9375 - loss: 1.6712\n",
      "Epoch 88: val_loss did not improve from 1.60194\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9314 - loss: 1.6487 - val_accuracy: 0.8500 - val_loss: 1.6363 - learning_rate: 5.0000e-04\n",
      "Epoch 89/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9062 - loss: 1.6185\n",
      "Epoch 89: val_loss improved from 1.60194 to 1.55754, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9400 - loss: 1.5704 - val_accuracy: 0.9000 - val_loss: 1.5575 - learning_rate: 5.0000e-04\n",
      "Epoch 90/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.9688 - loss: 1.4955\n",
      "Epoch 90: val_loss improved from 1.55754 to 1.47846, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9497 - loss: 1.5148 - val_accuracy: 0.9667 - val_loss: 1.4785 - learning_rate: 5.0000e-04\n",
      "Epoch 91/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9688 - loss: 1.5221\n",
      "Epoch 91: val_loss improved from 1.47846 to 1.44135, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9356 - loss: 1.5770 - val_accuracy: 0.9667 - val_loss: 1.4413 - learning_rate: 5.0000e-04\n",
      "Epoch 92/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 1.4362\n",
      "Epoch 92: val_loss improved from 1.44135 to 1.41770, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9303 - loss: 1.4984 - val_accuracy: 0.9500 - val_loss: 1.4177 - learning_rate: 5.0000e-04\n",
      "Epoch 93/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8438 - loss: 1.6083\n",
      "Epoch 93: val_loss did not improve from 1.41770\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9061 - loss: 1.5271 - val_accuracy: 0.9167 - val_loss: 1.4380 - learning_rate: 5.0000e-04\n",
      "Epoch 94/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9688 - loss: 1.3938\n",
      "Epoch 94: val_loss improved from 1.41770 to 1.35155, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9523 - loss: 1.3948 - val_accuracy: 0.9500 - val_loss: 1.3516 - learning_rate: 5.0000e-04\n",
      "Epoch 95/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.8750 - loss: 1.4594\n",
      "Epoch 95: val_loss improved from 1.35155 to 1.31376, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9048 - loss: 1.4466 - val_accuracy: 0.9667 - val_loss: 1.3138 - learning_rate: 5.0000e-04\n",
      "Epoch 96/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9375 - loss: 1.3027\n",
      "Epoch 96: val_loss improved from 1.31376 to 1.30450, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9305 - loss: 1.3735 - val_accuracy: 0.9500 - val_loss: 1.3045 - learning_rate: 5.0000e-04\n",
      "Epoch 97/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9375 - loss: 1.2838\n",
      "Epoch 97: val_loss improved from 1.30450 to 1.29259, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9451 - loss: 1.3183 - val_accuracy: 0.9500 - val_loss: 1.2926 - learning_rate: 5.0000e-04\n",
      "Epoch 98/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9375 - loss: 1.2562\n",
      "Epoch 98: val_loss did not improve from 1.29259\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9252 - loss: 1.2979 - val_accuracy: 0.8500 - val_loss: 1.3397 - learning_rate: 5.0000e-04\n",
      "Epoch 99/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.7500 - loss: 1.5428\n",
      "Epoch 99: val_loss did not improve from 1.29259\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8612 - loss: 1.4199 - val_accuracy: 0.8500 - val_loss: 1.3616 - learning_rate: 5.0000e-04\n",
      "Epoch 100/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.8750 - loss: 1.4334\n",
      "Epoch 100: val_loss did not improve from 1.29259\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9258 - loss: 1.3076 - val_accuracy: 0.8500 - val_loss: 1.3128 - learning_rate: 5.0000e-04\n",
      "Epoch 101/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9062 - loss: 1.2871\n",
      "Epoch 101: val_loss improved from 1.29259 to 1.20858, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9239 - loss: 1.2819 - val_accuracy: 0.9333 - val_loss: 1.2086 - learning_rate: 5.0000e-04\n",
      "Epoch 102/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 1.1531\n",
      "Epoch 102: val_loss improved from 1.20858 to 1.17793, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9514 - loss: 1.1870 - val_accuracy: 0.9333 - val_loss: 1.1779 - learning_rate: 5.0000e-04\n",
      "Epoch 103/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8750 - loss: 1.1963\n",
      "Epoch 103: val_loss improved from 1.17793 to 1.15487, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9425 - loss: 1.1620 - val_accuracy: 0.9167 - val_loss: 1.1549 - learning_rate: 5.0000e-04\n",
      "Epoch 104/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 1.1422\n",
      "Epoch 104: val_loss improved from 1.15487 to 1.12366, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9243 - loss: 1.1906 - val_accuracy: 0.9167 - val_loss: 1.1237 - learning_rate: 5.0000e-04\n",
      "Epoch 105/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.9375 - loss: 1.1524\n",
      "Epoch 105: val_loss improved from 1.12366 to 1.04664, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9069 - loss: 1.1958 - val_accuracy: 0.9667 - val_loss: 1.0466 - learning_rate: 5.0000e-04\n",
      "Epoch 106/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9062 - loss: 1.1400\n",
      "Epoch 106: val_loss improved from 1.04664 to 1.03421, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9348 - loss: 1.1464 - val_accuracy: 0.9667 - val_loss: 1.0342 - learning_rate: 5.0000e-04\n",
      "Epoch 107/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9062 - loss: 1.2650\n",
      "Epoch 107: val_loss improved from 1.03421 to 1.01711, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9446 - loss: 1.1138 - val_accuracy: 0.9667 - val_loss: 1.0171 - learning_rate: 5.0000e-04\n",
      "Epoch 108/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.8750 - loss: 1.3398\n",
      "Epoch 108: val_loss did not improve from 1.01711\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9196 - loss: 1.1506 - val_accuracy: 0.9333 - val_loss: 1.0421 - learning_rate: 5.0000e-04\n",
      "Epoch 109/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9688 - loss: 1.0142\n",
      "Epoch 109: val_loss improved from 1.01711 to 0.96048, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9306 - loss: 1.0979 - val_accuracy: 0.9667 - val_loss: 0.9605 - learning_rate: 5.0000e-04\n",
      "Epoch 110/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 1.0000 - loss: 0.9332\n",
      "Epoch 110: val_loss improved from 0.96048 to 0.94660, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9673 - loss: 1.0040 - val_accuracy: 0.9667 - val_loss: 0.9466 - learning_rate: 5.0000e-04\n",
      "Epoch 111/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 1.0421\n",
      "Epoch 111: val_loss improved from 0.94660 to 0.93630, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9327 - loss: 1.0322 - val_accuracy: 0.9667 - val_loss: 0.9363 - learning_rate: 5.0000e-04\n",
      "Epoch 112/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.9697\n",
      "Epoch 112: val_loss improved from 0.93630 to 0.91172, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9377 - loss: 1.0317 - val_accuracy: 0.9667 - val_loss: 0.9117 - learning_rate: 5.0000e-04\n",
      "Epoch 113/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.9688 - loss: 0.9318\n",
      "Epoch 113: val_loss improved from 0.91172 to 0.88382, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9353 - loss: 1.0125 - val_accuracy: 0.9833 - val_loss: 0.8838 - learning_rate: 5.0000e-04\n",
      "Epoch 114/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.9643\n",
      "Epoch 114: val_loss did not improve from 0.88382\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9275 - loss: 1.0040 - val_accuracy: 0.9333 - val_loss: 0.9438 - learning_rate: 5.0000e-04\n",
      "Epoch 115/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.8561\n",
      "Epoch 115: val_loss did not improve from 0.88382\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9640 - loss: 0.9836 - val_accuracy: 0.9333 - val_loss: 0.9053 - learning_rate: 5.0000e-04\n",
      "Epoch 116/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8750 - loss: 1.1963\n",
      "Epoch 116: val_loss improved from 0.88382 to 0.84522, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9375 - loss: 1.0106 - val_accuracy: 0.9833 - val_loss: 0.8452 - learning_rate: 5.0000e-04\n",
      "Epoch 117/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9375 - loss: 0.9607\n",
      "Epoch 117: val_loss improved from 0.84522 to 0.82822, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9341 - loss: 0.9399 - val_accuracy: 0.9667 - val_loss: 0.8282 - learning_rate: 5.0000e-04\n",
      "Epoch 118/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.8438 - loss: 1.0636\n",
      "Epoch 118: val_loss improved from 0.82822 to 0.80976, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9142 - loss: 0.9251 - val_accuracy: 0.9667 - val_loss: 0.8098 - learning_rate: 5.0000e-04\n",
      "Epoch 119/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 0.8888\n",
      "Epoch 119: val_loss improved from 0.80976 to 0.78621, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9375 - loss: 0.9281 - val_accuracy: 0.9833 - val_loss: 0.7862 - learning_rate: 5.0000e-04\n",
      "Epoch 120/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.9062 - loss: 0.9456\n",
      "Epoch 120: val_loss did not improve from 0.78621\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9557 - loss: 0.8508 - val_accuracy: 0.9667 - val_loss: 0.7879 - learning_rate: 5.0000e-04\n",
      "Epoch 121/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9062 - loss: 0.9892\n",
      "Epoch 121: val_loss improved from 0.78621 to 0.75664, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9365 - loss: 0.8961 - val_accuracy: 0.9833 - val_loss: 0.7566 - learning_rate: 5.0000e-04\n",
      "Epoch 122/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9688 - loss: 0.8770\n",
      "Epoch 122: val_loss improved from 0.75664 to 0.74384, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9614 - loss: 0.8330 - val_accuracy: 1.0000 - val_loss: 0.7438 - learning_rate: 5.0000e-04\n",
      "Epoch 123/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.9375 - loss: 0.9293\n",
      "Epoch 123: val_loss improved from 0.74384 to 0.72407, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9463 - loss: 0.8445 - val_accuracy: 1.0000 - val_loss: 0.7241 - learning_rate: 5.0000e-04\n",
      "Epoch 124/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9375 - loss: 0.8597\n",
      "Epoch 124: val_loss improved from 0.72407 to 0.72194, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9455 - loss: 0.8221 - val_accuracy: 0.9833 - val_loss: 0.7219 - learning_rate: 5.0000e-04\n",
      "Epoch 125/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 0.8771\n",
      "Epoch 125: val_loss improved from 0.72194 to 0.70610, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9546 - loss: 0.8019 - val_accuracy: 0.9833 - val_loss: 0.7061 - learning_rate: 5.0000e-04\n",
      "Epoch 126/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.6989\n",
      "Epoch 126: val_loss improved from 0.70610 to 0.68539, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9621 - loss: 0.7862 - val_accuracy: 0.9833 - val_loss: 0.6854 - learning_rate: 5.0000e-04\n",
      "Epoch 127/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.6924\n",
      "Epoch 127: val_loss improved from 0.68539 to 0.67150, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9666 - loss: 0.7449 - val_accuracy: 0.9833 - val_loss: 0.6715 - learning_rate: 5.0000e-04\n",
      "Epoch 128/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.6520\n",
      "Epoch 128: val_loss improved from 0.67150 to 0.66079, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9519 - loss: 0.7287 - val_accuracy: 0.9833 - val_loss: 0.6608 - learning_rate: 5.0000e-04\n",
      "Epoch 129/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.6743\n",
      "Epoch 129: val_loss did not improve from 0.66079\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9617 - loss: 0.7198 - val_accuracy: 0.9333 - val_loss: 0.6965 - learning_rate: 5.0000e-04\n",
      "Epoch 130/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.9688 - loss: 0.6536\n",
      "Epoch 130: val_loss did not improve from 0.66079\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9587 - loss: 0.7035 - val_accuracy: 0.9333 - val_loss: 0.6870 - learning_rate: 5.0000e-04\n",
      "Epoch 131/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 1.0000 - loss: 0.6787\n",
      "Epoch 131: val_loss did not improve from 0.66079\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9626 - loss: 0.7094 - val_accuracy: 0.9333 - val_loss: 0.6623 - learning_rate: 5.0000e-04\n",
      "Epoch 132/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.6226\n",
      "Epoch 132: val_loss improved from 0.66079 to 0.64546, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9537 - loss: 0.6873 - val_accuracy: 0.9667 - val_loss: 0.6455 - learning_rate: 5.0000e-04\n",
      "Epoch 133/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.7761\n",
      "Epoch 133: val_loss did not improve from 0.64546\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9488 - loss: 0.7091 - val_accuracy: 0.8667 - val_loss: 0.8287 - learning_rate: 5.0000e-04\n",
      "Epoch 134/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 0.7680\n",
      "Epoch 134: val_loss did not improve from 0.64546\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9520 - loss: 0.6969 - val_accuracy: 0.9000 - val_loss: 0.7160 - learning_rate: 5.0000e-04\n",
      "Epoch 135/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 0.6961\n",
      "Epoch 135: val_loss did not improve from 0.64546\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9486 - loss: 0.6794 - val_accuracy: 0.8833 - val_loss: 0.6831 - learning_rate: 5.0000e-04\n",
      "Epoch 136/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 0.6344\n",
      "Epoch 136: val_loss improved from 0.64546 to 0.64303, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9479 - loss: 0.6524 - val_accuracy: 0.9333 - val_loss: 0.6430 - learning_rate: 5.0000e-04\n",
      "Epoch 137/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9688 - loss: 0.5966\n",
      "Epoch 137: val_loss improved from 0.64303 to 0.57722, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9669 - loss: 0.6129 - val_accuracy: 0.9667 - val_loss: 0.5772 - learning_rate: 5.0000e-04\n",
      "Epoch 138/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 0.6569\n",
      "Epoch 138: val_loss improved from 0.57722 to 0.55158, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9412 - loss: 0.6367 - val_accuracy: 0.9833 - val_loss: 0.5516 - learning_rate: 5.0000e-04\n",
      "Epoch 139/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.5428\n",
      "Epoch 139: val_loss improved from 0.55158 to 0.53620, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9809 - loss: 0.5627 - val_accuracy: 1.0000 - val_loss: 0.5362 - learning_rate: 5.0000e-04\n",
      "Epoch 140/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9375 - loss: 0.6784\n",
      "Epoch 140: val_loss improved from 0.53620 to 0.52058, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9661 - loss: 0.5983 - val_accuracy: 1.0000 - val_loss: 0.5206 - learning_rate: 5.0000e-04\n",
      "Epoch 141/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.5245\n",
      "Epoch 141: val_loss improved from 0.52058 to 0.51088, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9821 - loss: 0.5603 - val_accuracy: 1.0000 - val_loss: 0.5109 - learning_rate: 5.0000e-04\n",
      "Epoch 142/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.5235\n",
      "Epoch 142: val_loss did not improve from 0.51088\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9826 - loss: 0.5390 - val_accuracy: 0.9833 - val_loss: 0.5133 - learning_rate: 5.0000e-04\n",
      "Epoch 143/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.9688 - loss: 0.5885\n",
      "Epoch 143: val_loss did not improve from 0.51088\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9644 - loss: 0.5682 - val_accuracy: 0.9500 - val_loss: 0.5204 - learning_rate: 5.0000e-04\n",
      "Epoch 144/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9375 - loss: 0.5709\n",
      "Epoch 144: val_loss did not improve from 0.51088\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9544 - loss: 0.5940 - val_accuracy: 0.9333 - val_loss: 0.5680 - learning_rate: 5.0000e-04\n",
      "Epoch 145/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 1.0000 - loss: 0.4836\n",
      "Epoch 145: val_loss did not improve from 0.51088\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9707 - loss: 0.5522 - val_accuracy: 0.8667 - val_loss: 0.7580 - learning_rate: 5.0000e-04\n",
      "Epoch 146/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 0.5807\n",
      "Epoch 146: val_loss did not improve from 0.51088\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9675 - loss: 0.5315 - val_accuracy: 0.9500 - val_loss: 0.5421 - learning_rate: 5.0000e-04\n",
      "Epoch 147/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9062 - loss: 0.5578\n",
      "Epoch 147: val_loss improved from 0.51088 to 0.48918, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9509 - loss: 0.5456 - val_accuracy: 0.9667 - val_loss: 0.4892 - learning_rate: 2.5000e-04\n",
      "Epoch 148/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 0.5424\n",
      "Epoch 148: val_loss did not improve from 0.48918\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9664 - loss: 0.5169 - val_accuracy: 0.9500 - val_loss: 0.5138 - learning_rate: 2.5000e-04\n",
      "Epoch 149/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.4484\n",
      "Epoch 149: val_loss did not improve from 0.48918\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9781 - loss: 0.5074 - val_accuracy: 0.9667 - val_loss: 0.4981 - learning_rate: 2.5000e-04\n",
      "Epoch 150/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.4730\n",
      "Epoch 150: val_loss improved from 0.48918 to 0.47232, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9587 - loss: 0.5185 - val_accuracy: 0.9833 - val_loss: 0.4723 - learning_rate: 2.5000e-04\n",
      "Epoch 151/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.4740\n",
      "Epoch 151: val_loss improved from 0.47232 to 0.45712, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9868 - loss: 0.4862 - val_accuracy: 1.0000 - val_loss: 0.4571 - learning_rate: 2.5000e-04\n",
      "Epoch 152/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.4820\n",
      "Epoch 152: val_loss improved from 0.45712 to 0.45184, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9789 - loss: 0.4909 - val_accuracy: 1.0000 - val_loss: 0.4518 - learning_rate: 2.5000e-04\n",
      "Epoch 153/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.4602\n",
      "Epoch 153: val_loss did not improve from 0.45184\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9688 - loss: 0.4930 - val_accuracy: 0.9667 - val_loss: 0.4538 - learning_rate: 2.5000e-04\n",
      "Epoch 154/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.4404\n",
      "Epoch 154: val_loss did not improve from 0.45184\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9905 - loss: 0.4510 - val_accuracy: 0.9667 - val_loss: 0.4632 - learning_rate: 2.5000e-04\n",
      "Epoch 155/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.4198\n",
      "Epoch 155: val_loss did not improve from 0.45184\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9911 - loss: 0.4554 - val_accuracy: 0.9667 - val_loss: 0.4748 - learning_rate: 2.5000e-04\n",
      "Epoch 156/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.4413\n",
      "Epoch 156: val_loss improved from 0.45184 to 0.45004, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9755 - loss: 0.4683 - val_accuracy: 0.9667 - val_loss: 0.4500 - learning_rate: 2.5000e-04\n",
      "Epoch 157/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9062 - loss: 0.5719\n",
      "Epoch 157: val_loss improved from 0.45004 to 0.43983, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9617 - loss: 0.4916 - val_accuracy: 0.9667 - val_loss: 0.4398 - learning_rate: 2.5000e-04\n",
      "Epoch 158/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 0.5625\n",
      "Epoch 158: val_loss did not improve from 0.43983\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9702 - loss: 0.5043 - val_accuracy: 0.9667 - val_loss: 0.4545 - learning_rate: 2.5000e-04\n",
      "Epoch 159/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.4762\n",
      "Epoch 159: val_loss improved from 0.43983 to 0.42243, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9703 - loss: 0.4725 - val_accuracy: 0.9833 - val_loss: 0.4224 - learning_rate: 2.5000e-04\n",
      "Epoch 160/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.4435\n",
      "Epoch 160: val_loss improved from 0.42243 to 0.40960, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9741 - loss: 0.4566 - val_accuracy: 1.0000 - val_loss: 0.4096 - learning_rate: 2.5000e-04\n",
      "Epoch 161/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 1.0000 - loss: 0.4674\n",
      "Epoch 161: val_loss improved from 0.40960 to 0.40414, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9878 - loss: 0.4503 - val_accuracy: 1.0000 - val_loss: 0.4041 - learning_rate: 2.5000e-04\n",
      "Epoch 162/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - accuracy: 0.8750 - loss: 0.5826\n",
      "Epoch 162: val_loss did not improve from 0.40414\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9463 - loss: 0.4850 - val_accuracy: 0.9833 - val_loss: 0.4403 - learning_rate: 2.5000e-04\n",
      "Epoch 163/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9375 - loss: 0.5101\n",
      "Epoch 163: val_loss did not improve from 0.40414\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9578 - loss: 0.4872 - val_accuracy: 0.9667 - val_loss: 0.4184 - learning_rate: 2.5000e-04\n",
      "Epoch 164/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.4134\n",
      "Epoch 164: val_loss did not improve from 0.40414\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9766 - loss: 0.4389 - val_accuracy: 0.9667 - val_loss: 0.4363 - learning_rate: 2.5000e-04\n",
      "Epoch 165/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9062 - loss: 0.5396\n",
      "Epoch 165: val_loss did not improve from 0.40414\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9386 - loss: 0.4851 - val_accuracy: 0.9500 - val_loss: 0.4694 - learning_rate: 2.5000e-04\n",
      "Epoch 166/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 0.4461\n",
      "Epoch 166: val_loss did not improve from 0.40414\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9529 - loss: 0.4460 - val_accuracy: 0.9500 - val_loss: 0.4681 - learning_rate: 2.5000e-04\n",
      "Epoch 167/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.4651\n",
      "Epoch 167: val_loss did not improve from 0.40414\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9680 - loss: 0.4711 - val_accuracy: 0.9500 - val_loss: 0.4743 - learning_rate: 1.2500e-04\n",
      "Epoch 168/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9062 - loss: 0.5444\n",
      "Epoch 168: val_loss did not improve from 0.40414\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9460 - loss: 0.4668 - val_accuracy: 0.9333 - val_loss: 0.4850 - learning_rate: 1.2500e-04\n",
      "Epoch 169/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.4170\n",
      "Epoch 169: val_loss did not improve from 0.40414\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9552 - loss: 0.4636 - val_accuracy: 0.9667 - val_loss: 0.4428 - learning_rate: 1.2500e-04\n",
      "Epoch 170/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.4193\n",
      "Epoch 170: val_loss did not improve from 0.40414\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9784 - loss: 0.4118 - val_accuracy: 0.9667 - val_loss: 0.4142 - learning_rate: 1.2500e-04\n",
      "Epoch 171/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.3966\n",
      "Epoch 171: val_loss improved from 0.40414 to 0.39853, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9635 - loss: 0.4698 - val_accuracy: 0.9667 - val_loss: 0.3985 - learning_rate: 1.2500e-04\n",
      "Epoch 172/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.4163\n",
      "Epoch 172: val_loss improved from 0.39853 to 0.39692, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9823 - loss: 0.4168 - val_accuracy: 0.9667 - val_loss: 0.3969 - learning_rate: 1.2500e-04\n",
      "Epoch 173/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 1.0000 - loss: 0.3824\n",
      "Epoch 173: val_loss improved from 0.39692 to 0.39661, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9838 - loss: 0.4042 - val_accuracy: 0.9667 - val_loss: 0.3966 - learning_rate: 1.2500e-04\n",
      "Epoch 174/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.3948\n",
      "Epoch 174: val_loss did not improve from 0.39661\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9799 - loss: 0.4183 - val_accuracy: 0.9667 - val_loss: 0.4014 - learning_rate: 1.2500e-04\n",
      "Epoch 175/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.4114\n",
      "Epoch 175: val_loss improved from 0.39661 to 0.39029, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9819 - loss: 0.4030 - val_accuracy: 0.9667 - val_loss: 0.3903 - learning_rate: 1.2500e-04\n",
      "Epoch 176/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.9688 - loss: 0.4004\n",
      "Epoch 176: val_loss did not improve from 0.39029\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9724 - loss: 0.4106 - val_accuracy: 0.9667 - val_loss: 0.3991 - learning_rate: 1.2500e-04\n",
      "Epoch 177/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.4038\n",
      "Epoch 177: val_loss did not improve from 0.39029\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9561 - loss: 0.4461 - val_accuracy: 0.9667 - val_loss: 0.3975 - learning_rate: 1.2500e-04\n",
      "Epoch 178/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.3828\n",
      "Epoch 178: val_loss improved from 0.39029 to 0.37972, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9766 - loss: 0.4109 - val_accuracy: 0.9667 - val_loss: 0.3797 - learning_rate: 1.2500e-04\n",
      "Epoch 179/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.4261\n",
      "Epoch 179: val_loss improved from 0.37972 to 0.36832, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9757 - loss: 0.3982 - val_accuracy: 0.9833 - val_loss: 0.3683 - learning_rate: 1.2500e-04\n",
      "Epoch 180/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9688 - loss: 0.4166\n",
      "Epoch 180: val_loss improved from 0.36832 to 0.36723, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9531 - loss: 0.4870 - val_accuracy: 0.9833 - val_loss: 0.3672 - learning_rate: 1.2500e-04\n",
      "Epoch 181/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 35ms/step - accuracy: 0.9375 - loss: 0.5118\n",
      "Epoch 181: val_loss did not improve from 0.36723\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9617 - loss: 0.4300 - val_accuracy: 0.9667 - val_loss: 0.3875 - learning_rate: 1.2500e-04\n",
      "Epoch 182/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9688 - loss: 0.4185\n",
      "Epoch 182: val_loss did not improve from 0.36723\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9756 - loss: 0.4037 - val_accuracy: 0.9667 - val_loss: 0.3794 - learning_rate: 1.2500e-04\n",
      "Epoch 183/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - accuracy: 0.9688 - loss: 0.4164\n",
      "Epoch 183: val_loss did not improve from 0.36723\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9798 - loss: 0.3957 - val_accuracy: 0.9667 - val_loss: 0.4104 - learning_rate: 1.2500e-04\n",
      "Epoch 184/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.3908\n",
      "Epoch 184: val_loss did not improve from 0.36723\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9602 - loss: 0.4210 - val_accuracy: 0.9333 - val_loss: 0.4276 - learning_rate: 1.2500e-04\n",
      "Epoch 185/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.3689\n",
      "Epoch 185: val_loss improved from 0.36723 to 0.35936, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9863 - loss: 0.3853 - val_accuracy: 0.9833 - val_loss: 0.3594 - learning_rate: 1.2500e-04\n",
      "Epoch 186/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9375 - loss: 0.5169\n",
      "Epoch 186: val_loss improved from 0.35936 to 0.34998, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9737 - loss: 0.4349 - val_accuracy: 1.0000 - val_loss: 0.3500 - learning_rate: 1.2500e-04\n",
      "Epoch 187/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9375 - loss: 0.4171\n",
      "Epoch 187: val_loss improved from 0.34998 to 0.34824, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9466 - loss: 0.4308 - val_accuracy: 1.0000 - val_loss: 0.3482 - learning_rate: 1.2500e-04\n",
      "Epoch 188/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.3678\n",
      "Epoch 188: val_loss improved from 0.34824 to 0.34664, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9955 - loss: 0.3675 - val_accuracy: 1.0000 - val_loss: 0.3466 - learning_rate: 1.2500e-04\n",
      "Epoch 189/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.3787\n",
      "Epoch 189: val_loss did not improve from 0.34664\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9681 - loss: 0.3850 - val_accuracy: 1.0000 - val_loss: 0.3512 - learning_rate: 1.2500e-04\n",
      "Epoch 190/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.3421\n",
      "Epoch 190: val_loss improved from 0.34664 to 0.34493, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9675 - loss: 0.3939 - val_accuracy: 1.0000 - val_loss: 0.3449 - learning_rate: 1.2500e-04\n",
      "Epoch 191/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.3531\n",
      "Epoch 191: val_loss improved from 0.34493 to 0.34040, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9731 - loss: 0.3816 - val_accuracy: 1.0000 - val_loss: 0.3404 - learning_rate: 1.2500e-04\n",
      "Epoch 192/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.4123\n",
      "Epoch 192: val_loss did not improve from 0.34040\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9695 - loss: 0.4132 - val_accuracy: 1.0000 - val_loss: 0.3492 - learning_rate: 1.2500e-04\n",
      "Epoch 193/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.3443\n",
      "Epoch 193: val_loss did not improve from 0.34040\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9776 - loss: 0.3696 - val_accuracy: 0.9667 - val_loss: 0.3560 - learning_rate: 1.2500e-04\n",
      "Epoch 194/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.9375 - loss: 0.5145\n",
      "Epoch 194: val_loss did not improve from 0.34040\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9629 - loss: 0.4232 - val_accuracy: 0.9667 - val_loss: 0.3561 - learning_rate: 1.2500e-04\n",
      "Epoch 195/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.3816\n",
      "Epoch 195: val_loss did not improve from 0.34040\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9729 - loss: 0.3887 - val_accuracy: 0.9667 - val_loss: 0.3653 - learning_rate: 1.2500e-04\n",
      "Epoch 196/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.3610\n",
      "Epoch 196: val_loss did not improve from 0.34040\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9787 - loss: 0.3705 - val_accuracy: 0.9667 - val_loss: 0.3533 - learning_rate: 1.2500e-04\n",
      "Epoch 197/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.3641\n",
      "Epoch 197: val_loss improved from 0.34040 to 0.33910, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9956 - loss: 0.3514 - val_accuracy: 1.0000 - val_loss: 0.3391 - learning_rate: 6.2500e-05\n",
      "Epoch 198/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9375 - loss: 0.4470\n",
      "Epoch 198: val_loss improved from 0.33910 to 0.33390, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9682 - loss: 0.3938 - val_accuracy: 1.0000 - val_loss: 0.3339 - learning_rate: 6.2500e-05\n",
      "Epoch 199/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.3856\n",
      "Epoch 199: val_loss improved from 0.33390 to 0.33213, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9673 - loss: 0.3828 - val_accuracy: 1.0000 - val_loss: 0.3321 - learning_rate: 6.2500e-05\n",
      "Epoch 200/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9688 - loss: 0.3931\n",
      "Epoch 200: val_loss improved from 0.33213 to 0.32979, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9694 - loss: 0.4119 - val_accuracy: 1.0000 - val_loss: 0.3298 - learning_rate: 6.2500e-05\n",
      "Epoch 201/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.3225\n",
      "Epoch 201: val_loss improved from 0.32979 to 0.32786, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9896 - loss: 0.3511 - val_accuracy: 1.0000 - val_loss: 0.3279 - learning_rate: 6.2500e-05\n",
      "Epoch 202/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.3308\n",
      "Epoch 202: val_loss improved from 0.32786 to 0.32481, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - accuracy: 0.9846 - loss: 0.3550 - val_accuracy: 1.0000 - val_loss: 0.3248 - learning_rate: 6.2500e-05\n",
      "Epoch 203/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.3347\n",
      "Epoch 203: val_loss improved from 0.32481 to 0.32374, saving model to best_handsigns_model.keras\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - accuracy: 0.9755 - loss: 0.3531 - val_accuracy: 1.0000 - val_loss: 0.3237 - learning_rate: 6.2500e-05\n",
      "Epoch 204/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.3543\n",
      "Epoch 204: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9792 - loss: 0.3563 - val_accuracy: 1.0000 - val_loss: 0.3252 - learning_rate: 6.2500e-05\n",
      "Epoch 205/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.3221\n",
      "Epoch 205: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9904 - loss: 0.3347 - val_accuracy: 1.0000 - val_loss: 0.3251 - learning_rate: 6.2500e-05\n",
      "Epoch 206/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.3230\n",
      "Epoch 206: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9925 - loss: 0.3499 - val_accuracy: 1.0000 - val_loss: 0.3248 - learning_rate: 6.2500e-05\n",
      "Epoch 207/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9375 - loss: 0.3698\n",
      "Epoch 207: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9548 - loss: 0.3768 - val_accuracy: 1.0000 - val_loss: 0.3255 - learning_rate: 6.2500e-05\n",
      "Epoch 208/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9688 - loss: 0.3651\n",
      "Epoch 208: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9822 - loss: 0.3497 - val_accuracy: 1.0000 - val_loss: 0.3256 - learning_rate: 6.2500e-05\n",
      "Epoch 209/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 0.9375 - loss: 0.4066\n",
      "Epoch 209: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9742 - loss: 0.3634 - val_accuracy: 1.0000 - val_loss: 0.3258 - learning_rate: 3.1250e-05\n",
      "Epoch 210/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.3334\n",
      "Epoch 210: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9786 - loss: 0.3720 - val_accuracy: 1.0000 - val_loss: 0.3262 - learning_rate: 3.1250e-05\n",
      "Epoch 211/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 1.0000 - loss: 0.3172\n",
      "Epoch 211: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9806 - loss: 0.3493 - val_accuracy: 1.0000 - val_loss: 0.3260 - learning_rate: 3.1250e-05\n",
      "Epoch 212/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 31ms/step - accuracy: 1.0000 - loss: 0.3217\n",
      "Epoch 212: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9841 - loss: 0.3773 - val_accuracy: 0.9833 - val_loss: 0.3276 - learning_rate: 3.1250e-05\n",
      "Epoch 213/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 32ms/step - accuracy: 0.9688 - loss: 0.3683\n",
      "Epoch 213: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9677 - loss: 0.4018 - val_accuracy: 1.0000 - val_loss: 0.3275 - learning_rate: 3.1250e-05\n",
      "Epoch 214/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 1.0000 - loss: 0.3269\n",
      "Epoch 214: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.9872 - loss: 0.3425 - val_accuracy: 1.0000 - val_loss: 0.3275 - learning_rate: 1.5625e-05\n",
      "Epoch 215/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.8750 - loss: 0.5190\n",
      "Epoch 215: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9422 - loss: 0.4313 - val_accuracy: 1.0000 - val_loss: 0.3267 - learning_rate: 1.5625e-05\n",
      "Epoch 216/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.3390\n",
      "Epoch 216: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9887 - loss: 0.3489 - val_accuracy: 1.0000 - val_loss: 0.3260 - learning_rate: 1.5625e-05\n",
      "Epoch 217/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 1.0000 - loss: 0.3523\n",
      "Epoch 217: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9787 - loss: 0.3562 - val_accuracy: 1.0000 - val_loss: 0.3253 - learning_rate: 1.5625e-05\n",
      "Epoch 218/500\n",
      "\u001B[1m1/8\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 1.0000 - loss: 0.3767\n",
      "Epoch 218: val_loss did not improve from 0.32374\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9823 - loss: 0.3641 - val_accuracy: 1.0000 - val_loss: 0.3249 - learning_rate: 1.5625e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "##          SINGLE VIDEO PREDICTION TEST         ##\n",
    "def predict_handsign(video_path, model):\n",
    "    # Process the video to extract landmarks\n",
    "    video_data = process_video(video_path)\n",
    "    \n",
    "    # Reshape the data to match the model input shape (add batch dimension for a single video)\n",
    "    video_data = video_data.reshape(1, frames_per_video, num_landmarks, num_coordinates)\n",
    "        # Make the prediction\n",
    "    prediction = model.predict(video_data)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    \n",
    "    return predicted_class, confidence  \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model('best_handsigns_model.keras')\n",
    "    \n",
    "    test_directory = \"Model testing videos\"\n",
    "    for video_file in os.listdir(test_directory):\n",
    "        if video_file.endswith(('.mp4', '.avi', '.mov')):\n",
    "            video_path = os.path.join(test_directory, video_file)\n",
    "            predicted_class, confidence = predict_handsign(video_path, model)\n",
    "            \n",
    "            # Get hand sign name\n",
    "            predicted_handsign = handsign_names.get(predicted_class, f\"HandSign_{predicted_class}\")\n",
    "            \n",
    "            # Apply confidence threshold\n",
    "            if confidence < 0.7:\n",
    "                predicted_handsign = \"Inseguro (\"+predicted_handsign+\")\"\n",
    "                \n",
    "            print(f\"Video: {video_file}\")\n",
    "            print(f\"Predicted Hand Sign: {predicted_handsign}\")\n",
    "            print(f\"Confidence: {confidence:.2f}\")\n",
    "            print(\"--------------------\")\n"
   ],
   "id": "4f9ed1d4df51b1c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:45:55.152456Z",
     "start_time": "2024-10-08T22:45:08.829127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##          CONTINUOUS PREDICTION WITH SLIDING WINDOW           ##\n",
    "\n",
    "import collections\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from scipy.interpolate import interp1d  # For smoothing landmarks\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('best_handsigns_model.keras')\n",
    "\n",
    "# Initialize Mediapipe solutions outside the loop for efficiency\n",
    "mp_hands = mp.solutions.hands.Hands(static_image_mode=False, \n",
    "                                    max_num_hands=2, \n",
    "                                    min_detection_confidence=0.4,  # Lowered confidence to allow for fast movement detection\n",
    "                                    min_tracking_confidence=0.4)   # Lowered tracking confidence\n",
    "mp_pose = mp.solutions.pose.Pose(static_image_mode=False, \n",
    "                                 min_detection_confidence=0.4, \n",
    "                                 min_tracking_confidence=0.4)\n",
    "\n",
    "# Open webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Sliding window buffer for frames\n",
    "frame_buffer = collections.deque(maxlen=frames_per_video)\n",
    "\n",
    "# To smooth predictions, keep track of recent predictions\n",
    "prediction_buffer = collections.deque(maxlen=3)\n",
    "\n",
    "# Store the last prediction\n",
    "last_prediction = \"No Prediction\"\n",
    "last_confidence = 0.0\n",
    "\n",
    "# Track missing hands to reset landmarks if missing for too long\n",
    "hand_missing_threshold = 5\n",
    "left_hand_missing_count = 0\n",
    "right_hand_missing_count = 0\n",
    "\n",
    "# Store the last known hand landmarks to compare in future frames\n",
    "last_left_hand_landmarks = None\n",
    "last_right_hand_landmarks = None\n",
    "\n",
    "# Movement delta threshold for fast movements\n",
    "movement_threshold = 0.9  # Adjusted threshold for movement delta\n",
    "\n",
    "# Smoothing factor for missing landmarks\n",
    "smoothing_factor = 0.8  # Weight to smooth landmarks during quick movements\n",
    "\n",
    "# Draw landmarks on the frame\n",
    "def draw_landmarks(frame, landmarks):\n",
    "    \"\"\"Draw landmarks on the frame.\"\"\"\n",
    "    for i, (x, y, z) in enumerate(landmarks):\n",
    "        h, w, _ = frame.shape\n",
    "        x = int(x * w + 325)\n",
    "        y = int(y * h + 250)\n",
    "        \n",
    "        if i < 21:  # Left hand landmarks\n",
    "            color = (0, 255, 0)\n",
    "        elif i < 42:  # Right hand landmarks\n",
    "            color = (0, 0, 255)\n",
    "        else:  # Body landmarks\n",
    "            color = (255, 0, 0)\n",
    "        \n",
    "        cv2.circle(frame, (x, y), 5, color, -1)\n",
    "\n",
    "def smooth_landmarks(new_landmarks, old_landmarks):\n",
    "    \"\"\"Smooth landmarks by interpolating between old and new.\"\"\"\n",
    "    if old_landmarks is None:\n",
    "        return new_landmarks\n",
    "\n",
    "    return old_landmarks * (1 - smoothing_factor) + new_landmarks * smoothing_factor\n",
    "\n",
    "def process_frame(frame):\n",
    "    global last_left_hand_landmarks, last_right_hand_landmarks\n",
    "    global left_hand_missing_count, right_hand_missing_count\n",
    "\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    hands_results = mp_hands.process(image)\n",
    "    pose_results = mp_pose.process(image)\n",
    "\n",
    "    # Initialize a zero-filled array for landmarks (51 landmarks, each with x, y, z)\n",
    "    landmarks = np.zeros((num_landmarks, num_coordinates))\n",
    "\n",
    "    # Detect nose for relative normalization\n",
    "    try:\n",
    "        nose_landmark = pose_results.pose_landmarks.landmark[0]\n",
    "    except:\n",
    "        class nose_landmark:\n",
    "            x = 0\n",
    "            y = 0\n",
    "            z = 0\n",
    "        nose_landmark = nose_landmark()\n",
    "\n",
    "    if hands_results.multi_hand_landmarks:\n",
    "        handedness_labels = [hand.classification[0].label for hand in hands_results.multi_handedness]\n",
    "\n",
    "        for i, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):\n",
    "            if handedness_labels[i] == 'Left':\n",
    "                left_hand = np.array([(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) \n",
    "                                      for lm in hand_landmarks.landmark])\n",
    "\n",
    "                # Smooth the transition between frames\n",
    "                left_hand = smooth_landmarks(left_hand, last_left_hand_landmarks)\n",
    "                \n",
    "                # Update the stored landmarks for the next frame\n",
    "                last_left_hand_landmarks = left_hand\n",
    "                landmarks[:21] = left_hand  # Insert the left hand landmarks into the first 21 slots\n",
    "\n",
    "            elif handedness_labels[i] == 'Right':\n",
    "                right_hand = np.array([(lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z) \n",
    "                                       for lm in hand_landmarks.landmark])\n",
    "\n",
    "                # Smooth the transition between frames\n",
    "                right_hand = smooth_landmarks(right_hand, last_right_hand_landmarks)\n",
    "                \n",
    "                # Update the stored landmarks for the next frame\n",
    "                last_right_hand_landmarks = right_hand\n",
    "                landmarks[21:42] = right_hand  # Insert the right hand landmarks into slots 21-42\n",
    "\n",
    "        # Reset the missing counts if hands are detected\n",
    "        left_hand_missing_count = 0\n",
    "        right_hand_missing_count = 0\n",
    "    else:\n",
    "        # Increment missing count when hands are not detected\n",
    "        left_hand_missing_count += 1\n",
    "        right_hand_missing_count += 1\n",
    "\n",
    "        # Reuse last known landmarks if available and hands are missing for too long\n",
    "        if last_left_hand_landmarks is not None:\n",
    "            landmarks[:21] = last_left_hand_landmarks\n",
    "        if last_right_hand_landmarks is not None:\n",
    "            landmarks[21:42] = last_right_hand_landmarks\n",
    "\n",
    "        # Reset landmarks if hands are missing for too long\n",
    "        if left_hand_missing_count > hand_missing_threshold:\n",
    "            last_left_hand_landmarks = None\n",
    "        if right_hand_missing_count > hand_missing_threshold:\n",
    "            last_right_hand_landmarks = None\n",
    "\n",
    "    # Fill in body landmarks (9 selected)\n",
    "    selected_body_landmarks = [0, 11, 12, 13, 14, 15, 16, 23, 24]\n",
    "    if pose_results.pose_landmarks:\n",
    "        for idx, landmark_idx in enumerate(selected_body_landmarks):\n",
    "            lm = pose_results.pose_landmarks.landmark[landmark_idx]\n",
    "            landmarks[42 + idx] = (lm.x - nose_landmark.x, lm.y - nose_landmark.y, lm.z - nose_landmark.z)\n",
    "\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "# Make a prediction based on the buffer\n",
    "def predict_handsign(buffer):\n",
    "    \"\"\"Make a prediction based on a buffer of frames.\"\"\"\n",
    "    video_data = np.array(buffer)\n",
    "    video_data = video_data.reshape(1, frames_per_video, num_landmarks, num_coordinates)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(video_data, verbose=0)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_class]\n",
    "\n",
    "    return predicted_class, confidence\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Process every frame (no skipping)\n",
    "    landmarks = process_frame(frame)\n",
    "\n",
    "    # Add the landmarks to the frame buffer\n",
    "    frame_buffer.append(landmarks)\n",
    "\n",
    "    # Draw the landmarks on the frame\n",
    "    draw_landmarks(frame, landmarks)\n",
    "\n",
    "    # Once the buffer is full, make a prediction using the sliding window\n",
    "    if len(frame_buffer) == frames_per_video:\n",
    "        predicted_class, confidence = predict_handsign(frame_buffer)\n",
    "        predicted_handsign = handsign_names.get(predicted_class, f\"HandSign_{predicted_class}\")\n",
    "\n",
    "        # Update the last prediction\n",
    "        last_prediction = predicted_handsign\n",
    "        last_confidence = confidence\n",
    "\n",
    "        # Store prediction and confidence in the buffer for smoothing\n",
    "        print((predicted_class, confidence))\n",
    "        prediction_buffer.append((predicted_class, confidence))\n",
    "\n",
    "        # Average the last N predictions to smooth the output\n",
    "        avg_pred_class = np.argmax(np.bincount([p[0] for p in prediction_buffer]))\n",
    "        avg_confidence = np.mean([p[1] for p in prediction_buffer if p[0] == avg_pred_class])\n",
    "\n",
    "        if avg_confidence > 0.8:\n",
    "            last_prediction = handsign_names.get(avg_pred_class, f\"HandSign_{avg_pred_class}\")\n",
    "            last_confidence = avg_confidence\n",
    "        elif 0.45 < avg_confidence < 0.8:\n",
    "            last_prediction = \"deteccion insegura: \"+handsign_names.get(avg_pred_class, f\"HandSign_{avg_pred_class}\")\n",
    "            last_confidence = avg_confidence\n",
    "        else:\n",
    "            last_prediction = \"deteccion nula\"\n",
    "            last_confidence = avg_confidence\n",
    "            \n",
    "    # Display the last prediction on the frame\n",
    "    cv2.putText(frame, f\"Predicted: {last_prediction} Conf: {last_confidence:.2f}\", \n",
    "                (10, 30), cv2.FONT_ITALIC, 0.7, (0, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('Hands Recognition', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "ee106e95cdc75678",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaqu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0.9974865)\n",
      "(2, 0.9990183)\n",
      "(2, 0.9991732)\n",
      "(2, 0.9995377)\n",
      "(2, 0.99977356)\n",
      "(2, 0.99988496)\n",
      "(2, 0.99994016)\n",
      "(2, 0.9999639)\n",
      "(2, 0.9999734)\n",
      "(2, 0.9999764)\n",
      "(2, 0.9999784)\n",
      "(2, 0.99998033)\n",
      "(2, 0.99997866)\n",
      "(2, 0.99997973)\n",
      "(2, 0.9999814)\n",
      "(2, 0.9999844)\n",
      "(2, 0.9999883)\n",
      "(2, 0.9999906)\n",
      "(2, 0.9999925)\n",
      "(2, 0.99999297)\n",
      "(2, 0.9999931)\n",
      "(2, 0.99999285)\n",
      "(2, 0.9999932)\n",
      "(2, 0.99999344)\n",
      "(2, 0.9999937)\n",
      "(2, 0.99999475)\n",
      "(2, 0.9999945)\n",
      "(2, 0.99999404)\n",
      "(2, 0.9999933)\n",
      "(2, 0.9999925)\n",
      "(2, 0.9999918)\n",
      "(2, 0.9999912)\n",
      "(2, 0.9999907)\n",
      "(2, 0.9999902)\n",
      "(2, 0.99998975)\n",
      "(2, 0.9999896)\n",
      "(2, 0.99999034)\n",
      "(2, 0.99998975)\n",
      "(2, 0.99998903)\n",
      "(2, 0.9999881)\n",
      "(2, 0.999987)\n",
      "(2, 0.9999876)\n",
      "(2, 0.99998844)\n",
      "(2, 0.99998903)\n",
      "(2, 0.9999863)\n",
      "(2, 0.99998367)\n",
      "(2, 0.99998367)\n",
      "(2, 0.9999844)\n",
      "(2, 0.99998474)\n",
      "(2, 0.9999852)\n",
      "(2, 0.999985)\n",
      "(2, 0.999984)\n",
      "(2, 0.9999827)\n",
      "(2, 0.99998105)\n",
      "(2, 0.999979)\n",
      "(2, 0.99998283)\n",
      "(2, 0.99998426)\n",
      "(2, 0.99998605)\n",
      "(2, 0.99998546)\n",
      "(2, 0.9999763)\n",
      "(2, 0.99993646)\n",
      "(2, 0.99977225)\n",
      "(2, 0.9994404)\n",
      "(2, 0.99936515)\n",
      "(2, 0.9997179)\n",
      "(2, 0.9999373)\n",
      "(2, 0.9999893)\n",
      "(2, 0.99999845)\n",
      "(2, 0.9999995)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999917)\n",
      "(2, 0.9999982)\n",
      "(2, 0.9999943)\n",
      "(2, 0.99997723)\n",
      "(2, 0.99988246)\n",
      "(2, 0.99904114)\n",
      "(2, 0.99463814)\n",
      "(2, 0.9709845)\n",
      "(2, 0.96199423)\n",
      "(2, 0.9263464)\n",
      "(2, 0.89430124)\n",
      "(2, 0.94267)\n",
      "(2, 0.9914335)\n",
      "(2, 0.99466103)\n",
      "(2, 0.9966671)\n",
      "(2, 0.9981165)\n",
      "(2, 0.99859494)\n",
      "(2, 0.99843675)\n",
      "(2, 0.9984163)\n",
      "(2, 0.9984841)\n",
      "(2, 0.9991333)\n",
      "(2, 0.9995803)\n",
      "(2, 0.99976987)\n",
      "(2, 0.9998318)\n",
      "(2, 0.99983597)\n",
      "(2, 0.99980885)\n",
      "(2, 0.99978393)\n",
      "(2, 0.9998006)\n",
      "(2, 0.99980193)\n",
      "(2, 0.999765)\n",
      "(2, 0.9997652)\n",
      "(2, 0.99975795)\n",
      "(2, 0.9997315)\n",
      "(2, 0.99971193)\n",
      "(2, 0.999658)\n",
      "(2, 0.99963284)\n",
      "(2, 0.9996824)\n",
      "(2, 0.9997379)\n",
      "(2, 0.9997929)\n",
      "(2, 0.9998299)\n",
      "(2, 0.99984896)\n",
      "(2, 0.9998528)\n",
      "(2, 0.9998461)\n",
      "(2, 0.99981874)\n",
      "(2, 0.9997701)\n",
      "(2, 0.9997316)\n",
      "(2, 0.9996996)\n",
      "(2, 0.9997067)\n",
      "(2, 0.9997265)\n",
      "(2, 0.9997576)\n",
      "(2, 0.99978334)\n",
      "(2, 0.9997981)\n",
      "(2, 0.9997814)\n",
      "(2, 0.999747)\n",
      "(2, 0.9997093)\n",
      "(2, 0.9996958)\n",
      "(2, 0.9997317)\n",
      "(2, 0.9997794)\n",
      "(2, 0.9998373)\n",
      "(2, 0.99989223)\n",
      "(2, 0.9999403)\n",
      "(2, 0.9999732)\n",
      "(2, 0.99999)\n",
      "(2, 0.99999654)\n",
      "(2, 0.9999989)\n",
      "(2, 0.99999964)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999964)\n",
      "(2, 0.99999917)\n",
      "(2, 0.9999989)\n",
      "(2, 0.9999974)\n",
      "(2, 0.99999666)\n",
      "(2, 0.9999949)\n",
      "(2, 0.9999896)\n",
      "(2, 0.99998224)\n",
      "(2, 0.99998736)\n",
      "(2, 0.99999225)\n",
      "(2, 0.9999957)\n",
      "(2, 0.9999975)\n",
      "(2, 0.9999982)\n",
      "(2, 0.99999857)\n",
      "(2, 0.9999987)\n",
      "(2, 0.999998)\n",
      "(2, 0.9999962)\n",
      "(2, 0.99999285)\n",
      "(2, 0.9999949)\n",
      "(2, 0.999997)\n",
      "(2, 0.9999987)\n",
      "(2, 0.99999917)\n",
      "(2, 0.9999993)\n",
      "(2, 0.9999993)\n",
      "(2, 0.99999905)\n",
      "(2, 0.99999857)\n",
      "(2, 0.99999917)\n",
      "(2, 0.9999993)\n",
      "(2, 0.9999995)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999964)\n",
      "(2, 0.9999995)\n",
      "(2, 0.9999989)\n",
      "(2, 0.9999968)\n",
      "(2, 0.9999865)\n",
      "(2, 0.99992526)\n",
      "(2, 0.99954826)\n",
      "(2, 0.9977175)\n",
      "(2, 0.99617875)\n",
      "(2, 0.9985821)\n",
      "(2, 0.9996488)\n",
      "(2, 0.99991536)\n",
      "(2, 0.9999844)\n",
      "(2, 0.999997)\n",
      "(2, 0.9999993)\n",
      "(2, 0.9999995)\n",
      "(2, 0.9999995)\n",
      "(2, 0.9999993)\n",
      "(2, 0.99999857)\n",
      "(2, 0.99999714)\n",
      "(2, 0.9999949)\n",
      "(2, 0.9999927)\n",
      "(2, 0.99999607)\n",
      "(2, 0.99999774)\n",
      "(2, 0.9999995)\n",
      "(2, 0.99999976)\n",
      "(2, 1.0)\n",
      "(2, 1.0)\n",
      "(2, 1.0)\n",
      "(2, 1.0)\n",
      "(2, 1.0)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 1.0)\n",
      "(2, 1.0)\n",
      "(2, 1.0)\n",
      "(2, 1.0)\n",
      "(2, 1.0)\n",
      "(2, 1.0)\n",
      "(2, 1.0)\n",
      "(2, 1.0)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999964)\n",
      "(2, 0.9999995)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.9999993)\n",
      "(2, 0.999998)\n",
      "(2, 0.9999912)\n",
      "(2, 0.9999454)\n",
      "(2, 0.99958664)\n",
      "(2, 0.996461)\n",
      "(2, 0.9663361)\n",
      "(2, 0.92815125)\n",
      "(2, 0.82026184)\n",
      "(2, 0.8024891)\n",
      "(2, 0.78415626)\n",
      "(2, 0.7901162)\n",
      "(2, 0.80541503)\n",
      "(2, 0.82826)\n",
      "(2, 0.8414892)\n",
      "(2, 0.85931176)\n",
      "(2, 0.8748201)\n",
      "(2, 0.8975202)\n",
      "(2, 0.93977296)\n",
      "(2, 0.9773008)\n",
      "(2, 0.9942081)\n",
      "(2, 0.99903154)\n",
      "(2, 0.9998832)\n",
      "(2, 0.99998856)\n",
      "(2, 0.9999987)\n",
      "(2, 0.99999976)\n",
      "(2, 0.99999976)\n",
      "(2, 0.9999995)\n",
      "(2, 0.999997)\n",
      "(2, 0.9999665)\n",
      "(2, 0.99953187)\n",
      "(2, 0.99276406)\n",
      "(2, 0.9046147)\n",
      "(2, 0.8601126)\n",
      "(2, 0.8710037)\n",
      "(2, 0.8946261)\n",
      "(2, 0.89550155)\n",
      "(2, 0.8691887)\n",
      "(2, 0.79186547)\n",
      "(2, 0.58050096)\n",
      "(0, 0.62544364)\n",
      "(0, 0.8206215)\n",
      "(0, 0.8786929)\n",
      "(0, 0.89761096)\n",
      "(0, 0.88550305)\n",
      "(0, 0.8729303)\n",
      "(0, 0.8241877)\n",
      "(0, 0.8123669)\n",
      "(0, 0.7887439)\n",
      "(0, 0.7159492)\n",
      "(0, 0.5732072)\n",
      "(1, 0.64801556)\n",
      "(1, 0.82831746)\n",
      "(1, 0.8749121)\n",
      "(1, 0.8089918)\n",
      "(2, 0.7470999)\n",
      "(2, 0.9796069)\n",
      "(2, 0.99786735)\n",
      "(2, 0.9997242)\n",
      "(2, 0.99995184)\n",
      "(2, 0.9999844)\n",
      "(2, 0.9999937)\n",
      "(2, 0.99999404)\n",
      "(2, 0.9999938)\n",
      "(2, 0.9999937)\n",
      "(2, 0.9999931)\n",
      "(2, 0.999992)\n",
      "(2, 0.9999901)\n",
      "(2, 0.99998605)\n",
      "(2, 0.99997723)\n",
      "(2, 0.99996185)\n",
      "(2, 0.9999306)\n",
      "(2, 0.9998666)\n",
      "(2, 0.9997167)\n",
      "(2, 0.9992392)\n",
      "(2, 0.9985442)\n",
      "(2, 0.996136)\n",
      "(2, 0.9825964)\n",
      "(2, 0.9780587)\n",
      "(2, 0.9502588)\n",
      "(2, 0.9337083)\n",
      "(2, 0.9526718)\n",
      "(2, 0.977448)\n",
      "(2, 0.984985)\n",
      "(2, 0.9874215)\n",
      "(2, 0.9897827)\n",
      "(2, 0.9912042)\n",
      "(2, 0.9920066)\n",
      "(2, 0.992269)\n",
      "(2, 0.99262625)\n",
      "(2, 0.99313664)\n",
      "(2, 0.99244964)\n",
      "(2, 0.99319845)\n",
      "(2, 0.9940818)\n",
      "(2, 0.99484336)\n",
      "(2, 0.99467826)\n",
      "(2, 0.99379706)\n",
      "(2, 0.9922651)\n",
      "(2, 0.9905426)\n",
      "(2, 0.9894371)\n",
      "(2, 0.98903906)\n",
      "(2, 0.9884985)\n",
      "(2, 0.98246175)\n",
      "(2, 0.9324592)\n",
      "(0, 0.48667824)\n",
      "(0, 0.9511523)\n",
      "(0, 0.9883868)\n",
      "(0, 0.99420565)\n",
      "(0, 0.99649066)\n",
      "(0, 0.9974808)\n",
      "(0, 0.99845016)\n",
      "(0, 0.9989594)\n",
      "(0, 0.9989796)\n",
      "(0, 0.9990037)\n",
      "(0, 0.99904305)\n",
      "(0, 0.99904865)\n",
      "(0, 0.99907315)\n",
      "(0, 0.99905735)\n",
      "(0, 0.9990601)\n",
      "(0, 0.99904317)\n",
      "(0, 0.9990219)\n",
      "(0, 0.99900466)\n",
      "(0, 0.9989826)\n",
      "(0, 0.9989753)\n",
      "(0, 0.9989611)\n",
      "(0, 0.99894756)\n",
      "(0, 0.9989323)\n",
      "(0, 0.99890924)\n",
      "(0, 0.9988894)\n",
      "(0, 0.9988707)\n",
      "(0, 0.9988575)\n",
      "(0, 0.99886584)\n",
      "(0, 0.99885345)\n",
      "(0, 0.9988476)\n",
      "(0, 0.99883777)\n",
      "(0, 0.998825)\n",
      "(0, 0.9988133)\n",
      "(0, 0.99877733)\n",
      "(0, 0.99875724)\n",
      "(0, 0.9987294)\n",
      "(0, 0.9987042)\n",
      "(0, 0.998676)\n",
      "(0, 0.9986206)\n",
      "(0, 0.99859494)\n",
      "(0, 0.9985424)\n",
      "(0, 0.99845004)\n",
      "(0, 0.99824536)\n",
      "(0, 0.99778795)\n",
      "(0, 0.996615)\n",
      "(0, 0.99492055)\n",
      "(0, 0.9890848)\n",
      "(0, 0.9638763)\n",
      "(0, 0.7222559)\n",
      "(1, 0.6459956)\n",
      "(2, 0.4931525)\n",
      "(2, 0.9807045)\n",
      "(2, 0.9811787)\n",
      "(2, 0.96858853)\n",
      "(2, 0.85041755)\n",
      "(0, 0.762341)\n",
      "(0, 0.98016536)\n",
      "(0, 0.99249446)\n",
      "(0, 0.9948343)\n",
      "(0, 0.995574)\n",
      "(0, 0.9965618)\n",
      "(0, 0.99703884)\n",
      "(0, 0.9978848)\n",
      "(0, 0.9972836)\n",
      "(0, 0.9957319)\n",
      "(0, 0.9914547)\n",
      "(0, 0.9857356)\n",
      "(0, 0.9564987)\n",
      "(2, 0.48751426)\n",
      "(2, 0.96967715)\n",
      "(2, 0.9721911)\n",
      "(2, 0.97412306)\n",
      "(2, 0.97743976)\n",
      "(2, 0.981689)\n",
      "(2, 0.9835865)\n",
      "(2, 0.98352456)\n",
      "(2, 0.9824584)\n",
      "(2, 0.9803022)\n",
      "(2, 0.9764115)\n",
      "(2, 0.975387)\n",
      "(2, 0.97518367)\n",
      "(2, 0.9752529)\n",
      "(2, 0.9732944)\n",
      "(2, 0.97297734)\n",
      "(2, 0.97500175)\n",
      "(2, 0.97502476)\n",
      "(2, 0.9685383)\n",
      "(2, 0.9600589)\n",
      "(2, 0.9588275)\n",
      "(2, 0.96631396)\n",
      "(2, 0.97612655)\n",
      "(2, 0.9874834)\n",
      "(2, 0.99138016)\n",
      "(2, 0.9811225)\n",
      "(2, 0.83088034)\n",
      "(0, 0.8719501)\n",
      "(0, 0.9851441)\n",
      "(0, 0.9917053)\n",
      "(0, 0.9933211)\n",
      "(0, 0.9953204)\n",
      "(0, 0.9965539)\n",
      "(0, 0.9980082)\n",
      "(0, 0.998064)\n",
      "(0, 0.99790645)\n",
      "(0, 0.99705803)\n",
      "(0, 0.99517834)\n",
      "(0, 0.99090844)\n",
      "(0, 0.9814957)\n",
      "(0, 0.9651609)\n",
      "(0, 0.9283975)\n",
      "(0, 0.92716974)\n",
      "(0, 0.8812991)\n",
      "(0, 0.55133057)\n",
      "(2, 0.9438266)\n",
      "(2, 0.99783236)\n",
      "(2, 0.9998436)\n",
      "(2, 0.9999821)\n",
      "(2, 0.99998736)\n",
      "(2, 0.9999908)\n",
      "(2, 0.99999523)\n",
      "(2, 0.99999654)\n",
      "(2, 0.99999475)\n",
      "(2, 0.9999894)\n",
      "(2, 0.9999764)\n",
      "(2, 0.9999585)\n",
      "(2, 0.99991715)\n",
      "(2, 0.99984443)\n",
      "(2, 0.9996092)\n",
      "(2, 0.9992387)\n",
      "(2, 0.9984956)\n",
      "(2, 0.9943293)\n",
      "(2, 0.9380517)\n",
      "(0, 0.66185576)\n",
      "(0, 0.9667896)\n",
      "(0, 0.98929906)\n",
      "(0, 0.99535096)\n",
      "(0, 0.9975745)\n",
      "(0, 0.9985719)\n",
      "(0, 0.99889755)\n",
      "(0, 0.99891555)\n",
      "(0, 0.9988945)\n",
      "(0, 0.99885964)\n",
      "(0, 0.9988237)\n",
      "(0, 0.99885213)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "##          MODEL TESTING          ##\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_and_preprocess_test_data(test_data_path):\n",
    "    # Reuse the process_dataset function\n",
    "    test_data = process_dataset(test_data_path)\n",
    "    \n",
    "    # Reshape the data to match the model input shape\n",
    "    X_test = test_data.reshape(-1, frames_per_video, num_landmarks, num_coordinates)\n",
    "    y_test = np.repeat(np.arange(num_handsigns), videos_per_handsign)\n",
    "    \n",
    "    return X_test, y_test\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Generate classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_classes))\n",
    "    \n",
    "    return y_pred_classes\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_misclassifications(X_test, y_test, y_pred, num_samples=5):\n",
    "    misclassified = np.where(y_test != y_pred)[0]\n",
    "    np.random.shuffle(misclassified)\n",
    "    \n",
    "    for i in range(min(num_samples, len(misclassified))):\n",
    "        idx = misclassified[i]\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Plot a representation of the hand sign (e.g., first frame landmarks)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(X_test[idx, 0, :, 0], X_test[idx, 0, :, 1])\n",
    "        plt.title(f\"True: {y_test[idx]}, Predicted: {y_pred[idx]}\")\n",
    "        plt.xlabel(\"X coordinate\")\n",
    "        plt.ylabel(\"Y coordinate\")\n",
    "        \n",
    "        # Plot the confidence scores for each class\n",
    "        plt.subplot(1, 2, 2)\n",
    "        confidence_scores = model.predict(X_test[idx:idx+1])[0]\n",
    "        plt.bar(range(num_handsigns), confidence_scores)\n",
    "        plt.title(\"Confidence Scores\")\n",
    "        plt.xlabel(\"Hand Sign Class\")\n",
    "        plt.ylabel(\"Confidence\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model('handsigns_model.h5')\n",
    "    \n",
    "    # Load and preprocess test data\n",
    "    test_data_path = \"Model testing videos\"  # Replace with your test dataset path\n",
    "    X_test, y_test = load_and_preprocess_test_data(test_data_path)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Visualize some misclassifications\n",
    "    visualize_misclassifications(X_test, y_test, y_pred)"
   ],
   "id": "67b4c8b4c4f1ca0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
